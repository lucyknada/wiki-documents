<!doctype html>
<html lang="en-US" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-Edge/NVIDIA_Jetson/Application/Computer_Vision/YOLOv8-TRT-Jetson" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.3">
<title data-rh="true">Deploy YOLOv8 with TensorRT | Seeed Studio Wiki</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://wiki.seeedstudio.com/YOLOv8-TRT-Jetson/"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Deploy YOLOv8 with TensorRT | Seeed Studio Wiki"><meta data-rh="true" name="description" content="Deploy YOLOv8 on NVIDIA Jetson using TensorRT - Data Label, AI Model Train, AI Model Deploy"><meta data-rh="true" property="og:description" content="Deploy YOLOv8 on NVIDIA Jetson using TensorRT - Data Label, AI Model Train, AI Model Deploy"><meta data-rh="true" property="og:image" content="https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png"><meta data-rh="true" name="twitter:image" content="https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png"><link data-rh="true" rel="icon" href="/img/S.png"><link data-rh="true" rel="canonical" href="https://wiki.seeedstudio.com/YOLOv8-TRT-Jetson/"><link data-rh="true" rel="alternate" href="https://wiki.seeedstudio.com/YOLOv8-TRT-Jetson/" hreflang="en-US"><link data-rh="true" rel="alternate" href="https://wiki.seeedstudio.com/YOLOv8-TRT-Jetson/" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Seeed Studio Wiki RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Seeed Studio Wiki Atom Feed">

<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n,g){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var m=t.getElementsByTagName(a)[0],r=t.createElement(a);r.async=!0,r.src="https://www.googletagmanager.com/gtm.js?id=GTM-M4JG2HVB",m.parentNode.insertBefore(r,m)}(window,document,"script","dataLayer")</script>


<link rel="icon" href="/img/S.png">
<link rel="manifest" href="/manifest.json">
<meta name="theme-color" content="rgb(37, 194, 160)">


<link rel="search" type="application/opensearchdescription+xml" title="Seeed Studio Wiki" href="/opensearch.xml">
<script src="https://viewer.altium.com/client/static/js/embed.js" async></script>
<script src="/js/custom.js" async></script><link rel="stylesheet" href="/assets/css/styles.f264e8be.css">
<link rel="preload" href="/assets/js/runtime~main.001b1c61.js" as="script">
<link rel="preload" href="/assets/js/main.5e3b5140.js" as="script">
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-M4JG2HVB" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementBar_mb4j" style="background-color:#013949;color:#FFFFFF" role="banner"><div class="content_knG7 announcementBarContent_xLdY">Building Sustainable Growth, Strengthening Local Partnerships. Join   the <a target="_blank" href="https://wiki.seeedstudio.com/ranger/">Seeed Studio Ranger Program</a> now! </div></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Getting_Started/"><div class="navbar__logo"><img src="https://files.seeedstudio.com/wiki/wiki-platform/SeeedStudio.png" alt="Seeed Studio" class="themedImage_ToTc themedImage--light_HNdA navbar_logo_items"><img src="https://files.seeedstudio.com/wiki/wiki-platform/seeed_white_logo.png" alt="Seeed Studio" class="themedImage_ToTc themedImage--dark_i4oU navbar_logo_items"></div></a><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link navbar_dorp_items" aria-haspopup="true" aria-expanded="false" role="button" href="/Getting_Started/">Getting Started</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/Sensor_Network/">Sensor and Sensing</a></li><li><a class="dropdown__link" href="/Network/">Networking</a></li><li><a class="dropdown__link" href="/Edge_Computing/">Edge Computing</a></li><li><a class="dropdown__link" href="/Cloud/">Cloud</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link navbar_dorp_items" aria-haspopup="true" aria-expanded="false" role="button" href="/topicintroduction/">Technology</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/tinyml_topic/">TinyML</a></li><li><a class="dropdown__link" href="/ModelAssistant_Introduce_Overview/">SenseCraft Model Assistant</a></li><li><a class="dropdown__link" href="/home_assistant_topic/">Home Assistant</a></li><li><a class="dropdown__link" href="/open_source_topic/">Open Source</a></li><li><a class="dropdown__link" href="/edge_ai_topic/">Edge AI</a></li><li><a class="dropdown__link" href="/cn/Getting_Started/">矽递科技 Wiki 文档平台（测试）</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link navbar_dorp_items" aria-haspopup="true" aria-expanded="false" role="button" href="/knowledgebase/">FAQs</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/Jetson_FAQ/">NVIDIA Jetson Series</a></li><li><a class="dropdown__link" href="/XIAO_FAQ/">Seeed Studio XIAO Series</a></li><li><a class="dropdown__link" href="/reTerminal-new_FAQ/">reTerminal</a></li><li><a class="dropdown__link" href="/FAQs_For_openWrt/">reRouter</a></li><li><a class="dropdown__link" href="/ODYSSEY_FAQ/">Odyssey</a></li><li><a class="dropdown__link" href="/wio_terminal_faq/">Wio Terminal</a></li><li><hr style="margin: 8px 0;"></li><li><a href="https://discord.com/invite/eWkprNDMU7" target="_blank" rel="noopener noreferrer" class="dropdown__link">Discord<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://www.seeedstudio.com/contacts" target="_blank" rel="noopener noreferrer" class="dropdown__link">Email<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://forum.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Forum<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://github.com/Seeed-Studio/wiki-documents/discussions/69" target="_blank" rel="noopener noreferrer" class="dropdown__link">Have Suggestions?<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link navbar_dorp_items" aria-haspopup="true" aria-expanded="false" role="button" href="/ranger/">Rangers</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/ranger/">Rangers</a></li><li><a href="https://github.com/orgs/Seeed-Studio/projects/6?pane=issue&amp;itemId=30957479" target="_blank" rel="noopener noreferrer" class="dropdown__link">Contributors(GitHub)<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="navbar__items navbar__items--right"><a href="https://www.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar_doc_right_items">Bazaar 🛍️</a><a href="https://wiki-gpt.seeedstudio.com/chat" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar_doc_right_items">AI Bot 🤖️</a><a href="https://sensecraft.seeed.cc/ai/#/home" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar_doc_right_items">SenseCraft AI</a><a href="https://sensecraft.seeed.cc/ai/#/home" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-SSCMA"></a><a href="https://github.com/Seeed-Studio/wiki-documents" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/Getting_Started/">Getting Started</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/weekly_wiki/">Weekly Wiki</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/Sensor_Network/">Sensing</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Grove_System/">Grove</a><button aria-label="Toggle the collapsible sidebar category &#x27;Grove&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/SenseCAP_introduction/">SenseCAP</a><button aria-label="Toggle the collapsible sidebar category &#x27;SenseCAP&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/mmwave_radar_Intro/">mmWave Radar Sensor</a><button aria-label="Toggle the collapsible sidebar category &#x27;mmWave Radar Sensor&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/SeeedStudio_XIAO_Series_Introduction/">XIAO</a><button aria-label="Toggle the collapsible sidebar category &#x27;XIAO&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Wio_Terminal_Intro/">Wio Terminal</a><button aria-label="Toggle the collapsible sidebar category &#x27;Wio Terminal&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Sensor/SenseCAP/SenseCAP_Indicator/Get_started_with_SenseCAP_Indicator/">SenseCAP Indicator</a><button aria-label="Toggle the collapsible sidebar category &#x27;SenseCAP Indicator&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Ultra_Sonic_range_measurement_module/">Other Sensing Modules</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Wio/">Other Microcontrollers</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/Network/">Network</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Network/SenseCAP_Network/SenseCAP_Gateway_Intro/">SenseCAP Gateway</a><button aria-label="Toggle the collapsible sidebar category &#x27;SenseCAP Gateway&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/SenseCAP_K1100_Intro/">SenseCAP K1100</a><button aria-label="Toggle the collapsible sidebar category &#x27;SenseCAP K1100&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/M2_Kit_Getting_Started/">SenseCAP LoRaWAN Starter Kit</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/reRouter_Intro/">Raspberry Pi Solutions</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Rockchip_network_solutions/">Rockchip Solutions</a><button aria-label="Toggle the collapsible sidebar category &#x27;Rockchip Solutions&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/The-Things-Indoor-Gateway/">Other Network Devices</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/Edge_Computing/">Edge Computing</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/raspberry-pi-devices/">Raspberry Pi Devices</a><button aria-label="Toggle the collapsible sidebar category &#x27;Raspberry Pi Devices&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/NVIDIA_Jetson/">NVIDIA Jetson®</a><button aria-label="Toggle the collapsible sidebar category &#x27;NVIDIA Jetson®&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/reComputer_J1010_J101_Flash_Jetpack/">Carrier Boards</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/reComputer_Intro/">reComputer Jetson Series</a><button aria-label="Toggle the collapsible sidebar category &#x27;reComputer Jetson Series&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/reServer_Industrial_Getting_Started/">reServer Jetson Series</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/Jetson_AGX_Orin_32GB_H01_Flash_Jetpack/">Other Devices</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/DashCamNet-with-Jetson-Xavier-NX-Multicamera/">Application</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/DashCamNet-with-Jetson-Xavier-NX-Multicamera/">Computer Vision</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/DashCamNet-with-Jetson-Xavier-NX-Multicamera/">DashCamNet with Jetson Xavier NX Multicamera</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/How_to_Train_and_Deploy_YOLOv8_on_reComputer/">How to train and deploy YOLOv8 on reComputer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/Jetson-Nano-MaskCam/">MaskCam</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/Security_Scan/">Security Xray Scan Knife Detection</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/reComputer_Jetson_Series_Projects/">Jetson Community Projects</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/Traffic-Management-DeepStream-SDK/">Traffic Management DeepStream SDK</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/YOLOv5-Object-Detection-Jetson/">Getting started with Yolov5 and roboflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/YOLOv8-DeepStream-TRT-Jetson/">Deploy YOLOv8 with TensorRT and DeepStream SDK</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/YOLOv8-TRT-Jetson/">Deploy YOLOv8 with TensorRT</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/reComputer_Jetson_Series_Tutorials_Exercise/">reComputer for Jetson Tutorials and Exercise</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/Local_Voice_Chatbot/">Generative AI</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/Allxon-Jetson-Getting-Started/">Managed Services</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/alwaysAI-Jetson-Getting-Started/">Developer Tools</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/Jetson_FAQ/">FAQs</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Edgebox-ESP-100-Arduino/">ESP Devices</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/BeagleBone/">BeagleBone®</a><button aria-label="Toggle the collapsible sidebar category &#x27;BeagleBone®&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/ODYSSEY_Intro/">ODYSSEY</a><button aria-label="Toggle the collapsible sidebar category &#x27;ODYSSEY&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/reServer-Getting-Started/">Other Edge Devices</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/Cloud/">Cloud</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Cloud_Chain/SenseCAP_Dashboard/Dashboard_Basics/">SenseCAP Dashboard</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Cloud_Chain/SenseCAP_Portal/QuickStart/">SenseCAP Portal</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/SenseCAP_Hotspot_APP/">SenseCAP Hotspot APP</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Cloud_Chain/SenseCAP_Mate_APP/SenseCAP_APP/">SenseCAP Mate APP</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/How_to_Use_SenseCAP_AI_on_SenseCAP_Portal_and_SenseCAP_Mate_APP/">SenseCAP AI</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Cloud_Chain/SenseCAP_API/SenseCAP_API_Introduction/">SenseCAP API</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/SenseCraft_AI/">SenseCraft</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/topicintroduction/">Technology Topics</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/home_assistant_topic/">Home Assistant</a><button aria-label="Toggle the collapsible sidebar category &#x27;Home Assistant&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/tinyml_topic/">TinyML</a><button aria-label="Toggle the collapsible sidebar category &#x27;TinyML&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/open_source_topic/">Open Source</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/edge_ai_topic/">Edge AI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/Contributor/">Contributions</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Contribution-Guide/">Github Contributions Guide</a><button aria-label="Toggle the collapsible sidebar category &#x27;Github Contributions Guide&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/community_sourced_projects/">Community Sourced Projects</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Scale-up-Your-Creation-with-Fusion/">Scale up Your Creation with Seeed Studio Fusion</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/popularplatforms/">Popular Platforms</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Arduino/">Arduino</a><button aria-label="Toggle the collapsible sidebar category &#x27;Arduino&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Raspberry_Pi/">Raspberry Pi</a><button aria-label="Toggle the collapsible sidebar category &#x27;Raspberry Pi&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/microbit_wiki_page/">Micro:bit</a><button aria-label="Toggle the collapsible sidebar category &#x27;Micro:bit&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/discontinuedproducts/">Discontinued Products</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/ReSpeaker/">Product List</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/About/">About</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/License/">License</a></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_z5aJ"><div class="docItemContainer_c0TR"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/NVIDIA_Jetson/"><span itemprop="name">NVIDIA Jetson®</span></a><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Application</span><meta itemprop="position" content="2"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Computer Vision</span><meta itemprop="position" content="3"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Deploy YOLOv8 with TensorRT</span><meta itemprop="position" content="4"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Deploy YOLOv8 on NVIDIA Jetson using TensorRT</h1><p>This wiki guide explains how to deploy a YOLOv8 model into NVIDIA Jetson Platform and perform inference using TensorRT. Here we use TensorRT to maximize the inference performance on the Jetson platform.</p><p>Different computer vision tasks will be introduced here such as:</p><ul><li>Object Detection</li><li>Image Segmentation</li><li>Image Classification</li><li>Pose Estimation</li><li>Object Tracking</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/8.gif" style="width:1000px;height:auto" class="img_ev3q"></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="prerequisites">Prerequisites<a href="#prerequisites" class="hash-link" aria-label="Direct link to Prerequisites" title="Direct link to Prerequisites">​</a></h2><ul><li>Ubuntu Host PC (native or VM using VMware Workstation Player)</li><li><a href="https://www.seeedstudio.com/reComputer-J4012-p-5586.html" target="_blank" rel="noopener noreferrer">reComputer Jetson</a> or any other NVIDIA Jetson device running JetPack 5.1.1 or higher</li></ul><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_S0QG"><p>This wiki has been tested and verified on a <a href="https://www.seeedstudio.com/reComputer-J4012-p-5586.html" target="_blank" rel="noopener noreferrer">reComputer J4012</a> and reComputer Industrial J4012<!-- -->[https://www.seeedstudio.com/reComputer-Industrial-J4012-p-5684.html]<!-- --> powered by NVIDIA Jetson orin NX 16GB module </p></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="flash-jetpack-to-jetson">Flash JetPack to Jetson<a href="#flash-jetpack-to-jetson" class="hash-link" aria-label="Direct link to Flash JetPack to Jetson" title="Direct link to Flash JetPack to Jetson">​</a></h2><p>Now you need to make sure that the Jetson device is flashed with a <a href="https://developer.nvidia.com/embedded/jetpack" target="_blank" rel="noopener noreferrer">JetPack</a> system. You can either use NVIDIA SDK Manager or command-line to flash JetPack to the device.</p><p>For Seeed Jetson-powered devices flashing guides, please refer to the below links:</p><ul><li><a href="https://wiki.seeedstudio.com/reComputer_J1010_J101_Flash_Jetpack" target="_blank" rel="noopener noreferrer">reComputer J1010 | J101</a></li><li><a href="https://wiki.seeedstudio.com/reComputer_J2021_J202_Flash_Jetpack" target="_blank" rel="noopener noreferrer">reComputer J2021 | J202</a></li><li><a href="https://wiki.seeedstudio.com/reComputer_J1020_A206_Flash_JetPack" target="_blank" rel="noopener noreferrer">reComputer J1020 | A206</a></li><li><a href="https://wiki.seeedstudio.com/reComputer_J4012_Flash_Jetpack" target="_blank" rel="noopener noreferrer">reComputer J4012 | J401</a></li><li><a href="https://wiki.seeedstudio.com/reComputer_A203_Flash_System" target="_blank" rel="noopener noreferrer">A203 Carrier Board</a></li><li><a href="https://wiki.seeedstudio.com/reComputer_A205_Flash_System" target="_blank" rel="noopener noreferrer">A205 Carrier Board</a></li><li><a href="https://wiki.seeedstudio.com/Jetson_Xavier_AGX_H01_Driver_Installation" target="_blank" rel="noopener noreferrer">Jetson Xavier AGX H01 Kit</a></li><li><a href="https://wiki.seeedstudio.com/Jetson_AGX_Orin_32GB_H01_Flash_Jetpack" target="_blank" rel="noopener noreferrer">Jetson AGX Orin 32GB H01 Kit</a></li></ul><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_S0QG"><p>Make sure to Flash JetPack version 5.1.1 because that is the version we have verified for this wiki </p></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-yolov8-to-jetson-in-one-line-of-code">Deploy YOLOV8 to Jetson in One Line of Code!<a href="#deploy-yolov8-to-jetson-in-one-line-of-code" class="hash-link" aria-label="Direct link to Deploy YOLOV8 to Jetson in One Line of Code!" title="Direct link to Deploy YOLOV8 to Jetson in One Line of Code!">​</a></h2><p>After you flash the Jetson device with JetPack, you can simply run the below commands to run YOLOv8 models.  This will first download and install the necessary packages, dependencies, setup the environment and download pretrained models from YOLOv8 to perform object detection, Image segmentation, pose estimation and image classifications tasks!</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget files.seeedstudio.com/YOLOv8-Jetson.py &amp;&amp; python YOLOv8-Jetson.py</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_S0QG"><p>The source code for the above script can be found <a href="https://github.com/yuyoujiang/Run-YOLOv8-in-One-Line-on-Jetson" target="_blank" rel="noopener noreferrer">here</a></p></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="use-pre-trained-models">Use Pre-trained models<a href="#use-pre-trained-models" class="hash-link" aria-label="Direct link to Use Pre-trained models" title="Direct link to Use Pre-trained models">​</a></h2><p>The fastest way to get started with YOLOv8 is to use pre-trained models provided by YOLOv8. However, these are PyTorch models and therefore will only utilize the CPU when inferencing on the Jetson. If you want the best performance of these models on the Jetson while running on the GPU, you can export the PyTorch models to TensorRT by following this section of the wiki.</p><div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Object Detection</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Image Classification</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Image Segmentation</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Pose Estimation</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Object Tracking</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><p>YOLOv8 offers 5 pre-trained PyTorch model weights for object detection, trained on COCO dataset at input image size 640x640. You can find them below</p><table><thead><tr><th>Model</th><th>size<br>(pixels)</th><th>mAPval<br>50-95</th><th>Speed<br>CPU ONNX<br>(ms)</th><th>Speed<br>A100 TensorRT<br>(ms)</th><th>params<br>(M)</th><th>FLOPs<br>(B)</th></tr></thead><tbody><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt" target="_blank" rel="noopener noreferrer">YOLOv8n</a></td><td>640</td><td>37.3</td><td>80.4</td><td>0.99</td><td>3.2</td><td>8.7</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt" target="_blank" rel="noopener noreferrer">YOLOv8s</a></td><td>640</td><td>44.9</td><td>128.4</td><td>1.20</td><td>11.2</td><td>28.6</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m.pt" target="_blank" rel="noopener noreferrer">YOLOv8m</a></td><td>640</td><td>50.2</td><td>234.7</td><td>1.83</td><td>25.9</td><td>78.9</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l.pt" target="_blank" rel="noopener noreferrer">YOLOv8l</a></td><td>640</td><td>52.9</td><td>375.2</td><td>2.39</td><td>43.7</td><td>165.2</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt" target="_blank" rel="noopener noreferrer">YOLOv8x</a></td><td>640</td><td>53.9</td><td>479.1</td><td>3.53</td><td>68.2</td><td>257.8</td></tr></tbody></table><p>Reference: <a href="https://docs.ultralytics.com/tasks/detect" target="_blank" rel="noopener noreferrer">https://docs.ultralytics.com/tasks/detect</a></p><p>You can choose and download your desired model from the above table and execute the below command to run inference on an image</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo detect predict model=yolov8n.pt source=&#x27;https://ultralytics.com/images/bus.jpg&#x27; show=True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Here for model, you can change to either yolov8s.pt, yolov8m.pt, yolov8l.pt, yolov8x.pt and it will download the relavant pre-trained model</p><p>You can also connect a webcam and execute the below command </p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo detect predict model=yolov8n.pt source=&#x27;0&#x27; show=True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_S0QG"><p>If you face any errors when executing the above commands, try adding &quot;device=0&quot; at the end of the command</p></div></div><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/2.gif" style="width:1000px;height:auto" class="img_ev3q"></div><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_S0QG"><p>The above is run on a reComputer J4012/ reComputer Industrial J4012 and uses YOLOv8s model trained with 640x640 input and uses TensorRT FP16 precision.</p></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><p>YOLOv8 offers 5 pre-trained PyTorch model weights for image classification, trained on ImageNet at input image size 224x224. You can find them below</p><table><thead><tr><th>Model</th><th>size<br>(pixels)</th><th>acc<br>top1</th><th>acc<br>top5<br></th><th>Speed<br>CPU ONNX<br>(ms)<br></th><th>Speed<br>A100 TensorRT<br>(ms)<br><br></th><th>params<br>(M)<br></th><th>FLOPs<br>(B) at 640</th></tr></thead><tbody><tr><td>YOLOv8n-cls</td><td>224</td><td>66.6</td><td>87.0</td><td>12.9</td><td>0.31</td><td>2.7</td><td>4.3</td></tr><tr><td>YOLOv8s-cls</td><td>224</td><td>72.3</td><td>91.1</td><td>23.4</td><td>0.35</td><td>6.4</td><td>13.5</td></tr><tr><td>YOLOv8m-cls</td><td>224</td><td>76.4</td><td>93.2</td><td>85.4</td><td>0.62</td><td>17.0</td><td>42.7</td></tr><tr><td>YOLOv8l-cls</td><td>224</td><td>78.0</td><td>94.1</td><td>163.0</td><td>0.87</td><td>37.5</td><td>99.7</td></tr><tr><td> YOLOv8x-cls</td><td>224</td><td>78.4</td><td>94.3</td><td>232.0</td><td>1.01</td><td>57.4</td><td>154.8</td></tr></tbody></table><p>Reference: <a href="https://docs.ultralytics.com/tasks/classify" target="_blank" rel="noopener noreferrer">https://docs.ultralytics.com/tasks/classify</a></p><p>You can choose your desired model and execute the below command to run inference on an image</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo classify predict model=yolov8n-cls.pt source=&#x27;https://ultralytics.com/images/bus.jpg&#x27; show=True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Here for model, you can change to either yolov8s-cls.pt, yolov8m-cls.pt, yolov8l-cls.pt, yolov8x-cls.pt and it will download the relavant pre-trained model</p><p>You can also connect a webcam and execute the below command </p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo classify predict model=yolov8n-cls.pt source=&#x27;0&#x27; show=True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_S0QG"><p>If you face any errors when executing the above commands, try adding &quot;device=0&quot; at the end of the command</p></div></div><p>(update with 224 inference)</p><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/5.gif" style="width:1000px;height:auto" class="img_ev3q"></div><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_S0QG"><p>The above is run on a reComputer J4012/ reComputer Industrial J4012 and uses YOLOv8s-cls model trained with 224x224 input and uses TensorRT FP16 precision. Also, make sure to pass the argument <strong>imgsz=224</strong> inside the inference command with TensorRT exports because the inference engine accepts 640 image size by default when using TensorRT models.</p></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><p>YOLOv8 offers 5 pre-trained PyTorch model weights for image segmentation, trained on COCO dataset at input image size 640x640. You can find them below</p><table><thead><tr><th>Model</th><th>size<br>(pixels)</th><th>mAPbox<br>50-95</th><th>mAPmask<br>50-95</th><th>Speed<br>CPU ONNX<br>(ms)</th><th>Speed<br>A100 TensorRT<br>(ms)</th><th>params<br>(M)</th><th>FLOPs<br>(B)</th></tr></thead><tbody><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-seg.pt" target="_blank" rel="noopener noreferrer">YOLOv8n-seg</a></td><td>640</td><td>36.7</td><td>30.5</td><td>96.1</td><td>1.21</td><td>3.4</td><td>12.6</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s-seg.pt" target="_blank" rel="noopener noreferrer">YOLOv8s-seg</a></td><td>640</td><td>44.6</td><td>36.8</td><td>155.7</td><td>1.47</td><td>11.8</td><td>42.6</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt" target="_blank" rel="noopener noreferrer">YOLOv8m-seg</a></td><td>640</td><td>49.9</td><td>40.8</td><td>317.0</td><td>2.18</td><td>27.3</td><td>110.2</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l-seg.pt" target="_blank" rel="noopener noreferrer">YOLOv8l-seg</a></td><td>640</td><td>52.3</td><td>42.6</td><td>572.4</td><td>2.79</td><td>46.0</td><td>220.5</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x-seg.pt" target="_blank" rel="noopener noreferrer">YOLOv8x-seg</a></td><td>640</td><td>53.4</td><td>43.4</td><td>712.1</td><td>4.02</td><td>71.8</td><td>344.1</td></tr></tbody></table><p>Reference: <a href="https://docs.ultralytics.com/tasks/segment" target="_blank" rel="noopener noreferrer">https://docs.ultralytics.com/tasks/segment</a></p><p>You can choose your desired model and execute the below command to run inference on an image</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo segment predict model=yolov8n-seg.pt source=&#x27;https://ultralytics.com/images/bus.jpg&#x27; show=True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Here for model, you can change to either yolov8s-seg.pt, yolov8m-seg.pt, yolov8l-seg.pt, yolov8x-seg.pt and it will download the relavant pre-trained model</p><p>You can also connect a webcam and execute the below command </p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo segment predict model=yolov8n-seg.pt source=&#x27;0&#x27; show=True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_S0QG"><p>If you face any errors when executing the above commands, try adding &quot;device=0&quot; at the end of the command</p></div></div><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/3.gif" style="width:1000px;height:auto" class="img_ev3q"></div><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_S0QG"><p>The above is run on a reComputer J4012/ reComputer Industrial J4012 and uses YOLOv8s-seg model trained with 640x640 input and uses TensorRT FP16 precision.</p></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><p>YOLOv8 offers 6 pre-trained PyTorch model weights for pose estimation, trained on COCO keypoints dataset at input image size 640x640. You can find them below</p><table><thead><tr><th>Model</th><th>size<br>(pixels)</th><th>mAPpose<br>50-95</th><th>mAPpose<br>50</th><th>Speed<br>CPU ONNX<br>(ms)</th><th>Speed<br>A100 TensorRT<br>(ms)</th><th>params<br>(M)</th><th>FLOPs<br>(B)</th></tr></thead><tbody><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-pose.pt" target="_blank" rel="noopener noreferrer">YOLOv8n-pose</a></td><td>640</td><td>50.4</td><td>80.1</td><td>131.8</td><td>1.18</td><td>3.3</td><td>9.2</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s-pose.pt" target="_blank" rel="noopener noreferrer">YOLOv8s-pose</a></td><td>640</td><td>60.0</td><td>86.2</td><td>233.2</td><td>1.42</td><td>11.6</td><td>30.2</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-pose.pt" target="_blank" rel="noopener noreferrer">YOLOv8m-pose</a></td><td>640</td><td>65.0</td><td>88.8</td><td>456.3</td><td>2.00</td><td>26.4</td><td>81.0</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l-pose.pt" target="_blank" rel="noopener noreferrer">YOLOv8l-pose</a></td><td>640</td><td>67.6</td><td>90.0</td><td>784.5</td><td>2.59</td><td>44.4</td><td>168.6</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x-pose.pt" target="_blank" rel="noopener noreferrer">YOLOv8x-pose</a></td><td>640</td><td>69.2</td><td>90.2</td><td>1607.1</td><td>3.73</td><td>69.4</td><td>263.2</td></tr><tr><td><a href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x-pose-p6.pt" target="_blank" rel="noopener noreferrer">YOLOv8x-pose-p6</a></td><td>1280</td><td>71.6</td><td>91.2</td><td>4088.7</td><td>10.04</td><td>99.1</td><td>1066.4</td></tr></tbody></table><p>Reference: <a href="https://docs.ultralytics.com/tasks/pose" target="_blank" rel="noopener noreferrer">https://docs.ultralytics.com/tasks/pose</a></p><p>You can choose your desired model and execute the below command to run inference on an image</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo pose predict model=yolov8n-pose.pt source=&#x27;https://ultralytics.com/images/bus.jpg&#x27;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Here for model, you can change to either yolov8s-pose.pt, yolov8m-pose.pt, yolov8l-pose.pt, yolov8x-pose.pt, yolov8x-pose-p6 and it will download the relavant pre-trained model</p><p>You can also connect a webcam and execute the below command </p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo pose predict model=yolov8n-pose.pt source=&#x27;0&#x27;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_S0QG"><p>If you face any errors when executing the above commands, try adding &quot;device=0&quot; at the end of the command</p></div></div><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/4.gif" style="width:1000px;height:auto" class="img_ev3q"></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><p>Object tracking is a task that involves identifying the location and class of objects, then assigning a unique ID to that detection in video streams.</p><p>Basically the output of object tracking is the same as object detection with an added object ID.</p><p>Reference: <a href="https://docs.ultralytics.com/modes/track" target="_blank" rel="noopener noreferrer">https://docs.ultralytics.com/modes/track</a></p><p>You can choose your desired model based on object detection/ image segmentation and execute the below command to run inference on an video</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo track model=yolov8n.pt source=&quot;https://youtu.be/Zgi9g1ksQHc&quot;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Here for model, you can change to either yolov8n.pt, yolov8s.pt, yolov8m.pt, yolov8l.pt, yolov8x.pt, yolov8n-seg.pt, yolov8s-seg.pt, yolov8m-seg.pt, yolov8l-seg.pt, yolov8x-seg.pt, and it will download the relavant pre-trained model</p><p>You can also connect a webcam and execute the below command </p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo track model=yolov8n.pt source=&quot;0&quot;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_S0QG"><p>If you face any errors when executing the above commands, try adding &quot;device=0&quot; at the end of the command</p></div></div><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/6.gif" style="width:1000px;height:auto" class="img_ev3q"></div><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/7.gif" style="width:1000px;height:auto" class="img_ev3q"></div></div></div></div><hr><h2 class="anchor anchorWithStickyNavbar_LWe7" id="use-tensorrt-to-improve-inference-speed">Use TensorRT to Improve Inference Speed<a href="#use-tensorrt-to-improve-inference-speed" class="hash-link" aria-label="Direct link to Use TensorRT to Improve Inference Speed" title="Direct link to Use TensorRT to Improve Inference Speed">​</a></h2><p>As we mentioned before, if you want to improve the inference speed on the Jetson running YOLOv8 models, you first need to convert the original PyTorch models to TensorRT models. </p><p>Follow the steps below to convert YOLOv8 PyTorch models to TensorRT models.</p><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_S0QG"><p>This works for all four computer vision tasks that we have mentioned before</p></div></div><ul><li><strong>Step 1.</strong> Execute the export command by specifying the model path</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo export model=&lt;path_to_pt_file&gt; format=engine device=0</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>For example:</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo export model=yolov8n.pt format=engine device=0</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_S0QG"><p>If you, encouter an error about cmake, you can ignore it. Please be patient until the TensorRT export is finished. It might take a few minutes</p></div></div><p>After the TensorRT model file (.engine) is created, you will see the output as follows</p><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/1.jpg" style="width:800px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 2.</strong> If you want to pass additional arguments, you can do so by following the below table</li></ul><table><thead><tr><th>Key</th><th>Value</th><th>Description</th></tr></thead><tbody><tr><td>imgsz</td><td>640</td><td>Image size as scalar or (h, w) list, i.e. (640, 480)</td></tr><tr><td>half</td><td>False</td><td>FP16 quantization</td></tr><tr><td>dynamic</td><td>False</td><td>Dynamic axes</td></tr><tr><td>simplify</td><td>False</td><td>Simplify model</td></tr><tr><td>workspace</td><td>4</td><td>Workspace size (GB)</td></tr></tbody></table><p>For example, if you want to convert your PyTorch model into a TensorRT model in FP16 quantization, execute as</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo export model=yolov8n.pt format=engine half=True device=0</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Once the model is exported successfully, you can directly replace this model with <strong>model=</strong> argument inside <strong>predict</strong> command of <strong>yolo</strong> when running all 4 tasks of detection, classification, segmentation, pose estimation.</p><p>For example, with object detection:</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo detect predict model=yolov8n.engine source=&#x27;0&#x27; show=True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="bring-your-own-ai-model">Bring Your Own AI Model<a href="#bring-your-own-ai-model" class="hash-link" aria-label="Direct link to Bring Your Own AI Model" title="Direct link to Bring Your Own AI Model">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="data-collection-and-labelling">Data Collection and Labelling<a href="#data-collection-and-labelling" class="hash-link" aria-label="Direct link to Data Collection and Labelling" title="Direct link to Data Collection and Labelling">​</a></h3><p>If you have a specific AI application and want to bring your own AI model that is suitable for your application, you can collect your own dataset, label them and then train using YOLOv8. </p><p>If you do not want to collect data by yourself, you can also choose public datasets which are readily available. You can download a number of publically available datasets such as the <a href="https://cocodataset.org" target="_blank" rel="noopener noreferrer">COCO dataset</a>, <a href="http://host.robots.ox.ac.uk/pascal/VOC" target="_blank" rel="noopener noreferrer">Pascal VOC dataset</a> and much more. <a href="https://universe.roboflow.com" target="_blank" rel="noopener noreferrer">Roboflow Universe</a> is a recommended platform which provides a wide-range of datasets and it has <a href="https://blog.roboflow.com/computer-vision-datasets-and-apis" target="_blank" rel="noopener noreferrer">90,000+ datasets with 66+ million images</a> available for building computer vision models. Also, you can simply search open-source datasets on Google and choose from a variety of datasets available.</p><p>If you have your own dataset and want to annotate the images, we recommend you to use the annotation tool provided by <a href="https://roboflow.com" target="_blank" rel="noopener noreferrer">Roboflow</a>. Please follow <a href="https://wiki.seeedstudio.com/YOLOv5-Object-Detection-Jetson/#annotate-dataset-using-roboflow" target="_blank" rel="noopener noreferrer">this part of the wiki</a> to learn more about it. You can also follow <a href="https://docs.roboflow.com/annotate/use-roboflow-annotate" target="_blank" rel="noopener noreferrer">this guide</a> from Roboflow about annotation. </p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="training">Training<a href="#training" class="hash-link" aria-label="Direct link to Training" title="Direct link to Training">​</a></h3><p>Here we have 3 methods to train a model. </p><ol><li><p>First way would be to use <a href="https://ultralytics.com/hub" target="_blank" rel="noopener noreferrer">Ultralytics HUB</a>. You can easily integrate Roboflow into Ultralytics HUB so that all your Roboflow projects will be readily available for training. Here it offers a Google Colab notebook to easily start the training process and also view the training progress in real-time. </p></li><li><p>Second way would be to use a Google Colab workspace created by us to make the training process easier. Here we use Roboflow API to download the dataset from Roboflow project.</p></li><li><p>Third way would be to use a local PC for the training process. Here you need to make sure you have a powerful enough GPU and also need to manually download the dataset.</p></li></ol><div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Ultralytics HUB + Roboflow + Google Colab</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Roboflow + Google Colab</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Roboflow + Local PC</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><p>Here we use Ultralytics HUB to load the Roboflow project and then train on Google Colab.</p><ul><li><p><strong>Step 1.</strong> Visit <a href="https://hub.ultralytics.com/signup" target="_blank" rel="noopener noreferrer">this URL</a> and sign up for an Ultralytics account</p></li><li><p><strong>Step 2.</strong> Once you sign in with the newly created account, you will be greeted with the following dashboard</p></li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/2.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><p><strong>Step 3.</strong> Visit <a href="https://app.roboflow.com/login" target="_blank" rel="noopener noreferrer">this URL</a> and sign up for a Roboflow account</p></li><li><p><strong>Step 4.</strong> Once you sign in with the newly created account, you will be greeted with the following dashboard</p></li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/11.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><p><strong>Step 5.</strong> Create a new workspace and create a new project under the workspace by following <a href="https://wiki.seeedstudio.com/YOLOv5-Object-Detection-Jetson/#annotate-dataset-using-roboflow" target="_blank" rel="noopener noreferrer">this wiki guide</a> we have prepared. You can also <a href="https://blog.roboflow.com/getting-started-with-roboflow" target="_blank" rel="noopener noreferrer">check here</a> to learn more from official Roboflow documentation.</p></li><li><p><strong>Step 6.</strong> Once you have a couple of projects inside your workspace, it will look like below </p></li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/12.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 7.</strong> Go to <strong>Settings</strong> and click <strong>Roboflow API</strong></li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/13.jpg" style="width:300px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 8.</strong> Click the <strong>copy</strong> button to copy the <strong>Private API Key</strong></li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/14.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 9.</strong> Come back to Ultralytics HUB dashboard, click on <strong>Integrations</strong>, paste the API Key we copied before into the empty column and click <strong>Add</strong></li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/15.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 10</strong> If you see your workspace name listed, that means the integration is successful</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/16.jpg" style="width:550px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 11</strong> Navigate to <strong>Datasets</strong> and you will see all your Roboflow projects here</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/17.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 12</strong> Click on a project to check more about the dataset. Here I have selected a dataset which can detect healthy and damaged apples</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/18.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 13</strong> Click <strong>Train Model</strong></li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/19.jpg" style="width:500px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 14</strong> Select the <strong>Architecture</strong>, set a <strong>Model name (optional)</strong> and then click <strong>Continue</strong>. Here we have selected YOLOv8s as the model architecture</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/22.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 15</strong> Under <strong>Advanced options</strong>, configure the settings as to your preference, copy and past the Colab code (this will be pasted late into Colab workspace) and then click <strong>Open Google Colab</strong></li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/24.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 16</strong> Sign in to your Google account if you have not already signed in</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/25.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 17</strong> Navigate to <code>Runtime &gt; Change runtime type</code></li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/26.jpg" style="width:500px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 18</strong> Select <strong>GPU</strong> under <strong>Hardware accelerator</strong>, the highest available under <strong>GPU type</strong> and click <strong>Save</strong></li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/27.jpg" style="width:500px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 19</strong> Click <strong>Connect</strong></li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/28.jpg" style="width:250px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 20</strong> Click on <strong>RAM, Disk</strong> button to check the hardware resource usage</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/31.jpg" style="width:600px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 21</strong> Click on the <strong>Play</strong> button to run the first code cell</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/29.jpg" style="width:750px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 22</strong> Paste the code cell we copied from Ultralytics HUB before under the <strong>Start</strong> section and run it to start training </li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/30.jpg" style="width:650px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 23</strong> Now if you go back to Ultralytics HUB, you will see the message <strong>Connected</strong>. Click <strong>Done</strong></li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/32.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 24</strong> Here you will see <strong>Box Loss, Class Loss and Object Loss</strong> in real-time as the model is training on Google Colab</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/33.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 25</strong> After the training is finished, you will see the following output on Google Colab</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/34.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 26</strong> Now go back to Ultralytics HUB, go to <strong>Preview</strong> tab and upload a test image to check how the trained model is performing</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/35.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 26</strong> Finally go to <strong>Deploy</strong> tab and download the trained model in the format you prefer to inference with YOLOv8. Here we have chosen PyTorch.</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/36.png" style="width:1000px;height:auto" class="img_ev3q"></div><p>Now you can use this downloaded model with the tasks that we have explained in this wiki before. You just need to replace the model file with your model.</p><p>For example:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo detect predict model=&lt;your_model.pt&gt; source=&#x27;0&#x27; show=True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><p>Here we use a Google Colaboratory environment to perform training on the cloud. Furthermore, we use Roboflow api within Colab to easily download our dataset.</p><ul><li><strong>Step 1.</strong> Click <a href="https://colab.research.google.com/gist/lakshanthad/9fbe33058cb7cab49ac8fc345143d849/yolov5-training-for-jetson.ipynb" target="_blank" rel="noopener noreferrer">here</a> to open an already prepared Google Colab workspace and go through the steps mentioned in the workspace</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/39.jpg" style="width:800px;height:auto" class="img_ev3q"></div><p>After the training is done, you will see an output as follows:</p><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/40.jpg" style="width:800px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 2.</strong> Under Files tab, if you navigate to <code>runs/train/exp/weights</code>, you will see a file called <strong>best.pt</strong>. This is the generated model from training. Download this file and copy to your Jetson device because this is the model we are going to use later for inferencing on the Jetson device.</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/41.jpg" style="width:500px;height:auto" class="img_ev3q"></div><p>Now you can use this downloaded model with the tasks that we have explained in this wiki before. You just need to replace the model file with your model.</p><p>For example:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo detect predict model=&lt;your_model.pt&gt; source=&#x27;0&#x27; show=True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><p>Here you can use a PC with a Linux OS for training. We have used an Ubuntu 20.04 PC for this wiki.</p><ul><li><strong>Step 1.</strong> Install pip if you do not have pip in your system</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt install python3-pip -y</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 2.</strong> Install Ultralytics along with dependencies</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip install ultralytics</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 3.</strong> On Roboflow, inside your project, go to <strong>Versions</strong>, select <strong>Export Dataset</strong>, select <strong>Format</strong> as <strong>YOLOv8</strong>, choose <strong>download zip to computer</strong> and click <strong>Continue</strong></li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/42.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><p><strong>Step 4.</strong> Extract the downloaded zip file</p></li><li><p><strong>Step 5.</strong> Execute the following to start training. Here you need to replace <strong>path_to_yaml</strong> with the .yaml file location which is inside the extracted zip file before</p></li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo train data=&lt;path_to_yaml&gt; model=yolov8s.pt epochs=100 imgsz=640 batch=-1</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_S0QG"><p>Here the image size is set to 640x640. We use batch-size as -1 because that will automatically determine the best batch size. You can also change epoch according to your preference. Here you can change the pre-trained model to any detect, segment, classify, pose model.</p></div></div><p>After the training is done, you will see an output as follows:</p><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/43.png" style="width:1000px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 6.</strong> Under <strong>runs/detect/train/weights</strong>, you will see a file called <strong>best.pt</strong>. This is the generated model from training. Download this file and copy to your Jetson device because this is the model we are going to use later for inferencing on the Jetson device.</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/44.png" style="width:500px;height:auto" class="img_ev3q"></div><p>Now you can use this downloaded model with the tasks that we have explained in this wiki before. You just need to replace the model file with your model.</p><p>For example:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo detect predict model=&lt;your_model.pt&gt; source=&#x27;0&#x27; show=True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></div><hr><h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance-benchmarks">Performance Benchmarks<a href="#performance-benchmarks" class="hash-link" aria-label="Direct link to Performance Benchmarks" title="Direct link to Performance Benchmarks">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="preparation">Preparation<a href="#preparation" class="hash-link" aria-label="Direct link to Preparation" title="Direct link to Preparation">​</a></h3><p>We have done performance benchmarks for all computer vision tasks supported by YOLOv8 running on reComputer J4012/ reComputer Industrial J4012 powered by NVIDIA Jetson Orin NX 16GB module. </p><p>Included in the samples directory is a command-line wrapper tool called <a href="https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#trtexec" target="_blank" rel="noopener noreferrer">trtexec</a>. trtexec is a tool to use TensorRT without having to develop your own application. The trtexec tool has three main purposes:</p><ul><li>Benchmarking networks on random or user-provided input data.</li><li>Generating serialized engines from models.</li><li>Generating a serialized timing cache from the builder.</li></ul><p>Here we can use trtexec tool to quickly benchmark the models with different parameter. But first of all, you need to have an onnx model and we can genrate this onnx model by using ultralytics yolov8.</p><ul><li><strong>Step 1.</strong> Build ONNX using:</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">yolo mode=export model=yolov8s.pt format=onnx</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 2.</strong> Build engine file using trtexec as follows:</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd /usr/src/tensorrt/bin</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">./trtexec --onnx=&lt;path_to_onnx_file&gt; --saveEngine=&lt;path_to_save_engine_file&gt;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>For example:</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">./trtexec --onnx=/home/nvidia/yolov8s.onnx --saveEngine=/home/nvidia/yolov8s.engine</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This will output performance results as follows along with a generated .engine file. By default it will convert ONNX to an TensorRT optimized file in FP32 precision and you can see the output as follows</p><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/46.jpg" style="width:1000px;height:auto" class="img_ev3q"></div><p>If you want <strong>FP16</strong> precision which offers better performance than <strong>FP32</strong>, you can execute the above command as follows</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">./trtexec --onnx=/home/nvidia/yolov8s.onnx --fp16 --saveEngine=/home/nvidia/yolov8s.engine </span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>However, if you want <strong>INT8</strong> precision which offers better performance than <strong>FP16</strong>, you can execute the above command as follows</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">./trtexec --onnx=/home/nvidia/yolov8s.onnx --int8 --saveEngine=/home/nvidia/yolov8s.engine </span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="results">Results<a href="#results" class="hash-link" aria-label="Direct link to Results" title="Direct link to Results">​</a></h3><p>Below we summarize the results that we get from all the four computer vision tasks running on reComputer J4012/ reComputer Industrial J4012.</p><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/45.png" style="width:1000px;height:auto" class="img_ev3q"></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="bonus-demo-exercise-detector-and-counter-with-yolov8">Bonus Demo: Exercise Detector and Counter with YOLOv8<a href="#bonus-demo-exercise-detector-and-counter-with-yolov8" class="hash-link" aria-label="Direct link to Bonus Demo: Exercise Detector and Counter with YOLOv8" title="Direct link to Bonus Demo: Exercise Detector and Counter with YOLOv8">​</a></h2><p>We have built a pose estimation demo application for exercise detection and counting with YOLOv8 using YOLOv8-Pose model. You can check the project <a href="https://github.com/yuyoujiang/Exercise-Counter-with-YOLOv8-on-NVIDIA-Jetson" target="_blank" rel="noopener noreferrer">here</a> to learn more about this demo and deploy on your own Jetson device!</p><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/YOLOV8-TRT/9.gif" style="width:1000px;height:auto" class="img_ev3q"></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="manual-set-up-of-yolov8-for-nvidia-jetson">Manual Set Up of YOLOv8 for NVIDIA Jetson<a href="#manual-set-up-of-yolov8-for-nvidia-jetson" class="hash-link" aria-label="Direct link to Manual Set Up of YOLOv8 for NVIDIA Jetson" title="Direct link to Manual Set Up of YOLOv8 for NVIDIA Jetson">​</a></h2><p>If the one-line script we mentioned before has some errors, you can go through the below steps one-by-one to prepare the Jetson device with YOLOv8.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="install-ultralytics-package">Install Ultralytics Package<a href="#install-ultralytics-package" class="hash-link" aria-label="Direct link to Install Ultralytics Package" title="Direct link to Install Ultralytics Package">​</a></h3><ul><li><strong>Step 1.</strong> Access the terminal of Jetson device, install pip and upgrade it</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt update</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt install -y python3-pip -y</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install --upgrade pip</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 2.</strong>  Install Ultralytics package</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install ultralytics</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 3.</strong>  Upgrade numpy version to latest</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install numpy -U</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 4.</strong> Reboot the device</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo reboot</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="uninstall-torch-and-torchvision">Uninstall Torch and Torchvision<a href="#uninstall-torch-and-torchvision" class="hash-link" aria-label="Direct link to Uninstall Torch and Torchvision" title="Direct link to Uninstall Torch and Torchvision">​</a></h3><p>The above ultralytics installation will install Torch and Torchvision. However, these 2 packages installed via pip are not compatible to run on Jetson platform wwhich is based on <strong>ARM aarch64 architecture</strong>. Therefore we need to manually install pre-built PyTorch pip wheel and compile/ install Torchvision from source.</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 uninstall torch torchvision</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="install-pytorch-and-torchvision">Install PyTorch and Torchvision<a href="#install-pytorch-and-torchvision" class="hash-link" aria-label="Direct link to Install PyTorch and Torchvision" title="Direct link to Install PyTorch and Torchvision">​</a></h3><p>Visit <a href="https://forums.developer.nvidia.com/t/pytorch-for-jetson" target="_blank" rel="noopener noreferrer">this page</a> to access all the PyTorch and Torchvision links.</p><p>Here are some of the versions supported by JetPack 5.0 and above.</p><p><strong>PyTorch v2.0.0</strong></p><p>Supported by JetPack 5.1 (L4T R35.2.1) / JetPack 5.1.1 (L4T R35.3.1) with Python 3.8</p><p><strong>file_name:</strong> torch-2.0.0+nv23.05-cp38-cp38-linux_aarch64.whl
<strong>URL:</strong> <a href="https://nvidia.box.com/shared/static/i8pukc49h3lhak4kkn67tg9j4goqm0m7.whl" target="_blank" rel="noopener noreferrer">https://nvidia.box.com/shared/static/i8pukc49h3lhak4kkn67tg9j4goqm0m7.whl</a></p><p><strong>PyTorch v1.13.0</strong></p><p>Supported by JetPack 5.0 (L4T R34.1) / JetPack 5.0.2 (L4T R35.1) / JetPack 5.1 (L4T R35.2.1) / JetPack 5.1.1 (L4T R35.3.1) with Python 3.8</p><p><strong>file_name:</strong> torch-1.13.0a0+d0d6b1f2.nv22.10-cp38-cp38-linux_aarch64.whl
<strong>URL:</strong> <a href="https://developer.download.nvidia.com/compute/redist/jp/v502/pytorch/torch-1.13.0a0+d0d6b1f2.nv22.10-cp38-cp38-linux_aarch64.whl" target="_blank" rel="noopener noreferrer">https://developer.download.nvidia.com/compute/redist/jp/v502/pytorch/torch-1.13.0a0+d0d6b1f2.nv22.10-cp38-cp38-linux_aarch64.whl</a></p><ul><li><strong>Step 1.</strong> Install torch according to your JetPack version in the following format
pip3 </li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget &lt;URL&gt; -O &lt;file_name&gt;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install &lt;file_name&gt;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>For example, here we are running <strong>JP5.1.1</strong> and therefore we choose <strong>PyTorch v2.0.0</strong></p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt-get install -y libopenblas-base libopenmpi-dev</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget https://nvidia.box.com/shared/static/i8pukc49h3lhak4kkn67tg9j4goqm0m7.whl -O torch-2.0.0+nv23.05-cp38-cp38-linux_aarch64.whl</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install torch-2.0.0+nv23.05-cp38-cp38-linux_aarch64.whl</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 2.</strong> Install torchvision depending on the version of PyTorch that you have installed. For example, we chose PyTorch v2.0.0, which means, we need to choose Torchvision v0.15.2</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt install -y libjpeg-dev zlib1g-dev</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">git clone https://github.com/pytorch/vision torchvision</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd torchvision</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">git checkout v0.15.2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">python3 setup.py install --user</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Here is a list of the corresponding torchvision version that you need to install according to the PyTorch version:</p><ul><li>PyTorch v2.0.0 - torchvision v0.15</li><li>PyTorch v1.13.0 - torchvision v0.14</li></ul><p>If you want a more detailed list, please check <a href="https://github.com/pytorch/vision" target="_blank" rel="noopener noreferrer">this link</a>.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="install-onnx-and-downgrade-numpy">Install ONNX and Downgrade Numpy<a href="#install-onnx-and-downgrade-numpy" class="hash-link" aria-label="Direct link to Install ONNX and Downgrade Numpy" title="Direct link to Install ONNX and Downgrade Numpy">​</a></h3><p>This is only needed if you want to convert the PyTorch models to TensorRT</p><ul><li><strong>Step 1.</strong> Install ONNX which is a requirement</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install onnx</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 2.</strong> Downgrade to lower version of Numpy to fix an error</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install numpy==1.20.3</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="resources">Resources<a href="#resources" class="hash-link" aria-label="Direct link to Resources" title="Direct link to Resources">​</a></h2><ul><li><a href="https://docs.ultralytics.com" target="_blank" rel="noopener noreferrer">YOLOv8 documentation</a></li><li><a href="https://docs.roboflow.com" target="_blank" rel="noopener noreferrer">Roboflow documentation</a></li><li><a href="https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html" target="_blank" rel="noopener noreferrer">TensorRT documentation</a></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="tech-support--product-discussion">Tech Support &amp; Product Discussion<a href="#tech-support--product-discussion" class="hash-link" aria-label="Direct link to Tech Support &amp; Product Discussion" title="Direct link to Tech Support &amp; Product Discussion">​</a></h2><p>Thank you for choosing our products! We are here to provide you with different support to ensure that your experience with our products is as smooth as possible. We offer several communication channels to cater to different preferences and needs.</p><div class="button_tech_support_container"><a href="https://forum.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="button_forum"></a><a href="https://www.seeedstudio.com/contacts" target="_blank" rel="noopener noreferrer" class="button_email"></a></div><div class="button_tech_support_container"><a href="https://discord.gg/eWkprNDMU7" target="_blank" rel="noopener noreferrer" class="button_discord"></a><a href="https://github.com/Seeed-Studio/wiki-documents/discussions/69" target="_blank" rel="noopener noreferrer" class="button_discussion"></a></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/data-label/">Data Label</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/ai-model-train/">AI model train</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/ai-model-deploy/">AI model deploy</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/yolov-8/">Yolov8</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/Seeed-Studio/wiki-documents/blob/docusaurus-version/docs/Edge/NVIDIA_Jetson/Application/Computer_Vision/YOLOv8-TRT-Jetson.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2023-07-17T00:00:00.000Z">Jul 17, 2023</time></b> by <b>Lakshantha</b></span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/YOLOv8-DeepStream-TRT-Jetson/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Deploy YOLOv8 with TensorRT and DeepStream SDK</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/reComputer_Jetson_Series_Tutorials_Exercise/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">reComputer for Jetson Tutorials and Exercise</div></a></nav></div><div>Loading Comments...</div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#prerequisites" class="table-of-contents__link toc-highlight">Prerequisites</a></li><li><a href="#flash-jetpack-to-jetson" class="table-of-contents__link toc-highlight">Flash JetPack to Jetson</a></li><li><a href="#deploy-yolov8-to-jetson-in-one-line-of-code" class="table-of-contents__link toc-highlight">Deploy YOLOV8 to Jetson in One Line of Code!</a></li><li><a href="#use-pre-trained-models" class="table-of-contents__link toc-highlight">Use Pre-trained models</a></li><li><a href="#use-tensorrt-to-improve-inference-speed" class="table-of-contents__link toc-highlight">Use TensorRT to Improve Inference Speed</a></li><li><a href="#bring-your-own-ai-model" class="table-of-contents__link toc-highlight">Bring Your Own AI Model</a><ul><li><a href="#data-collection-and-labelling" class="table-of-contents__link toc-highlight">Data Collection and Labelling</a></li><li><a href="#training" class="table-of-contents__link toc-highlight">Training</a></li></ul></li><li><a href="#performance-benchmarks" class="table-of-contents__link toc-highlight">Performance Benchmarks</a><ul><li><a href="#preparation" class="table-of-contents__link toc-highlight">Preparation</a></li><li><a href="#results" class="table-of-contents__link toc-highlight">Results</a></li></ul></li><li><a href="#bonus-demo-exercise-detector-and-counter-with-yolov8" class="table-of-contents__link toc-highlight">Bonus Demo: Exercise Detector and Counter with YOLOv8</a></li><li><a href="#manual-set-up-of-yolov8-for-nvidia-jetson" class="table-of-contents__link toc-highlight">Manual Set Up of YOLOv8 for NVIDIA Jetson</a><ul><li><a href="#install-ultralytics-package" class="table-of-contents__link toc-highlight">Install Ultralytics Package</a></li><li><a href="#uninstall-torch-and-torchvision" class="table-of-contents__link toc-highlight">Uninstall Torch and Torchvision</a></li><li><a href="#install-pytorch-and-torchvision" class="table-of-contents__link toc-highlight">Install PyTorch and Torchvision</a></li><li><a href="#install-onnx-and-downgrade-numpy" class="table-of-contents__link toc-highlight">Install ONNX and Downgrade Numpy</a></li></ul></li><li><a href="#resources" class="table-of-contents__link toc-highlight">Resources</a></li><li><a href="#tech-support--product-discussion" class="table-of-contents__link toc-highlight">Tech Support &amp; Product Discussion</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Navigation</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/Getting_Started/">Getting Started</a></li><li class="footer__item"><a class="footer__link-item" href="/Sensor_Network/">Sensor and Sensing</a></li><li class="footer__item"><a class="footer__link-item" href="/Network/">Network</a></li><li class="footer__item"><a class="footer__link-item" href="/Edge_Computing/">Edge Computing</a></li><li class="footer__item"><a class="footer__link-item" href="/Cloud/">Cloud</a></li><li class="footer__item"><a class="footer__link-item" href="/Solutions/">Solutions</a></li></ul></div><div class="col footer__col"><div class="footer__title">Ecosystem</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.com/invite/QqMgVwHT3X" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord</a></li><li class="footer__item"><a href="https://project.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Project Hub</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/ecosystem/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Partners</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/distributors.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Distributors</a></li></ul></div><div class="col footer__col"><div class="footer__title">Quick Guide</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Bazzar</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/get_help/HowToGetHelp" target="_blank" rel="noopener noreferrer" class="footer__link-item">How to get help</a></li><li class="footer__item"><a href="https://support.seeedstudio.com/knowledgebase" target="_blank" rel="noopener noreferrer" class="footer__link-item">FAQs</a></li><li class="footer__item"><a href="https://forum.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Forum</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/get_help/TechnicalSupport" target="_blank" rel="noopener noreferrer" class="footer__link-item">Technical Support</a></li></ul></div><div class="col footer__col"><div class="footer__title">Company</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.seeedstudio.com/about-us/" target="_blank" rel="noopener noreferrer" class="footer__link-item">About Seeed</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/join-us/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Join us</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/contacts" target="_blank" rel="noopener noreferrer" class="footer__link-item">Contact Us</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/blog/2020/04/22/seeed-in-the-news/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Press</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Seeed Studio, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.001b1c61.js"></script>
<script src="/assets/js/main.5e3b5140.js"></script>
</body>
</html>