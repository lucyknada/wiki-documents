"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[52073],{15680:(e,t,o)=>{o.d(t,{xA:()=>s,yg:()=>u});var n=o(96540);function a(e,t,o){return t in e?Object.defineProperty(e,t,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[t]=o,e}function l(e,t){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),o.push.apply(o,n)}return o}function i(e){for(var t=1;t<arguments.length;t++){var o=null!=arguments[t]?arguments[t]:{};t%2?l(Object(o),!0).forEach((function(t){a(e,t,o[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):l(Object(o)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(o,t))}))}return e}function r(e,t){if(null==e)return{};var o,n,a=function(e,t){if(null==e)return{};var o,n,a={},l=Object.keys(e);for(n=0;n<l.length;n++)o=l[n],t.indexOf(o)>=0||(a[o]=e[o]);return a}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)o=l[n],t.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(a[o]=e[o])}return a}var p=n.createContext({}),d=function(e){var t=n.useContext(p),o=t;return e&&(o="function"==typeof e?e(t):i(i({},t),e)),o},s=function(e){var t=d(e.components);return n.createElement(p.Provider,{value:t},e.children)},m="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},y=n.forwardRef((function(e,t){var o=e.components,a=e.mdxType,l=e.originalType,p=e.parentName,s=r(e,["components","mdxType","originalType","parentName"]),m=d(o),y=a,u=m["".concat(p,".").concat(y)]||m[y]||c[y]||l;return o?n.createElement(u,i(i({ref:t},s),{},{components:o})):n.createElement(u,i({ref:t},s))}));function u(e,t){var o=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var l=o.length,i=new Array(l);i[0]=y;var r={};for(var p in t)hasOwnProperty.call(t,p)&&(r[p]=t[p]);r.originalType=e,r[m]="string"==typeof e?e:a,i[1]=r;for(var d=2;d<l;d++)i[d]=o[d];return n.createElement.apply(null,i)}return n.createElement.apply(null,o)}y.displayName="MDXCreateElement"},69766:(e,t,o)=>{o.r(t),o.d(t,{assets:()=>p,contentTitle:()=>i,default:()=>c,frontMatter:()=>l,metadata:()=>r,toc:()=>d});var n=o(58168),a=(o(96540),o(15680));const l={description:"YOLOv5 from training to deployment",title:"Train and deploy the YOLOv5 object detection model",keywords:["YOLOv5","we2","object detection"],image:"https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png",slug:"/ma_deploy_yolov5",last_update:{date:"04/02/2024",author:"Jack Mu"}},i="Deploy YOLOv5 object detection model",r={unversionedId:"Topics/TinyML/ModelAssistant/deploy/ma_deploy_yolov5",id:"Topics/TinyML/ModelAssistant/deploy/ma_deploy_yolov5",title:"Train and deploy the YOLOv5 object detection model",description:"YOLOv5 from training to deployment",source:"@site/docs/Topics/TinyML/ModelAssistant/deploy/ma_deploy_yolov5.md",sourceDirName:"Topics/TinyML/ModelAssistant/deploy",slug:"/ma_deploy_yolov5",permalink:"/ma_deploy_yolov5",draft:!1,editUrl:"https://github.com/Seeed-Studio/wiki-documents/blob/docusaurus-version/docs/Topics/TinyML/ModelAssistant/deploy/ma_deploy_yolov5.md",tags:[],version:"current",lastUpdatedBy:"Jack Mu",lastUpdatedAt:1712016e3,formattedLastUpdatedAt:"Apr 2, 2024",frontMatter:{description:"YOLOv5 from training to deployment",title:"Train and deploy the YOLOv5 object detection model",keywords:["YOLOv5","we2","object detection"],image:"https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png",slug:"/ma_deploy_yolov5",last_update:{date:"04/02/2024",author:"Jack Mu"}},sidebar:"ProductSidebar",previous:{title:"Deployment",permalink:"/ModelAssistant_Deploy_Overview"},next:{title:"Train and deploy the YOLOv8 object detection model",permalink:"/ma_deploy_yolov8"}},p={},d=[{value:"Dataset preparation",id:"dataset-preparation",level:2},{value:"Clone YOLOv5 official repository",id:"clone-yolov5-official-repository",level:2},{value:"Train",id:"train",level:2},{value:"Export model to tflite",id:"export-model-to-tflite",level:2},{value:"Model graph optimization",id:"model-graph-optimization",level:3},{value:"Deploy",id:"deploy",level:2}],s={toc:d},m="wrapper";function c(e){let{components:t,...o}=e;return(0,a.yg)(m,(0,n.A)({},s,o,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("h1",{id:"deploy-yolov5-object-detection-model"},"Deploy YOLOv5 object detection model"),(0,a.yg)("div",{style:{textAlign:"center"}},(0,a.yg)("img",{src:"https://files.seeedstudio.com/sscma/static/detection_person_yolov5.png",style:{width:600,height:"auto"}})),(0,a.yg)("p",null,"This wiki will introduce how to train the official YOLOv5 target detection model and deploy the trained model to ",(0,a.yg)("inlineCode",{parentName:"p"},"Grove Vision AI(V2)")," or ",(0,a.yg)("inlineCode",{parentName:"p"},"XIAO ESP32S3")," devices."),(0,a.yg)("h2",{id:"dataset-preparation"},"Dataset preparation"),(0,a.yg)("p",null,"It is recommended to use the ",(0,a.yg)("a",{parentName:"p",href:"https://universe.roboflow.com/"},"roboflow")," platform for data sets. This platform can perform data set annotation and some data enhancement strategies, and supports the export of multiple data set formats. You can view the yolov5 data set preparation ",(0,a.yg)("a",{parentName:"p",href:"https://docs.ultralytics.com/zh/yolov5/tutorials/train_custom_data/"},"Introduction")),(0,a.yg)("h2",{id:"clone-yolov5-official-repository"},"Clone YOLOv5 official repository"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"By default, you already have the python environment and pip package management tool and python>=3.8.")),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-bash"},"# Clone YOLOv5 official repository\ngit clone https://github.com/ultralytics/yolov5\n")),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Install the required environment")),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-bash"},"# Cut to the YOLOv5 folder\ncd yolov5\n# Use pip to install required dependencies\npip install -r requirements.txt\n")),(0,a.yg)("h2",{id:"train"},"Train"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Execute the following command to start training the model")),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-bash"},"python train.py  --weights yolov5n.pt --data ${dataset yaml file path} --imgsz 192\n")),(0,a.yg)("h2",{id:"export-model-to-tflite"},"Export model to tflite"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"After training, the model will be in the ",(0,a.yg)("inlineCode",{parentName:"li"},"runs/train/exp*/weights/")," folder. Make sure that the evaluation indicators of your model meet your needs."),(0,a.yg)("li",{parentName:"ul"},"First export the saved_model format model using the following command")),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-bash"},"python export.py --weights ${Your trained model path (.pt format)}  --imgsz 192 --include saved_model\n")),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Then use the following code to quantify and convert the exported saved_model model into tflite model format")),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},"import tensorflow as tf\nimport os.path as osp\n\n\n\nconverter = tf.lite.TFLiteConverter.from_saved_model(r'Your saved_model folder path')\n\ntflite_model = converter.convert()\n\ndef representative_dataset():\n  for _ in range(100):\n    yield [\n        tf.random.uniform((1, 192, 192\n                           , 3))\n    ]\n\nconverter.optimizations = [\n    tf.lite.Optimize.DEFAULT\n]\nconverter.target_spec.supported_ops = [\n    tf.lite.OpsSet.TFLITE_BUILTINS_INT8\n]\nconverter.inference_input_type = tf.int8\nconverter.inference_output_type = tf.int8\nconverter.representative_dataset = representative_dataset\n\ntflite_quant_model = converter.convert()\n\nwith open(osp.join(r'The location path to be saved','yolov5n_int8.tflite'), 'wb') as f:\n    f.write(tflite_quant_model)\n\n")),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Afterwards, you will see a ",(0,a.yg)("inlineCode",{parentName:"li"},"yolov5n_int8.tflite")," model file under the save path folder of the club,This model file can be deployed to ",(0,a.yg)("inlineCode",{parentName:"li"},"Grove Vision AI(V2)")," or ",(0,a.yg)("inlineCode",{parentName:"li"},"XIAO ESP32S3")," devices..")),(0,a.yg)("h3",{id:"model-graph-optimization"},"Model graph optimization"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Grove Vision AI (V2) supports vela-optimized models and can also accelerate model inference. First, execute the following command to install the vela command line tool (",(0,a.yg)("inlineCode",{parentName:"li"},"XIAO ESP32S3")," device is not supported yet).")),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-bash"},"pip3 install ethos-u-vela\n")),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"After that, you need to ",(0,a.yg)("a",{parentName:"li",href:"https://files.seeedstudio.com/sscma/configs/vela_config.ini"},"download")," ",(0,a.yg)("inlineCode",{parentName:"li"},"vela")," related configuration file, or copy the following content into a file, which can be named ",(0,a.yg)("inlineCode",{parentName:"li"},"vela_config.ini"))),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-bash"},"; file: my_vela_cfg.ini ; ----------------------------------------------------------------------------- \n; Vela configuration file ; ----------------------------------------------------------------------------- \n; System Configuration \n\n; My_Sys_Cfg \n[System_Config.My_Sys_Cfg] \ncore_clock=400e6 \naxi0_port=Sram \naxi1_port=OffChipFlash \nSram_clock_scale=1.0 \nSram_burst_length=32 \nSram_read_latency=16 \nSram_write_latency=16 \nDram_clock_scale=0.75 \nDram_burst_length=128 \nDram_read_latency=500 \nDram_write_latency=250 \nOnChipFlash_clock_scale=0.25 \nOffChipFlash_clock_scale=0.015625 \nOffChipFlash_burst_length=32 \nOffChipFlash_read_latency=64 \nOffChipFlash_write_latency=64 \n; ----------------------------------------------------------------------------- \n; Memory Mode \n; My_Mem_Mode_Parent \n[Memory_Mode.My_Mem_Mode_Parent] \nconst_mem_area=Axi1 \narena_mem_area=Axi0 \ncache_mem_area=Axi0\n")),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Finally, use the following command to optimize the graph")),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-bash"},"vela --accelerator-config ethos-u55-64 \\ \n    --config vela_config.ini \\\n    --system-config My_Sys_Cfg \\\n    --memory-mode My_Mem_Mode_Parent \\\n    --output-dir ${Save path of the optimized model} \\\n    ${The path of the tflite model that needs to be optimized}\n")),(0,a.yg)("h2",{id:"deploy"},"Deploy"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"The model file that needs to be deployed is the ",(0,a.yg)("inlineCode",{parentName:"p"},"tflite")," file exported above. You can burn the model file to the target device according to the following tutorial.")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"We strongly recommend using our web tool to burn the trained tflite model into the device. Detailed operations are provided in the ",(0,a.yg)("a",{parentName:"p",href:"https://wiki.seeedstudio.com/ModelAssistant_Deploy_Overview/"},"Deployment Tutorial")))),(0,a.yg)("p",null,(0,a.yg)("inlineCode",{parentName:"p"},"Note:")," Since the ",(0,a.yg)("inlineCode",{parentName:"p"},"ESP32S3")," device does not support model deployment after ",(0,a.yg)("inlineCode",{parentName:"p"},"vela")," graph optimization, you do not need to perform ",(0,a.yg)("inlineCode",{parentName:"p"},"tflite")," model graph optimization if you want to deploy the model to the ",(0,a.yg)("inlineCode",{parentName:"p"},"XIAO ESP32S3")," device."))}c.isMDXComponent=!0}}]);