"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[60636],{15680:(e,t,n)=>{n.d(t,{xA:()=>c,yg:()=>m});var o=n(96540);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,o,a=function(e,t){if(null==e)return{};var n,o,a={},r=Object.keys(e);for(o=0;o<r.length;o++)n=r[o],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(o=0;o<r.length;o++)n=r[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var l=o.createContext({}),d=function(e){var t=o.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},c=function(e){var t=d(e.components);return o.createElement(l.Provider,{value:t},e.children)},p="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},g=o.forwardRef((function(e,t){var n=e.components,a=e.mdxType,r=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),p=d(n),g=a,m=p["".concat(l,".").concat(g)]||p[g]||u[g]||r;return n?o.createElement(m,i(i({ref:t},c),{},{components:n})):o.createElement(m,i({ref:t},c))}));function m(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var r=n.length,i=new Array(r);i[0]=g;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[p]="string"==typeof e?e:a,i[1]=s;for(var d=2;d<r;d++)i[d]=n[d];return o.createElement.apply(null,i)}return o.createElement.apply(null,n)}g.displayName="MDXCreateElement"},65354:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>u,frontMatter:()=>r,metadata:()=>s,toc:()=>d});var o=n(58168),a=(n(96540),n(15680));const r={description:"Getting Started with SenseCAP Vision AI",title:"Getting Started with SenseCAP Vision AI",keywords:["Sensor Vision_AI"],image:"https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png",slug:"/SenseCAP-Vision-AI-Get-Started",last_update:{date:"1/31/2023",author:"Kewei Li"}},i=void 0,s={unversionedId:"Sensor/SenseCAP/SenseCAP_LoRaWAN_Sensor/SenseCAP_A1101/SenseCAP-Vision-AI-Get-Started",id:"Sensor/SenseCAP/SenseCAP_LoRaWAN_Sensor/SenseCAP_A1101/SenseCAP-Vision-AI-Get-Started",title:"Getting Started with SenseCAP Vision AI",description:"Getting Started with SenseCAP Vision AI",source:"@site/docs/Sensor/SenseCAP/SenseCAP_LoRaWAN_Sensor/SenseCAP_A1101/SenseCAP-Vision-AI-Get-Started.md",sourceDirName:"Sensor/SenseCAP/SenseCAP_LoRaWAN_Sensor/SenseCAP_A1101",slug:"/SenseCAP-Vision-AI-Get-Started",permalink:"/SenseCAP-Vision-AI-Get-Started",draft:!1,editUrl:"https://github.com/Seeed-Studio/wiki-documents/blob/docusaurus-version/docs/Sensor/SenseCAP/SenseCAP_LoRaWAN_Sensor/SenseCAP_A1101/SenseCAP-Vision-AI-Get-Started.md",tags:[],version:"current",lastUpdatedBy:"Kewei Li",lastUpdatedAt:1675123200,formattedLastUpdatedAt:"Jan 31, 2023",frontMatter:{description:"Getting Started with SenseCAP Vision AI",title:"Getting Started with SenseCAP Vision AI",keywords:["Sensor Vision_AI"],image:"https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png",slug:"/SenseCAP-Vision-AI-Get-Started",last_update:{date:"1/31/2023",author:"Kewei Li"}},sidebar:"ProductSidebar",previous:{title:"Getting Started with SenseCAP S2120 8-in-1 LoRaWAN Weather Sensor",permalink:"/Getting_Started_with_SenseCAP_S2120_8-in-1_LoRaWAN_Weather_Sensor"},next:{title:"Train and Deploy Your Own AI Model Into SenseCAP A1101",permalink:"/Train-Deploy-AI-Model-A1101"}},l={},d=[{value:"How to Select Gateway and LoraWAN\xae",id:"how-to-select-gateway-and-lorawan",level:2},{value:"How to use the Sensor",id:"how-to-use-the-sensor",level:2}],c={toc:d},p="wrapper";function u(e){let{components:t,...n}=e;return(0,a.yg)(p,(0,o.A)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("div",{align:"center"},(0,a.yg)("img",{width:400,src:"https://media-cdn.seeedstudio.com/media/catalog/product/cache/bb49d3ec4ee05b6f018e93f896b8a25d/1/0/101990962-a1101-first-new-10.17.jpg"})),(0,a.yg)("div",{class:"get_one_now_container",style:{textAlign:"center"}},(0,a.yg)("a",{class:"get_one_now_item",href:"https://www.seeedstudio.com/SenseCAP-A1101-LoRaWAN-Vision-AI-Sensor-p-5367.html"},(0,a.yg)("strong",null,(0,a.yg)("span",null,(0,a.yg)("font",{color:"FFFFFF",size:"4"}," Get One Now \ud83d\uddb1\ufe0f"))))),(0,a.yg)("h1",{id:"introduction"},"Introduction"),(0,a.yg)("p",null,"SenseCAP A1101 - LoRaWAN Vision AI Sensor is a TinyML Edge AI enabled smart image sensor. It supports a variety of AI models such as image recognition, people counting, target detection, meter recoignition etc. It also supports training models with TensorFlow Lite. ",(0,a.yg)("br",null)),(0,a.yg)("h1",{id:"features"},"Features"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"Ultra-Low Power and Powerful Himax Camara: 400Mhz DSP, Maximum camera frame rate 640",(0,a.yg)("em",{parentName:"p"},"480"),"VGA 60 FPS, Local inferencing")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"Low Power and Long Range Transmission: Down to 2.3uWh sleep mode power consumption, powered by Wio-E5 LoRaWAN Modules, transfers data up to miles")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"High Data Security by Edge Computing: Local image inferencing and transfers the final result data to the Cloud, suitable for applications that require limited data transmission and high data privacy.")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"Easy to Visualize Data: Few clicks to display and manage data via SenseCAP Mate App and SenseCAP Dashboard, wide compatibility with other third-party tools")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"High Industrial Protection Grade: -40 ~ 85\u2103 operating temperature and IP66 rating, suitable for indoor and outdoor deployment")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"Easy for Scalable Deployment: 1min to add and configure the device by scanning the device QR code, low LoRaWAN network cost and maintenance cost ensure business scalability."))),(0,a.yg)("h1",{id:"specification"},"Specification"),(0,a.yg)("p",null,"Please direct you to ",(0,a.yg)("a",{parentName:"p",href:"https://files.seeedstudio.com/wiki/SenseCAP-A1101/SenseCAP_A1101_spec.pdf"},"specification")," for more details."),(0,a.yg)("h1",{id:"getting-started"},"Getting Started"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},"There are several built-in AI models for A1101, and users can select modelsaccording to their needs. Currently, the following algorithms and models are available:")),(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:null},(0,a.yg)("strong",{parentName:"th"},"Algorithm")),(0,a.yg)("th",{parentName:"tr",align:null},(0,a.yg)("strong",{parentName:"th"},"AI Model")))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"Object Detection"),(0,a.yg)("td",{parentName:"tr",align:null},"Human Body Detection;User-defined")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"Object Counting"),(0,a.yg)("td",{parentName:"tr",align:null},"People Counting;User-defined")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:null},"Image Classification"),(0,a.yg)("td",{parentName:"tr",align:null},"Person&Panda Recognition;User-defined")))),(0,a.yg)("p",null,"Model selection and configuration is also done in the Setting interface. First select the Algorithm, different algorithms achieve different functions andshowdifferent results in the APP preview.Clicking on the drop-down triangle behindthealgorithm will bring up the selection box. Then select the AI model, click on the model, the selection box pops up, select themodel."),(0,a.yg)("ol",{start:2},(0,a.yg)("li",{parentName:"ol"},"If you want to train your own AI model, there are two ways. please refer to:")),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"1.",(0,a.yg)("a",{parentName:"strong",href:"https://wiki.seeedstudio.com/One-Stop-Model-Training-with-Edge-Impulse"},"One Stop Model Training with Edge Impulse"))," Fast to follow."),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"2.",(0,a.yg)("a",{parentName:"strong",href:"https://wiki.seeedstudio.com/Train-Deploy-AI-Model-A1101"},"Train AI Model with Roboflow, YOLOv5, TensorFlow Lite"))," Slow to follow."),(0,a.yg)("h1",{id:"connect-to-the-lorawan"},"Connect to the LoraWAN\xae"),(0,a.yg)("p",null,"LoRaWAN\xae (Long Range Wide Area Network) is a wireless communication protocol designed for low-power, long-range communications between IoT (Internet of Things) devices and gateways. It uses unlicensed radio spectrum in the Industrial, Scientific, and Medical (ISM) band, typically at 868 MHz in Europe and 915 MHz in the United States. LoRaWAN\xae provides a low-cost, energy-efficient solution for connecting IoT devices over long distances. The technology allows for bi-directional communication between devices and gateways, and it supports a range of data rates to accommodate different types of applications. "),(0,a.yg)("h2",{id:"how-to-select-gateway-and-lorawan"},"How to Select Gateway and LoraWAN\xae"),(0,a.yg)("p",null,"LoRaWAN\xae network coverage is required when using sensors, there are two options.\n",(0,a.yg)("img",{parentName:"p",src:"https://files.seeedstudio.com/wiki/SenseCAP/SenseCAP_LoRaWAN_S210X_Series/4.png",alt:"p21"})),(0,a.yg)("h2",{id:"how-to-use-the-sensor"},"How to use the Sensor"),(0,a.yg)("p",null,"In addition to connecting directly to a computer to view real-time detection data, you can also transmit these data through LoraWAN\xae and finally upload them to the ",(0,a.yg)("a",{parentName:"p",href:"https://sensecap.seeed.cc/"},"SenseCAP cloud platform")," or a third-party cloud platform. On the SenseCAP cloud platform, you can view the data in a cycle and display it graphically through your mobile phone or computer. The SenseCAP cloud platform and SenseCAP Mate App use the same account system."),(0,a.yg)("p",null,"Since our focus here is on describing the model training process, we won't go into the details of the cloud platform data display. But if you're interested, you can always visit the SenseCAP cloud platform to try adding devices and viewing data. It's a great way to get a better understanding of the platform's capabilities!"),(0,a.yg)("p",null,(0,a.yg)("img",{parentName:"p",src:"https://files.seeedstudio.com/wiki/SenseCAP/SenseCAP_LoRaWAN_S210X_Series/11.png",alt:"p22"})),(0,a.yg)("h1",{id:"tech-support"},"Tech Support"),(0,a.yg)("p",null,"Thank you for choosing our products! We are here to provide you with different support to ensure that your experience with our products is as smooth as possible. We offer several communication channels to cater to different preferences and needs."),(0,a.yg)("div",{class:"button_tech_support_container"},(0,a.yg)("a",{href:"https://forum.seeedstudio.com/",class:"button_forum"}),(0,a.yg)("a",{href:"https://www.seeedstudio.com/contacts",class:"button_email"})),(0,a.yg)("div",{class:"button_tech_support_container"},(0,a.yg)("a",{href:"https://discord.gg/eWkprNDMU7",class:"button_discord"}),(0,a.yg)("a",{href:"https://github.com/Seeed-Studio/wiki-documents/discussions/69",class:"button_discussion"})))}u.isMDXComponent=!0}}]);