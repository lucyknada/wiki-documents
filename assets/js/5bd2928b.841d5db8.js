"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[97879],{15680:(e,n,t)=>{t.d(n,{xA:()=>f,yg:()=>y});var a=t(96540);function i(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function l(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function r(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?l(Object(t),!0).forEach((function(n){i(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):l(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function o(e,n){if(null==e)return{};var t,a,i=function(e,n){if(null==e)return{};var t,a,i={},l=Object.keys(e);for(a=0;a<l.length;a++)t=l[a],n.indexOf(t)>=0||(i[t]=e[t]);return i}(e,n);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(a=0;a<l.length;a++)t=l[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(i[t]=e[t])}return i}var s=a.createContext({}),p=function(e){var n=a.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):r(r({},n),e)),t},f=function(e){var n=p(e.components);return a.createElement(s.Provider,{value:n},e.children)},m="mdxType",d={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},c=a.forwardRef((function(e,n){var t=e.components,i=e.mdxType,l=e.originalType,s=e.parentName,f=o(e,["components","mdxType","originalType","parentName"]),m=p(t),c=i,y=m["".concat(s,".").concat(c)]||m[c]||d[c]||l;return t?a.createElement(y,r(r({ref:n},f),{},{components:t})):a.createElement(y,r({ref:n},f))}));function y(e,n){var t=arguments,i=n&&n.mdxType;if("string"==typeof e||i){var l=t.length,r=new Array(l);r[0]=c;var o={};for(var s in n)hasOwnProperty.call(n,s)&&(o[s]=n[s]);o.originalType=e,o[m]="string"==typeof e?e:i,r[1]=o;for(var p=2;p<l;p++)r[p]=t[p];return a.createElement.apply(null,r)}return a.createElement.apply(null,t)}c.displayName="MDXCreateElement"},19413:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>r,default:()=>d,frontMatter:()=>l,metadata:()=>o,toc:()=>p});var a=t(58168),i=(t(96540),t(15680));const l={description:"YOLOv8 from training to deployment",title:"\u8bad\u7ec3\u90e8\u7f72YOLOv8\u59ff\u6001\u4f30\u8ba1\u6a21\u578b",keywords:["YOLOv8","we2","pose detection"],image:"https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png",slug:"/CN/TinyML/ModelAssistant/Deploy/Deploy_YOLOv8_Pose",last_update:{date:"04/02/2024",author:"\u5927\u5e86"}},r="YOLOv8\u59ff\u6001\u4f30\u8ba1\u6a21\u578b\u90e8\u7f72",o={unversionedId:"zh-CN/TinyML/ModelAssistant/Deploy/cn_ma_deploy_yolov8_pose",id:"zh-CN/TinyML/ModelAssistant/Deploy/cn_ma_deploy_yolov8_pose",title:"\u8bad\u7ec3\u90e8\u7f72YOLOv8\u59ff\u6001\u4f30\u8ba1\u6a21\u578b",description:"YOLOv8 from training to deployment",source:"@site/docs/zh-CN/TinyML/ModelAssistant/Deploy/cn_ma_deploy_yolov8_pose.md",sourceDirName:"zh-CN/TinyML/ModelAssistant/Deploy",slug:"/CN/TinyML/ModelAssistant/Deploy/Deploy_YOLOv8_Pose",permalink:"/CN/TinyML/ModelAssistant/Deploy/Deploy_YOLOv8_Pose",draft:!1,editUrl:"https://github.com/Seeed-Studio/wiki-documents/blob/docusaurus-version/docs/zh-CN/TinyML/ModelAssistant/Deploy/cn_ma_deploy_yolov8_pose.md",tags:[],version:"current",lastUpdatedBy:"\u5927\u5e86",lastUpdatedAt:1712016e3,formattedLastUpdatedAt:"Apr 2, 2024",frontMatter:{description:"YOLOv8 from training to deployment",title:"\u8bad\u7ec3\u90e8\u7f72YOLOv8\u59ff\u6001\u4f30\u8ba1\u6a21\u578b",keywords:["YOLOv8","we2","pose detection"],image:"https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png",slug:"/CN/TinyML/ModelAssistant/Deploy/Deploy_YOLOv8_Pose",last_update:{date:"04/02/2024",author:"\u5927\u5e86"}}},s={},p=[{value:"\u6570\u636e\u96c6\u51c6\u5907",id:"\u6570\u636e\u96c6\u51c6\u5907",level:2},{value:"\u5b89\u88c5YOLOv8\u547d\u4ee4\u884c\u5de5\u5177",id:"\u5b89\u88c5yolov8\u547d\u4ee4\u884c\u5de5\u5177",level:2},{value:"\u8bad\u7ec3",id:"\u8bad\u7ec3",level:2},{value:"\u5bfc\u51fa\u6a21\u578b\u81f3tflite",id:"\u5bfc\u51fa\u6a21\u578b\u81f3tflite",level:2},{value:"\u6a21\u578b\u56fe\u4f18\u5316",id:"\u6a21\u578b\u56fe\u4f18\u5316",level:3},{value:"\u90e8\u7f72",id:"\u90e8\u7f72",level:2}],f={toc:p},m="wrapper";function d(e){let{components:n,...t}=e;return(0,i.yg)(m,(0,a.A)({},f,t,{components:n,mdxType:"MDXLayout"}),(0,i.yg)("h1",{id:"yolov8\u59ff\u6001\u4f30\u8ba1\u6a21\u578b\u90e8\u7f72"},"YOLOv8\u59ff\u6001\u4f30\u8ba1\u6a21\u578b\u90e8\u7f72"),(0,i.yg)("div",{style:{textAlign:"center"}},(0,i.yg)("img",{src:"https://files.seeedstudio.com/sscma/static/detection_pose.png",style:{width:600,height:"auto"}})),(0,i.yg)("p",null,"\u6b64wiki\u5c06\u4ecb\u7ecd\u5982\u4f55\u8bad\u7ec3\u5b98\u65b9\u7684YOLOv8\u59ff\u6001\u4f30\u8ba1\u6a21\u578b\u53ca\u5c06\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u90e8\u7f72\u5230",(0,i.yg)("inlineCode",{parentName:"p"},"Grove Vision AI(V2)"),"\u6216",(0,i.yg)("inlineCode",{parentName:"p"},"XIAO ESP32S3"),"\u8bbe\u5907\u4e0a\u3002"),(0,i.yg)("h2",{id:"\u6570\u636e\u96c6\u51c6\u5907"},"\u6570\u636e\u96c6\u51c6\u5907"),(0,i.yg)("p",null,"\u59ff\u6001\u4f30\u8ba1\u7684\u6570\u636e\u96c6\u5efa\u8bae\u67e5\u770b",(0,i.yg)("a",{parentName:"p",href:"https://docs.ultralytics.com/datasets/pose/coco8-pose/"},"YOLOv8\u5b98\u65b9\u6587\u6863"),"\u3002"),(0,i.yg)("h2",{id:"\u5b89\u88c5yolov8\u547d\u4ee4\u884c\u5de5\u5177"},"\u5b89\u88c5YOLOv8\u547d\u4ee4\u884c\u5de5\u5177"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},"\u5728\u6b64\u9ed8\u8ba4\u4f60\u5df2\u7ecf\u6709\u4e86",(0,i.yg)("inlineCode",{parentName:"li"},"python"),"\u7684\u73af\u5883\u4e0e",(0,i.yg)("inlineCode",{parentName:"li"},"pip"),"\u5305\u7ba1\u7406\u5de5\u5177\uff0c\u4e14python>=3.8\u3002")),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-bash"},"# \u514b\u9686\u5b98\u65b9\u4ed3\u5e93\ngit clone https://github.com/ultralytics/ultralytics\n\n# \u8fdb\u5165\u5230\u514b\u9686\u4e0b\u6765\u7684\u6587\u4ef6\u5939\u5185\ncd ultralytics\n\n# \u4ee5\u5f00\u53d1\u8005\u6a21\u5f0f\u8fdb\u884c\u5b89\u88c5\uff0c\u4ee5\u4fbf\u540e\u7eed\u7684\u4fee\u6539\u80fd\u591f\u540c\u6b65\npip install -e .\n")),(0,i.yg)("p",null,"\u8fd9\u91cc\u5efa\u8bae\u4f7f\u7528",(0,i.yg)("inlineCode",{parentName:"p"},"Git"),"\u5b89\u88c5\u7684\u539f\u56e0\u662f\u540e\u9762\u9700\u8981\u4fee\u6539\u90e8\u5206\u4ee3\u7801\uff0c\u6240\u4ee5\u9700\u8981\u4ee5\u5f00\u53d1\u8005\u6a21\u578b\u5b89\u88c5"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},"\u53ef\u4f7f\u7528\u7248\u672c\u67e5\u8be2\u547d\u4ee4\u6d4b\u8bd5\u662f\u5426\u6210\u529f\u5b89\u88c5",(0,i.yg)("inlineCode",{parentName:"li"},"yolo"),"\u547d\u4ee4\u884c\u5de5\u5177")),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-bash"},"# \u8bad\u7ec3\u6d4b\u8bd5\nyolo -v\n")),(0,i.yg)("h2",{id:"\u8bad\u7ec3"},"\u8bad\u7ec3"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("p",{parentName:"li"},"\u9996\u5148\u5207\u5165\u5230\u6240\u4e0b\u8f7d\u7684\u6570\u636e\u96c6\u6587\u4ef6\u5939\u4e0b")),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("p",{parentName:"li"},"\u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\u5f00\u59cb\u8bad\u7ec3\u6a21\u578b"))),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-bash"},"yolo train detect model=yolov8n-pose.pt data=./data_pose.yaml imgsz=192\n")),(0,i.yg)("h2",{id:"\u5bfc\u51fa\u6a21\u578b\u81f3tflite"},"\u5bfc\u51fa\u6a21\u578b\u81f3tflite"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("p",{parentName:"li"},"\u8bad\u7ec3\u5b8c\u6210\u540e\u7684\u6a21\u578b\u4f1a\u518d",(0,i.yg)("inlineCode",{parentName:"p"},"runs/train/exp*/weights/"),"\u6587\u4ef6\u5939\u4e0b\uff0c\u786e\u8ba4\u4f60\u7684\u6a21\u578b\u7684\u8bc4\u4f30\u6307\u6807\u8fbe\u5230\u4f60\u7684\u9700\u6c42")),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("p",{parentName:"li"},"\u4e4b\u540e\u9700\u8981\u4fee\u6539\u5b98\u65b9\u4ee3\u7801\uff0c\u51cf\u5c11\u6a21\u578b\u7684\u90e8\u5206\u540e\u5904\u7406\uff0c\u9996\u5148\u4fee\u6539",(0,i.yg)("inlineCode",{parentName:"p"},"~/ultralytics/ultralytics/nn/modules/head.py"),"\u6587\u4ef6\u4e0b",(0,i.yg)("inlineCode",{parentName:"p"},"Detect"),"\u548c",(0,i.yg)("inlineCode",{parentName:"p"},"Pose"),"\u7c7b\u7684",(0,i.yg)("inlineCode",{parentName:"p"},"forward"),"\u51fd\u6570\uff0c\u4fee\u6539\u540e\u5982\u4e0b\u6240\u793a"))),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-python"},'# Detect \u7c7b\u7684forward\u51fd\u6570\n    def forward(self, x):\n        """Concatenates and returns predicted bounding boxes and class probabilities."""\n        shape = x[0].shape  # BCHW\n\n        if self.export:\n            return [\n                torch.permute(j, (0, 2, 3, 1)).reshape(j.shape[0], -1, x.shape[1])\n                for j in [self.cv2[i](x[i]) for i in range(self.nl)]\n                + [self.cv3[i](x[i]) for i in range(self.nl)]\n            ]\n        else:\n            for i in range(self.nl):\n                x[i] = torch.cat((self.cv2[i](x[i]), self.cv3[i](x[i])), 1)\n        if self.training:\n            return x\n        elif self.dynamic or self.shape != shape:\n            self.anchors, self.strides = (\n                x.transpose(0, 1) for x in make_anchors(x, self.stride, 0.5)\n            )\n            self.shape = shape\n\n        x_cat = torch.cat([xi.view(shape[0], self.no, -1) for xi in x], 2)\n        if self.export and self.format in (\n            "saved_model",\n            "pb",\n            "tflite",\n            "edgetpu",\n            "tfjs",\n        ):  # avoid TF FlexSplitV ops\n            box = x_cat[:, : self.reg_max * 4]\n            cls = x_cat[:, self.reg_max * 4 :]\n        else:\n            box, cls = x_cat.split((self.reg_max * 4, self.nc), 1)\n        dbox = (\n            dist2bbox(self.dfl(box), self.anchors.unsqueeze(0), xywh=True, dim=1)\n            * self.strides\n        )\n\n        if self.export and self.format in ("tflite", "edgetpu"):\n            # Normalize xywh with image size to mitigate quantization error of TFLite integer models as done in YOLOv5:\n            # https://github.com/ultralytics/yolov5/blob/0c8de3fca4a702f8ff5c435e67f378d1fce70243/models/tf.py#L307-L309\n            # See this PR for details: https://github.com/ultralytics/ultralytics/pull/1695\n            img_h = shape[2] * self.stride[0]\n            img_w = shape[3] * self.stride[0]\n            img_size = torch.tensor(\n                [img_w, img_h, img_w, img_h], device=dbox.device\n            ).reshape(1, 4, 1)\n            dbox /= img_size\n\n        y = torch.cat((dbox, cls.sigmoid()), 1)\n        return y if self.export else (y, x)\n\n# Pose\u7c7b\u7684forward\u51fd\u6570\n    def forward(self, x):\n        """Perform forward pass through YOLO model and return predictions."""\n        bs = x[0].shape[0]  # batch size\n        kpt = torch.cat([self.cv4[i](x[i]).view(bs, self.nk, -1) for i in range(self.nl)], -1)  # (bs, 17*3, h*w)\n        x = self.detect(self, x)\n        if self.training:\n            return x, kpt\n        if self.export:\n            return x, torch.permute(kpt, (0, 2, 1))\n        pred_kpt = self.kpts_decode(bs, kpt)\n        return torch.cat([x, pred_kpt], 1) if self.export else (torch.cat([x[0], pred_kpt], 1), (x[1], kpt))\n')),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},"\u4e3a\u4e86\u547d\u4ee4\u884c\u4e0d\u53d1\u751f\u5f02\u5e38\u9519\u8bef\uff0c\u8fd8\u53ef\u4fee\u6539",(0,i.yg)("inlineCode",{parentName:"li"},"~/ultralytics/ultralytics/engine/exporter.py"),"\u6587\u4ef6\u4e0b",(0,i.yg)("inlineCode",{parentName:"li"},"Exporter"),"\u7c7b\u7684",(0,i.yg)("inlineCode",{parentName:"li"},"export_saved_model"),"\u65b9\u6cd5\u4ee3\u7801\u5982\u4e0b\uff0c")),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-python"},"    @try_export\n    def export_saved_model(self, prefix=colorstr('TensorFlow SavedModel:')):\n        \"\"\"YOLOv8 TensorFlow SavedModel export.\"\"\"\n        cuda = torch.cuda.is_available()\n        try:\n            import tensorflow as tf  # noqa\n        except ImportError:\n            check_requirements(f\"tensorflow{'-macos' if MACOS else '-aarch64' if ARM64 else '' if cuda else '-cpu'}\")\n            import tensorflow as tf  # noqa\n        check_requirements(\n            ('onnx', 'onnx2tf>=1.15.4,<=1.17.5', 'sng4onnx>=1.0.1', 'onnxsim>=0.4.33', 'onnx_graphsurgeon>=0.3.26',\n             'tflite_support', 'onnxruntime-gpu' if cuda else 'onnxruntime'),\n            cmds='--extra-index-url https://pypi.ngc.nvidia.com')  # onnx_graphsurgeon only on NVIDIA\n\n        LOGGER.info(f'\\n{prefix} starting export with tensorflow {tf.__version__}...')\n        check_version(tf.__version__,\n                      '<=2.13.1',\n                      name='tensorflow',\n                      verbose=True,\n                      msg='https://github.com/ultralytics/ultralytics/issues/5161')\n        f = Path(str(self.file).replace(self.file.suffix, '_saved_model'))\n        if f.is_dir():\n            import shutil\n            shutil.rmtree(f)  # delete output folder\n\n        # Pre-download calibration file to fix https://github.com/PINTO0309/onnx2tf/issues/545\n        onnx2tf_file = Path('calibration_image_sample_data_20x128x128x3_float32.npy')\n        if not onnx2tf_file.exists():\n            attempt_download_asset(f'{onnx2tf_file}.zip', unzip=True, delete=True)\n\n        # Export to ONNX\n        self.args.simplify = True\n        f_onnx, _ = self.export_onnx()\n\n        # Export to TF\n        tmp_file = f / 'tmp_tflite_int8_calibration_images.npy'  # int8 calibration images file\n        if self.args.int8:\n            verbosity = '--verbosity info'\n            if self.args.data:\n                # Generate calibration data for integer quantization\n                LOGGER.info(f\"{prefix} collecting INT8 calibration images from 'data={self.args.data}'\")\n                data = check_det_dataset(self.args.data)\n                dataset = YOLODataset(data['val'], data=data, imgsz=self.imgsz[0], augment=False)\n                images = []\n                for i, batch in enumerate(dataset):\n                    if i >= 100:  # maximum number of calibration images\n                        break\n                    im = batch['img'].permute(1, 2, 0)[None]  # list to nparray, CHW to BHWC\n                    images.append(im)\n                f.mkdir()\n                images = torch.cat(images, 0).float()\n                # mean = images.view(-1, 3).mean(0)  # imagenet mean [123.675, 116.28, 103.53]\n                # std = images.view(-1, 3).std(0)  # imagenet std [58.395, 57.12, 57.375]\n                np.save(str(tmp_file), images.numpy())  # BHWC\n                int8 = f'-oiqt -qt per-tensor -cind images \"{tmp_file}\" \"[[[[0, 0, 0]]]]\" \"[[[[255, 255, 255]]]]\"'\n            else:\n                int8 = '-oiqt -qt per-tensor'\n        else:\n            verbosity = '--non_verbose'\n            int8 = ''\n\n        cmd = f'onnx2tf -i \"{f_onnx}\" -o \"{f}\" -nuo {verbosity} {int8}'.strip()\n        LOGGER.info(f\"{prefix} running '{cmd}'\")\n        subprocess.run(cmd, shell=True)\n        yaml_save(f / 'metadata.yaml', self.metadata)  # add metadata.yaml\n\n        # Remove/rename TFLite models\n        if self.args.int8:\n            tmp_file.unlink(missing_ok=True)\n            for file in f.rglob('*_dynamic_range_quant.tflite'):\n                file.rename(file.with_name(file.stem.replace('_dynamic_range_quant', '_int8') + file.suffix))\n            for file in f.rglob('*_integer_quant_with_int16_act.tflite'):\n                file.unlink()  # delete extra fp16 activation TFLite files\n\n        # Add TFLite metadata\n        # for file in f.rglob('*.tflite'):\n            # f.unlink() if 'quant_with_int16_act.tflite' in str(f) else self._add_tflite_metadata(file)\n\n        return str(f), tf.saved_model.load(f, tags=None, options=None)  # load saved_model as Keras model\n")),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},"\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u53ef\u5bfc\u51fatflite\u6a21\u578b")),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-bash"},"yolo export model=${\u4f60\u7684\u6a21\u578b\u8def\u5f84}  format=tflite imgsz=192 int8\n")),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},"\u4e4b\u540e\u4f1a\u518d\u6240\u5728\u6587\u4ef6\u5939\u4e0b\u770b\u5230\u4e00\u4e2a",(0,i.yg)("inlineCode",{parentName:"li"},"yolov8n-pose_saved_model"),"\u7684\u6587\u4ef6\u5939\uff0c\u91cc\u9762\u542b\u6709",(0,i.yg)("inlineCode",{parentName:"li"},"yolov8n-pose_full_integer_quant.tflite"),"\u6a21\u578b\u6587\u4ef6\uff0c\u53ef\u5c06\u6b64\u6a21\u578b\u6587\u4ef6\u90e8\u7f72\u5230",(0,i.yg)("inlineCode",{parentName:"li"},"Grove Vision AI(V2)"),"\u6216",(0,i.yg)("inlineCode",{parentName:"li"},"XIAO ESP32S3"),"\u8bbe\u5907\u4e0a\u3002")),(0,i.yg)("h3",{id:"\u6a21\u578b\u56fe\u4f18\u5316"},"\u6a21\u578b\u56fe\u4f18\u5316"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"Grove Vision AI(V2)"),"\u652f\u6301\u4f7f\u7528",(0,i.yg)("inlineCode",{parentName:"li"},"vela"),"\u4f18\u5316\u540e\u7684\u6a21\u578b\uff0c\u540c\u65f6\u4e5f\u80fd\u52a0\u901f\u6a21\u578b\u7684\u63a8\u7406\uff0c\u9996\u5148\u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\u5b89\u88c5vela\u547d\u4ee4\u884c\u5de5\u5177(",(0,i.yg)("inlineCode",{parentName:"li"},"XIAO ESP32S3"),"\u8bbe\u5907\u6682\u4e0d\u652f\u6301)")),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-bash"},"\npip3 install ethos-u-vela\n")),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},"\u4e4b\u540e\u9700\u8981",(0,i.yg)("a",{parentName:"li",href:"https://files.seeedstudio.com/sscma/configs/vela_config.ini"},"\u4e0b\u8f7d"),(0,i.yg)("inlineCode",{parentName:"li"},"vela"),"\u76f8\u5173\u7684\u914d\u7f6e\u6587\u4ef6,\u6216\u8005\u590d\u5236\u4e0b\u5217\u7684\u5185\u5bb9\u5230\u4e00\u4e2a\u6587\u4ef6\u5185\uff0c\u53ef\u547d\u540d\u4e3a",(0,i.yg)("inlineCode",{parentName:"li"},"vela_config.ini"))),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-bash"},"; file: my_vela_cfg.ini ; ----------------------------------------------------------------------------- \n; Vela configuration file ; ----------------------------------------------------------------------------- \n; System Configuration \n\n; My_Sys_Cfg \n[System_Config.My_Sys_Cfg] \ncore_clock=400e6 \naxi0_port=Sram \naxi1_port=OffChipFlash \nSram_clock_scale=1.0 \nSram_burst_length=32 \nSram_read_latency=16 \nSram_write_latency=16 \nDram_clock_scale=0.75 \nDram_burst_length=128 \nDram_read_latency=500 \nDram_write_latency=250 \nOnChipFlash_clock_scale=0.25 \nOffChipFlash_clock_scale=0.015625 \nOffChipFlash_burst_length=32 \nOffChipFlash_read_latency=64 \nOffChipFlash_write_latency=64 \n; ----------------------------------------------------------------------------- \n; Memory Mode \n; My_Mem_Mode_Parent \n[Memory_Mode.My_Mem_Mode_Parent] \nconst_mem_area=Axi1 \narena_mem_area=Axi0 \ncache_mem_area=Axi0\n")),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},"\u6700\u540e\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\uff0c\u8fdb\u884c\u56fe\u4f18\u5316")),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-bash"},"vela --accelerator-config ethos-u55-64 \\ \n    --config vela_config.ini \\\n    --system-config My_Sys_Cfg \\\n    --memory-mode My_Mem_Mode_Parent \\\n    --output-dir ${\u4f18\u5316\u540e\u7684\u6a21\u578b\u4fdd\u5b58\u8def\u5f84} \\\n    ${\u9700\u8981\u88ab\u4f18\u5316\u7684tflite\u6a21\u578b\u8def\u5f84}\n")),(0,i.yg)("h2",{id:"\u90e8\u7f72"},"\u90e8\u7f72"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("p",{parentName:"li"},"\u9700\u8981\u90e8\u7f72\u7684\u6a21\u578b\u6587\u4ef6\u662f\u4ee5\u4e0a\u5bfc\u51fa\u7684",(0,i.yg)("inlineCode",{parentName:"p"},"tflite"),"\u6587\u4ef6\uff0c\u53ef\u6839\u636e\u4ee5\u4e0b\u6559\u7a0b\u5c06\u6a21\u578b\u6587\u4ef6\u70e7\u5f55\u81f3\u76ee\u6807\u8bbe\u5907")),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("p",{parentName:"li"},"\u6211\u4eec\u5f3a\u70c8\u5efa\u8bae\u4f7f\u7528\u6211\u4eec\u7684\u7f51\u9875\u5de5\u5177\u5c06\u8bad\u7ec3\u597d\u7684tflite\u6a21\u578b\u70e7\u5f55\u5230\u8bbe\u5907\u4e2d\uff0c\u5176\u8be6\u7ec6\u64cd\u4f5c\u6211\u4eec\u63d0\u4f9b\u7684",(0,i.yg)("a",{parentName:"p",href:"https://wiki.seeedstudio.com/ModelAssistant_Deploy_Overview/"},"\u90e8\u7f72\u6559\u7a0b"),"\u8fdb\u884c"))),(0,i.yg)("p",null,(0,i.yg)("inlineCode",{parentName:"p"},"\u6ce8\u610f:"),"\u7531\u4e8e",(0,i.yg)("inlineCode",{parentName:"p"},"ESP32S3"),"\u8bbe\u5907\u4e0d\u652f\u6301\u7ecf\u8fc7",(0,i.yg)("inlineCode",{parentName:"p"},"vela"),"\u56fe\u4f18\u5316\u540e\u7684\u6a21\u578b\u90e8\u7f72\uff0c\u56e0\u6b64\u5982\u679c\u4f60\u60f3\u5c06\u6a21\u578b\u90e8\u7f72\u5230",(0,i.yg)("inlineCode",{parentName:"p"},"XIAO ESP32S3"),"\u8bbe\u5907\u4e0a\u4e0d\u9700\u8981\u8fdb\u884c",(0,i.yg)("inlineCode",{parentName:"p"},"tflite"),"\u6a21\u578b\u56fe\u4f18\u5316\u3002"))}d.isMDXComponent=!0}}]);