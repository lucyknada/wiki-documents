"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[40361],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>f});var i=n(67294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,i,o=function(e,t){if(null==e)return{};var n,i,o={},a=Object.keys(e);for(i=0;i<a.length;i++)n=a[i],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(i=0;i<a.length;i++)n=a[i],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=i.createContext({}),c=function(e){var t=i.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},d=function(e){var t=c(e.components);return i.createElement(l.Provider,{value:t},e.children)},p="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},h=i.forwardRef((function(e,t){var n=e.components,o=e.mdxType,a=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),p=c(n),h=o,f=p["".concat(l,".").concat(h)]||p[h]||u[h]||a;return n?i.createElement(f,r(r({ref:t},d),{},{components:n})):i.createElement(f,r({ref:t},d))}));function f(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=n.length,r=new Array(a);r[0]=h;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[p]="string"==typeof e?e:o,r[1]=s;for(var c=2;c<a;c++)r[c]=n[c];return i.createElement.apply(null,r)}return i.createElement.apply(null,n)}h.displayName="MDXCreateElement"},85162:(e,t,n)=>{n.d(t,{Z:()=>r});var i=n(67294),o=n(86010);const a={tabItem:"tabItem_Ymn6"};function r(e){let{children:t,hidden:n,className:r}=e;return i.createElement("div",{role:"tabpanel",className:(0,o.Z)(a.tabItem,r),hidden:n},t)}},74866:(e,t,n)=>{n.d(t,{Z:()=>y});var i=n(87462),o=n(67294),a=n(86010),r=n(12466),s=n(16550),l=n(91980),c=n(67392),d=n(50012);function p(e){return function(e){return o.Children.map(e,(e=>{if(!e||(0,o.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(e).map((e=>{let{props:{value:t,label:n,attributes:i,default:o}}=e;return{value:t,label:n,attributes:i,default:o}}))}function u(e){const{values:t,children:n}=e;return(0,o.useMemo)((()=>{const e=t??p(n);return function(e){const t=(0,c.l)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,n])}function h(e){let{value:t,tabValues:n}=e;return n.some((e=>e.value===t))}function f(e){let{queryString:t=!1,groupId:n}=e;const i=(0,s.k6)(),a=function(e){let{queryString:t=!1,groupId:n}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:t,groupId:n});return[(0,l._X)(a),(0,o.useCallback)((e=>{if(!a)return;const t=new URLSearchParams(i.location.search);t.set(a,e),i.replace({...i.location,search:t.toString()})}),[a,i])]}function m(e){const{defaultValue:t,queryString:n=!1,groupId:i}=e,a=u(e),[r,s]=(0,o.useState)((()=>function(e){let{defaultValue:t,tabValues:n}=e;if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!h({value:t,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const i=n.find((e=>e.default))??n[0];if(!i)throw new Error("Unexpected error: 0 tabValues");return i.value}({defaultValue:t,tabValues:a}))),[l,c]=f({queryString:n,groupId:i}),[p,m]=function(e){let{groupId:t}=e;const n=function(e){return e?`docusaurus.tab.${e}`:null}(t),[i,a]=(0,d.Nk)(n);return[i,(0,o.useCallback)((e=>{n&&a.set(e)}),[n,a])]}({groupId:i}),g=(()=>{const e=l??p;return h({value:e,tabValues:a})?e:null})();(0,o.useLayoutEffect)((()=>{g&&s(g)}),[g]);return{selectedValue:r,selectValue:(0,o.useCallback)((e=>{if(!h({value:e,tabValues:a}))throw new Error(`Can't select invalid tab value=${e}`);s(e),c(e),m(e)}),[c,m,a]),tabValues:a}}var g=n(72389);const S={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};function _(e){let{className:t,block:n,selectedValue:s,selectValue:l,tabValues:c}=e;const d=[],{blockElementScrollPositionUntilNextRender:p}=(0,r.o5)(),u=e=>{const t=e.currentTarget,n=d.indexOf(t),i=c[n].value;i!==s&&(p(t),l(i))},h=e=>{let t=null;switch(e.key){case"Enter":u(e);break;case"ArrowRight":{const n=d.indexOf(e.currentTarget)+1;t=d[n]??d[0];break}case"ArrowLeft":{const n=d.indexOf(e.currentTarget)-1;t=d[n]??d[d.length-1];break}}t?.focus()};return o.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,a.Z)("tabs",{"tabs--block":n},t)},c.map((e=>{let{value:t,label:n,attributes:r}=e;return o.createElement("li",(0,i.Z)({role:"tab",tabIndex:s===t?0:-1,"aria-selected":s===t,key:t,ref:e=>d.push(e),onKeyDown:h,onClick:u},r,{className:(0,a.Z)("tabs__item",S.tabItem,r?.className,{"tabs__item--active":s===t})}),n??t)})))}function k(e){let{lazy:t,children:n,selectedValue:i}=e;const a=(Array.isArray(n)?n:[n]).filter(Boolean);if(t){const e=a.find((e=>e.props.value===i));return e?(0,o.cloneElement)(e,{className:"margin-top--md"}):null}return o.createElement("div",{className:"margin-top--md"},a.map(((e,t)=>(0,o.cloneElement)(e,{key:t,hidden:e.props.value!==i}))))}function v(e){const t=m(e);return o.createElement("div",{className:(0,a.Z)("tabs-container",S.tabList)},o.createElement(_,(0,i.Z)({},e,t)),o.createElement(k,(0,i.Z)({},e,t)))}function y(e){const t=(0,g.Z)();return o.createElement(v,(0,i.Z)({key:String(t)},e))}},84312:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>l,default:()=>f,frontMatter:()=>s,metadata:()=>c,toc:()=>p});var i=n(87462),o=(n(67294),n(3905)),a=n(74866),r=n(85162);const s={description:"This tutorial explains how to use the XIAO ESP32S3, record a voice, recognise the voice and then ask ChatGPT a question and get an answer to display on the screen.",title:"Miniature ChatGPT Voice Assistant based on XIAO ESP32S3 Sense",keywords:["xiao esp32s3 sense","chatGPT","speech to text"],image:"https://files.seeedstudio.com/wiki/seeed_logo/logo_2023.png",slug:"/xiao_esp32s3_speech2chatgpt",last_update:{date:"5/31/2023",author:"Citric"}},l="Miniature ChatGPT Voice Assistant based on XIAO ESP32S3",c={unversionedId:"Sensor/SeeedStudio_XIAO/SeeedStudio_XIAO_ESP32S3/Application/XIAO_ESP32S3_Speech2chatgpt",id:"Sensor/SeeedStudio_XIAO/SeeedStudio_XIAO_ESP32S3/Application/XIAO_ESP32S3_Speech2chatgpt",title:"Miniature ChatGPT Voice Assistant based on XIAO ESP32S3 Sense",description:"This tutorial explains how to use the XIAO ESP32S3, record a voice, recognise the voice and then ask ChatGPT a question and get an answer to display on the screen.",source:"@site/docs/Sensor/SeeedStudio_XIAO/SeeedStudio_XIAO_ESP32S3/Application/XIAO_ESP32S3_Speech2chatgpt.md",sourceDirName:"Sensor/SeeedStudio_XIAO/SeeedStudio_XIAO_ESP32S3/Application",slug:"/xiao_esp32s3_speech2chatgpt",permalink:"/xiao_esp32s3_speech2chatgpt",draft:!1,editUrl:"https://github.com/Seeed-Studio/wiki-documents/blob/docusaurus-version/docs/Sensor/SeeedStudio_XIAO/SeeedStudio_XIAO_ESP32S3/Application/XIAO_ESP32S3_Speech2chatgpt.md",tags:[],version:"current",lastUpdatedBy:"Citric",lastUpdatedAt:1685491200,formattedLastUpdatedAt:"May 31, 2023",frontMatter:{description:"This tutorial explains how to use the XIAO ESP32S3, record a voice, recognise the voice and then ask ChatGPT a question and get an answer to display on the screen.",title:"Miniature ChatGPT Voice Assistant based on XIAO ESP32S3 Sense",keywords:["xiao esp32s3 sense","chatGPT","speech to text"],image:"https://files.seeedstudio.com/wiki/seeed_logo/logo_2023.png",slug:"/xiao_esp32s3_speech2chatgpt",last_update:{date:"5/31/2023",author:"Citric"}},sidebar:"ProductSidebar",previous:{title:"Camera Usage for Sense Version",permalink:"/xiao_esp32s3_camera_usage"},next:{title:"SenseCraft Model Assistant with XIAO ESP32S3 (Sense)",permalink:"/xiao_esp32s3_edgelab"}},d={},p=[{value:"Getting Started",id:"getting-started",level:2},{value:"Hardware preparation",id:"hardware-preparation",level:3},{value:"Software preparation",id:"software-preparation",level:3},{value:"Sign up and enable Google Cloud Speech to Text service",id:"sign-up-and-enable-google-cloud-speech-to-text-service",level:2},{value:"Step 1. Sign in to Google Cloud console",id:"step-1-sign-in-to-google-cloud-console",level:3},{value:"Step 2. Go to the project selector page",id:"step-2-go-to-the-project-selector-page",level:3},{value:"Step 3. Start a Speech-to-Text service",id:"step-3-start-a-speech-to-text-service",level:3},{value:"Step 4. Create a service account",id:"step-4-create-a-service-account",level:3},{value:"Step 5. Create a JSON key for your service account",id:"step-5-create-a-json-key-for-your-service-account",level:3},{value:"Deploy speech-to-text services on local hosts",id:"deploy-speech-to-text-services-on-local-hosts",level:2},{value:"Step 6. Download the project file",id:"step-6-download-the-project-file",level:3},{value:"Step 7. Set your authentication environment variable",id:"step-7-set-your-authentication-environment-variable",level:3},{value:"Step 8. Testing the deployment of a local Google Cloud speech-to-text service",id:"step-8-testing-the-deployment-of-a-local-google-cloud-speech-to-text-service",level:3},{value:"Upload XIAO ESP32S3 Sense recorded sound files to Google Cloud for recognition",id:"upload-xiao-esp32s3-sense-recorded-sound-files-to-google-cloud-for-recognition",level:2},{value:"Step 9. Turn on port listening for Google Cloud Speech Recognition Service",id:"step-9-turn-on-port-listening-for-google-cloud-speech-recognition-service",level:3},{value:"Step 10. Check the host IP address",id:"step-10-check-the-host-ip-address",level:3},{value:"Step 11. Uploading programs for the XIAO ESP32S3 Sense",id:"step-11-uploading-programs-for-the-xiao-esp32s3-sense",level:3},{value:"Deploy ChatGPT on XIAO ESP32S3 Sense",id:"deploy-chatgpt-on-xiao-esp32s3-sense",level:2},{value:"Step 12. Ask ChatGPT a question with the identified text as a question",id:"step-12-ask-chatgpt-a-question-with-the-identified-text-as-a-question",level:3},{value:"Design of screen display content &amp; Integration of programs",id:"design-of-screen-display-content--integration-of-programs",level:2},{value:"Step 13. Using SquareLine Studio to draw display screens",id:"step-13-using-squareline-studio-to-draw-display-screens",level:3},{value:"Step 14. Integration procedures",id:"step-14-integration-procedures",level:3},{value:"Tech Support &amp; Product Discussion",id:"tech-support--product-discussion",level:2}],u={toc:p},h="wrapper";function f(e){let{components:t,...n}=e;return(0,o.kt)(h,(0,i.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"miniature-chatgpt-voice-assistant-based-on-xiao-esp32s3"},"Miniature ChatGPT Voice Assistant based on XIAO ESP32S3"),(0,o.kt)("iframe",{width:"100%",height:"400",src:"https://www.youtube.com/embed/wPi-XjeJPNw?controls=0",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",allowfullscreen:!0}),(0,o.kt)("p",null,"We are pleased to bring you today a brand new project using the XIAO ESP32S3 Sense and Round Display for XIAO! The project aims to first build a speech recognition system using the XIAO ESP32S3 Sense's microphone and Google Cloud's speech-to-text service. The recognized speech text is then used to call OpenAI's interface to ask questions to ChatGPT and return answers. Finally, we display the recognised speech and the content of the answers on screen. "),(0,o.kt)("p",null,'This is our intelligent "XIAO" assistant!'),(0,o.kt)("p",null,"Let's take a look at some of the general steps required to complete this project."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#sign-up-and-enable-google-cloud-speech-to-text-service"},"Sign up and enable Google Cloud Speech to Text service")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#deploy-speech-to-text-services-on-local-hosts"},"Deploy speech-to-text services on local hosts")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#upload-xiao-esp32s3-sense-recorded-sound-files-to-google-cloud-for-recognition"},"Upload XIAO ESP32S3 Sense recorded sound files to Google Cloud for recognition")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#deploy-chatgpt-on-xiao-esp32s3-sense"},"Deploy ChatGPT on XIAO ESP32S3 Sense")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#design-of-screen-display-content--integration-of-programs"},"Design of screen display content & Integration of programs"))),(0,o.kt)("p",null,"The general framework structure can be seen in the diagram below."),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/xiaoesp32s3sense-speech2chatgpt/17.png",style:{width:1e3,height:"auto"}})),(0,o.kt)("h2",{id:"getting-started"},"Getting Started"),(0,o.kt)("p",null,"Before you start this project, you may need to prepare your hardware and software in advance as described here."),(0,o.kt)("h3",{id:"hardware-preparation"},"Hardware preparation"),(0,o.kt)("p",null,"If you want to experience the entire programme content in full, you need to have at least the following hardware equipment."),(0,o.kt)("div",{class:"table-center"},(0,o.kt)("table",{align:"center"},(0,o.kt)("tr",null,(0,o.kt)("th",null,"Seeed Studio XIAO ESP32S3 Sense"),(0,o.kt)("th",null,"Seeed Studio Round Display for XIAO")),(0,o.kt)("tr",null,(0,o.kt)("td",null,(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/SeeedStudio-XIAO-ESP32S3/img/xiaoesp32s3sense.jpg",style:{width:250,height:"auto"}}))),(0,o.kt)("td",null,(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/round_display_for_xiao/rounddisplay.jpg",style:{width:250,height:"auto"}})))),(0,o.kt)("tr",null,(0,o.kt)("td",null,(0,o.kt)("div",{class:"get_one_now_container",style:{textAlign:"center"}},(0,o.kt)("a",{class:"get_one_now_item",href:"https://www.seeedstudio.com/XIAO-ESP32S3-Sense-p-5639.html"},(0,o.kt)("strong",null,(0,o.kt)("span",null,(0,o.kt)("font",{color:"FFFFFF",size:"4"}," Get One Now \ud83d\uddb1\ufe0f")))))),(0,o.kt)("td",null,(0,o.kt)("div",{class:"get_one_now_container",style:{textAlign:"center"}},(0,o.kt)("a",{class:"get_one_now_item",href:"https://www.seeedstudio.com/Seeed-Studio-Round-Display-for-XIAO-p-5638.html"},(0,o.kt)("strong",null,(0,o.kt)("span",null,(0,o.kt)("font",{color:"FFFFFF",size:"4"}," Get One Now \ud83d\uddb1\ufe0f"))))))))),(0,o.kt)("p",null,"In addition to this, we need a microSD card in FAT32 format no larger than 32GB to store the recording files."),(0,o.kt)("p",null,"Since the XIAO EPS32S3 Sense is designed with three pull-up resistors R4~R6 connected to the SD card slot, and the round display also has pull-up resistors, the SD card cannot be read when both are used at the same time. To solve this problem, we need to cut off J3 on the XIAO ESP32S3 Sense expansion board."),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/SeeedStudio-XIAO-ESP32S3/img/33.png",style:{width:500,height:"auto"}})),(0,o.kt)("p",null,"After disconnecting J3, the SD card slot on XIAO ESP32S3 Sense will not work properly, so you need to insert a microSD card into the SD card slot on the Round Display."),(0,o.kt)("p",null,"Next, please install the microSD card, XIAO ESP32S3 Sense and Round Display in order."),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/SeeedStudio-XIAO-ESP32S3/img/101.gif",style:{width:500,height:"auto"}})),(0,o.kt)("admonition",{type:"tip"},(0,o.kt)("p",{parentName:"admonition"},"We recommend that you remove the camera module first to avoid scratching the camera when you cut the J3 connection with the blade.")),(0,o.kt)("h3",{id:"software-preparation"},"Software preparation"),(0,o.kt)("p",null,"As the XIAO ESP32S3 is used, please install the XIAO ESP32S3 on-board package according to the Wiki instructions before you start."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://wiki.seeedstudio.com/xiao_esp32s3_getting_started/#software-preparation"},"Getting Started with Seeed Studio XIAO ESP32S3 (Sense)"))),(0,o.kt)("p",null,"In addition to this, we also use the Round Display for XIAO, so you will also need to prepare the library for the expansion board as per the Wiki."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://wiki.seeedstudio.com/get_start_round_display/#getting-started"},"Getting Started with Seeed Studio Round Display for XIAO"))),(0,o.kt)("p",null,"During the project, we may also use some third-party libraries, such as ChatGPT's library and ArduinoJSON, which can be downloaded and added to the Arduino development environment here."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://github.com/limengdu/XIAO-ESP32S3Sense-Speech2ChatGPT/tree/main/libraries"},"Libraries"))),(0,o.kt)("p",null,"In addition to the basic libraries, we also need to use the Node service, so you will need to install Nodejs yourself, you can download it directly from the ",(0,o.kt)("a",{parentName:"p",href:"https://nodejs.org/en"},"official website"),"."),(0,o.kt)("p",null,"With everything in place, let's get started with today's tutorial."),(0,o.kt)("h2",{id:"sign-up-and-enable-google-cloud-speech-to-text-service"},"Sign up and enable Google Cloud Speech to Text service"),(0,o.kt)("admonition",{type:"tip"},(0,o.kt)("p",{parentName:"admonition"},"You can also refer directly to the ",(0,o.kt)("a",{parentName:"p",href:"https://cloud.google.com/speech-to-text/docs/before-you-begin#setting_up_your_google_cloud_platform_project"},"official Google Cloud tutorial")," on how to register and start the Google Cloud speech-to-text service to configure it.")),(0,o.kt)("p",null,"Speech-to-Text is an API that is powered by Google's artificial intelligence (AI) technology. You send your audio data to Speech-to-Text, then receive a text transcription of your audio data in response. Before you can begin sending requests to Speech-to-Text, you must enable the API in the Google Cloud console."),(0,o.kt)("h3",{id:"step-1-sign-in-to-google-cloud-console"},"Step 1. Sign in to Google Cloud console"),(0,o.kt)("p",null,"You can jump to the Google Cloud console by clicking ",(0,o.kt)("a",{parentName:"p",href:"https://console.cloud.google.com/?_ga=2.241031875.1758680688.1685496686-1606155345.1684977559"},"here"),", and if you have not yet registered for Google Cloud you can do so ",(0,o.kt)("a",{parentName:"p",href:"https://console.cloud.google.com/?_ga=2.241031875.1758680688.1685496686-1606155345.1684977559"},"here"),"."),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/xiaoesp32s3sense-speech2chatgpt/18.png",style:{width:1e3,height:"auto"}})),(0,o.kt)("h3",{id:"step-2-go-to-the-project-selector-page"},"Step 2. ",(0,o.kt)("a",{parentName:"h3",href:"https://console.cloud.google.com/projectselector2/home/dashboard?_ga=2.5754355.1758680688.1685496686-1606155345.1684977559"},"Go to the project selector page")),(0,o.kt)("p",null,"You can either choose an existing project or create a new one. For more information about creating a project, see ",(0,o.kt)("a",{parentName:"p",href:"https://cloud.google.com/resource-manager/docs/creating-managing-projects"},"Creating and managing projects"),"."),(0,o.kt)("p",null,"If you create a new project, you will be prompted to link a billing account to this project. If you are using a pre-existing project, make sure that you have billing enabled."),(0,o.kt)("admonition",{type:"note"},(0,o.kt)("p",{parentName:"admonition"},"Note: You must enable billing to use Speech-to-Text API, however you will not be charged unless you exceed the free quota. See the ",(0,o.kt)("a",{parentName:"p",href:"https://cloud.google.com/speech-to-text/pricing"},"pricing")," page for more details.")),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/xiaoesp32s3sense-speech2chatgpt/2.png",style:{width:1e3,height:"auto"}})),(0,o.kt)("h3",{id:"step-3-start-a-speech-to-text-service"},"Step 3. Start a Speech-to-Text service"),(0,o.kt)("p",null,"Once you have selected a project and linked it to a billing account, you can enable the Speech-to-Text API. Go to the Search products and resources bar at the top of the page and type in ",(0,o.kt)("strong",{parentName:"p"},"speech"),". Select the ",(0,o.kt)("strong",{parentName:"p"},"Cloud Speech-to-Text API")," from the list of results."),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/xiaoesp32s3sense-speech2chatgpt/1.png",style:{width:600,height:"auto"}})),(0,o.kt)("h3",{id:"step-4-create-a-service-account"},"Step 4. Create a service account"),(0,o.kt)("p",null,"Create a new service account if your project doesn't already have one. You must create a service account in order to use Speech-to-Text."),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/xiaoesp32s3sense-speech2chatgpt/3.png",style:{width:600,height:"auto"}})),(0,o.kt)("p",null,"On the new pop-up page, select the ",(0,o.kt)("strong",{parentName:"p"},"Service account")," under ",(0,o.kt)("strong",{parentName:"p"},"CREATE CREDENTIALS"),"."),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/xiaoesp32s3sense-speech2chatgpt/4.png",style:{width:1e3,height:"auto"}})),(0,o.kt)("p",null,"In the ",(0,o.kt)("strong",{parentName:"p"},"service account name")," box, type a unique name for the new service account. Your input is automatically populated in the ",(0,o.kt)("strong",{parentName:"p"},"Service account ID box"),". The Service account description box is optional but recommended if you plan to associate multiple service accounts with your project. Enter a brief description of the service account into this box, then click ",(0,o.kt)("strong",{parentName:"p"},"CREATE AND CONTINUE"),"."),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/xiaoesp32s3sense-speech2chatgpt/5.png",style:{width:500,height:"auto"}})),(0,o.kt)("p",null,"We recommend that you assign one of the basic IAM roles to your service account. You can also assign multiple roles to a single service account if needed. See ",(0,o.kt)("a",{parentName:"p",href:"https://cloud.google.com/iam/docs/understanding-roles"},"IAM roles")," for details on available roles and the permissions allowed to each. Click on the drop-down Select a role menu and scroll down to ",(0,o.kt)("strong",{parentName:"p"},"Owner"),". You can choose a role for this service account from the options that appear in the right-hand column. Click ",(0,o.kt)("strong",{parentName:"p"},"CONTINUE"),"."),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/xiaoesp32s3sense-speech2chatgpt/6.png",style:{width:500,height:"auto"}})),(0,o.kt)("p",null,"The final step allows you to optionally allow other entities (individuals, Google groups, and so on) to access your service account. If you don't need to grant additional access, you can click ",(0,o.kt)("strong",{parentName:"p"},"DONE")," without entering any information."),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/xiaoesp32s3sense-speech2chatgpt/7.png",style:{width:500,height:"auto"}})),(0,o.kt)("p",null,"The service account is now listed on the ",(0,o.kt)("strong",{parentName:"p"},"Service Accounts")," page. You can change the service account's permissions, add or generate new keys, and grant access at any time."),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/xiaoesp32s3sense-speech2chatgpt/8.png",style:{width:1e3,height:"auto"}})),(0,o.kt)("h3",{id:"step-5-create-a-json-key-for-your-service-account"},"Step 5. Create a JSON key for your service account"),(0,o.kt)("p",null,"You need to use this private key during the ",(0,o.kt)("a",{parentName:"p",href:"https://cloud.google.com/speech-to-text/docs/before-you-begin#set_up_your_environment_variables"},"authentication process")," when you send a request to Speech-to-Text."),(0,o.kt)("p",null,"To create a key, click on the service account and select the ",(0,o.kt)("strong",{parentName:"p"},"KEYS")," tab. Click ",(0,o.kt)("strong",{parentName:"p"},"ADD KEY -> Create new key"),". We recommend that you create a key in JSON format."),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/xiaoesp32s3sense-speech2chatgpt/9.png",style:{width:800,height:"auto"}})),(0,o.kt)("p",null,"A new key in the format of your choice is automatically downloaded. Store this file in a safe location and make a note of the file path. You will need to point the ",(0,o.kt)("strong",{parentName:"p"},"GOOGLE_APPLICATION_CREDENTIALS")," environment variable to this file when you go through the authentication process at the beginning of each new Speech-to-Text session. This is an essential step for authenticating requests to Speech-to-Text. The key's unique ID appears next to the name of the service account."),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/xiaoesp32s3sense-speech2chatgpt/10.png",style:{width:1e3,height:"auto"}})),(0,o.kt)("admonition",{type:"note"},(0,o.kt)("p",{parentName:"admonition"},"Please keep the key in JSON format as we will use it in a later step.")),(0,o.kt)("h2",{id:"deploy-speech-to-text-services-on-local-hosts"},"Deploy speech-to-text services on local hosts"),(0,o.kt)("h3",{id:"step-6-download-the-project-file"},"Step 6. Download the project file"),(0,o.kt)("p",null,"We have packed the project file needed to complete the entire tutorial and you can download it directly from Github using the button below, or you can download it locally using the Git command."),(0,o.kt)("div",{class:"github_container",style:{textAlign:"center"}},(0,o.kt)("a",{class:"github_item",href:"https://github.com/limengdu/XIAO-ESP32S3Sense-Speech2ChatGPT"},(0,o.kt)("strong",null,(0,o.kt)("span",null,(0,o.kt)("font",{color:"FFFFFF",size:"4"}," Download the Project")))," ",(0,o.kt)("svg",{"aria-hidden":"true",focusable:"false",role:"img",className:"mr-2",viewBox:"-3 10 9 1",width:16,height:16,fill:"currentColor",style:{textAlign:"center",display:"inline-block",userSelect:"none",verticalAlign:"text-bottom",overflow:"visible"}},(0,o.kt)("path",{d:"M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z"})))),(0,o.kt)("br",null),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"git clone https://github.com/limengdu/XIAO-ESP32S3Sense-Speech2ChatGPT.git\n")),(0,o.kt)("p",null,"In the meantime, you can copy the JSON file we prepared in ",(0,o.kt)("strong",{parentName:"p"},"step 5")," to the ",(0,o.kt)("strong",{parentName:"p"},"NodejsServer")," folder and we'll use it later."),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/xiaoesp32s3sense-speech2chatgpt/19.png",style:{width:600,height:"auto"}})),(0,o.kt)("h3",{id:"step-7-set-your-authentication-environment-variable"},"Step 7. Set your authentication environment variable"),(0,o.kt)("p",null,"In order to set your ",(0,o.kt)("strong",{parentName:"p"},"GOOGLE_APPLICATION_CREDENTIALS"),", you must have a service account associated with your project and have access to the service account's JSON key."),(0,o.kt)("p",null,"Provide authentication credentials to your application code by setting the environment variable ",(0,o.kt)("strong",{parentName:"p"},"GOOGLE_APPLICATION_CREDENTIALS"),"."),(0,o.kt)(a.Z,{mdxType:"Tabs"},(0,o.kt)(r.Z,{value:"Windows",label:"Windows",mdxType:"TabItem"},(0,o.kt)("p",null,"For PowerShell:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'$env:GOOGLE_APPLICATION_CREDENTIALS="KEY_PATH"\n')),(0,o.kt)("p",null,"Replace ",(0,o.kt)("strong",{parentName:"p"},"KEY_PATH")," with the path of the JSON file that contains your service account key."),(0,o.kt)("p",null,"For example:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'$env:GOOGLE_APPLICATION_CREDENTIALS="C:\\Users\\username\\Downloads\\service-account-file.json"\n')),(0,o.kt)("p",null,"For command prompt:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"set GOOGLE_APPLICATION_CREDENTIALS=KEY_PATH\n")),(0,o.kt)("p",null,"Replace ",(0,o.kt)("strong",{parentName:"p"},"KEY_PATH")," with the path of the JSON file that contains your service account key.")),(0,o.kt)(r.Z,{value:"MacOS or Linux",label:"MacOS or Linux",mdxType:"TabItem"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'export GOOGLE_APPLICATION_CREDENTIALS="KEY_PATH"\n')),(0,o.kt)("p",null,"Replace ",(0,o.kt)("strong",{parentName:"p"},"KEY_PATH")," with the path of the JSON file that contains your service account key."),(0,o.kt)("p",null,"For example:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'export GOOGLE_APPLICATION_CREDENTIALS="/home/user/Downloads/service-account-file.json"\n')))),(0,o.kt)("p",null,"In the previous step, we have placed the JSON file in the ",(0,o.kt)("strong",{parentName:"p"},"NodejsServer")," folder, so we can go directly to that folder, right click and select ",(0,o.kt)("strong",{parentName:"p"},"Open in Powershell")," to enter the Windows terminal."),(0,o.kt)("p",null,"Then just enter the command."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'$env:GOOGLE_APPLICATION_CREDENTIALS="tensile-yen-3xxxxx-fdxxxxxxxxxx.json"\n')),(0,o.kt)("admonition",{type:"tip"},(0,o.kt)("p",{parentName:"admonition"},"Please use your JSON filename when executing the above command.")),(0,o.kt)("admonition",{type:"caution"},(0,o.kt)("p",{parentName:"admonition"},"If you have restarted your computer or closed Powershell, this may require you to reconfigure your environment variables to add the key.")),(0,o.kt)("h3",{id:"step-8-testing-the-deployment-of-a-local-google-cloud-speech-to-text-service"},"Step 8. Testing the deployment of a local Google Cloud speech-to-text service"),(0,o.kt)("p",null,"With everything in place, we can then use a piece of recorded audio, combined with a json program, to check that our deployment is successful in getting the recording to text."),(0,o.kt)("p",null,"Please open a Powershell window in ",(0,o.kt)("strong",{parentName:"p"},"NodejsServer")," in the project folder."),(0,o.kt)("p",null,"Then enter the following command. This command will execute the ",(0,o.kt)("inlineCode",{parentName:"p"},"speechAPItest.js")," file and use the recording file in the resources folder of the project as the audio input source to send to Google Cloud for analysis and return the recognised speech content."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"node ./speechAPItest.js\n")),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/xiaoesp32s3sense-speech2chatgpt/13.png",style:{width:800,height:"auto"}})),(0,o.kt)("p",null,"If your implementation works as shown above, this indicates that you have successfully deployed Google Cloud Services on your local host and are ready to proceed to the next step."),(0,o.kt)("p",null,"If you encounter problems, you can consult the ",(0,o.kt)("a",{parentName:"p",href:"https://cloud.google.com/speech-to-text/docs/"},"official Google Cloud instructions")," to check if there are any errors or missing steps in the deployment process."),(0,o.kt)("h2",{id:"upload-xiao-esp32s3-sense-recorded-sound-files-to-google-cloud-for-recognition"},"Upload XIAO ESP32S3 Sense recorded sound files to Google Cloud for recognition"),(0,o.kt)("p",null,"Next, we change the path to the uploaded audio file. From a local upload to an upload via XIAO ESP32S3 Sense recording. And the audio files recorded by the XIAO ESP32S3 Sense are first saved to a microSD card and then transferred to Google Cloud by way of the local port."),(0,o.kt)("h3",{id:"step-9-turn-on-port-listening-for-google-cloud-speech-recognition-service"},"Step 9. Turn on port listening for Google Cloud Speech Recognition Service"),(0,o.kt)("p",null,"Similarly, in the NodejsServer folder, use Poweshell to execute the following command."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"node ./speechAPIServer.js\n")),(0,o.kt)("p",null,"Once executed, the ",(0,o.kt)("strong",{parentName:"p"},"speechAPIServer.js")," program will be executed and will continuously listen to ",(0,o.kt)("inlineCode",{parentName:"p"},"localhost:8888"),". Once a file is transferred to this port, the Google Cloud service will be called."),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/xiaoesp32s3sense-speech2chatgpt/20.png",style:{width:800,height:"auto"}})),(0,o.kt)("p",null,"Once the listening has started, just leave the window open and the service will stay up."),(0,o.kt)("h3",{id:"step-10-check-the-host-ip-address"},"Step 10. Check the host IP address"),(0,o.kt)("p",null,"Because the recording files after XIAO need to be uploaded to Google Cloud Services via the host's port number, we need to know the IP address of your computer host."),(0,o.kt)(a.Z,{mdxType:"Tabs"},(0,o.kt)(r.Z,{value:"Windows",label:"Windows",mdxType:"TabItem"},(0,o.kt)("p",null,"Execute the following command in Powershell to obtain information on the IP address of your computer."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"ipcofig\n"))),(0,o.kt)(r.Z,{value:"MacOS or Linux",label:"MacOS or Linux",mdxType:"TabItem"},(0,o.kt)("p",null,"Execute the following command in shell to obtain information on the IP address of your computer."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"ifconfig\n")))),(0,o.kt)("p",null,"Please make a note of your IP address as we will need to use it later."),(0,o.kt)("h3",{id:"step-11-uploading-programs-for-the-xiao-esp32s3-sense"},"Step 11. Uploading programs for the XIAO ESP32S3 Sense"),(0,o.kt)("p",null,"In the project folder ",(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("a",{parentName:"strong",href:"https://github.com/limengdu/XIAO-ESP32S3Sense-Speech2ChatGPT/blob/main/XIAOESP32S3-RECORD-UPLOAD/XIAOESP32S3-RECORD-UPLOAD.ino"},"XIAOESP32S3-RECORD-UPLOAD"))," we have prepared the program for the examples in this section."),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Click to preview the full program"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-cpp"},'#include <I2S.h>\n#include <WiFi.h>\n#include <HTTPClient.h>\n#include "FS.h"\n#include "SD.h"\n#include "SPI.h"\n\n//Variables to be used in the recording program, do not change for best\n#define SAMPLE_RATE 16000U\n#define SAMPLE_BITS 16\n#define WAV_HEADER_SIZE 44\n#define VOLUME_GAIN 2\n#define RECORD_TIME 10      // seconds, The maximum value is 240\n\n// Number of bytes required for the recording buffer\nuint32_t record_size = (SAMPLE_RATE * SAMPLE_BITS / 8) * RECORD_TIME;\n\nFile file;\nconst char filename[] = "/recording.wav";\n\nbool isWIFIConnected;\n\nvoid setup() {\n  // put your setup code here, to run once:\n  Serial.begin(115200);\n  while (!Serial) ;\n  \n  I2S.setAllPins(-1, 42, 41, -1, -1);\n  \n  //The transmission mode is PDM_MONO_MODE, which means that PDM (pulse density modulation) mono mode is used for transmission\n  if (!I2S.begin(PDM_MONO_MODE, SAMPLE_RATE, SAMPLE_BITS)) {\n    Serial.println("Failed to initialize I2S!");\n    while (1) ;\n  }\n\n  if(!SD.begin(D2)){\n    Serial.println("Failed to mount SD Card!");\n    while (1) ;\n  }\n  \n  xTaskCreate(i2s_adc, "i2s_adc", 1024 * 8, NULL, 1, NULL);\n  delay(500);\n  xTaskCreate(wifiConnect, "wifi_Connect", 4096, NULL, 0, NULL);\n}\n\nvoid loop() {\n  // put your main code here, to run repeatedly:\n}\n\nvoid i2s_adc(void *arg)\n{\n  uint32_t sample_size = 0;\n\n  //This variable will be used to point to the actual recording buffer\n  uint8_t *rec_buffer = NULL;\n  Serial.printf("Ready to start recording ...\\n");\n\n  File file = SD.open(filename, FILE_WRITE);\n\n  // Write the header to the WAV file\n  uint8_t wav_header[WAV_HEADER_SIZE];\n\n  //Write the WAV file header information to the wav_header array\n  generate_wav_header(wav_header, record_size, SAMPLE_RATE);\n\n  //Call the file.write() function to write the data in the wav_header array to the newly created WAV file\n  file.write(wav_header, WAV_HEADER_SIZE);\n\n  // This code uses the ESP32\'s PSRAM (external cache memory) to dynamically allocate a section of memory to store the recording data.\n  rec_buffer = (uint8_t *)ps_malloc(record_size);\n  if (rec_buffer == NULL) {\n    Serial.printf("malloc failed!\\n");\n    while(1) ;\n  }\n  Serial.printf("Buffer: %d bytes\\n", ESP.getPsramSize() - ESP.getFreePsram());\n\n  // Start recording\n  // I2S port number (in this case I2S_NUM_0), \n  // a pointer to the buffer to which the data is to be written (i.e. rec_buffer),\n  // the size of the data to be read (i.e. record_size),\n  // a pointer to a variable that points to the actual size of the data being read (i.e. &sample_size),\n  // and the maximum time to wait for the data to be read (in this case portMAX_DELAY, indicating an infinite wait time).\n  esp_i2s::i2s_read(esp_i2s::I2S_NUM_0, rec_buffer, record_size, &sample_size, portMAX_DELAY);\n  if (sample_size == 0) {\n    Serial.printf("Record Failed!\\n");\n  } else {\n    Serial.printf("Record %d bytes\\n", sample_size);\n  }\n\n  // Increase volume\n  for (uint32_t i = 0; i < sample_size; i += SAMPLE_BITS/8) {\n    (*(uint16_t *)(rec_buffer+i)) <<= VOLUME_GAIN;\n  }\n\n  // Write data to the WAV file\n  Serial.printf("Writing to the file ...\\n");\n  if (file.write(rec_buffer, record_size) != record_size)\n    Serial.printf("Write file Failed!\\n");\n\n  free(rec_buffer);\n  rec_buffer = NULL;\n  file.close();\n  Serial.printf("The recording is over.\\n");\n    \n  listDir(SD, "/", 0);\n\n  if(isWIFIConnected){\n    uploadFile();\n  }\n  \n  vTaskDelete(NULL);\n}\n\n\nvoid generate_wav_header(uint8_t *wav_header, uint32_t wav_size, uint32_t sample_rate)\n{\n  // See this for reference: http://soundfile.sapp.org/doc/WaveFormat/\n  uint32_t file_size = wav_size + WAV_HEADER_SIZE - 8;\n  uint32_t byte_rate = SAMPLE_RATE * SAMPLE_BITS / 8;\n  const uint8_t set_wav_header[] = {\n    \'R\', \'I\', \'F\', \'F\', // ChunkID\n    file_size, file_size >> 8, file_size >> 16, file_size >> 24, // ChunkSize\n    \'W\', \'A\', \'V\', \'E\', // Format\n    \'f\', \'m\', \'t\', \' \', // Subchunk1ID\n    0x10, 0x00, 0x00, 0x00, // Subchunk1Size (16 for PCM)\n    0x01, 0x00, // AudioFormat (1 for PCM)\n    0x01, 0x00, // NumChannels (1 channel)\n    sample_rate, sample_rate >> 8, sample_rate >> 16, sample_rate >> 24, // SampleRate\n    byte_rate, byte_rate >> 8, byte_rate >> 16, byte_rate >> 24, // ByteRate\n    0x02, 0x00, // BlockAlign\n    0x10, 0x00, // BitsPerSample (16 bits)\n    \'d\', \'a\', \'t\', \'a\', // Subchunk2ID\n    wav_size, wav_size >> 8, wav_size >> 16, wav_size >> 24, // Subchunk2Size\n  };\n  memcpy(wav_header, set_wav_header, sizeof(set_wav_header));\n}\n\n\nvoid listDir(fs::FS &fs, const char * dirname, uint8_t levels){\n    Serial.printf("Listing directory: %s\\n", dirname);\n\n    File root = fs.open(dirname);\n    if(!root){\n        Serial.println("Failed to open directory");\n        return;\n    }\n    if(!root.isDirectory()){\n        Serial.println("Not a directory");\n        return;\n    }\n\n    File file = root.openNextFile();\n    while(file){\n        if(file.isDirectory()){\n            Serial.print("  DIR : ");\n            Serial.println(file.name());\n            if(levels){\n                listDir(fs, file.path(), levels -1);\n            }\n        } else {\n            Serial.print("  FILE: ");\n            Serial.print(file.name());\n            Serial.print("  SIZE: ");\n            Serial.println(file.size());\n        }\n        file = root.openNextFile();\n    }\n}\n\nvoid wifiConnect(void *pvParameters){\n  isWIFIConnected = false;\n  char* ssid = "wifi-ssid";\n  char* password = "wifi-password";\n  Serial.print("Try to connect to ");\n  Serial.println(ssid);\n  WiFi.begin(ssid, password);\n  while(WiFi.status() != WL_CONNECTED){\n    vTaskDelay(500);\n    Serial.print(".");\n  }\n  Serial.println("Wi-Fi Connected!");\n  isWIFIConnected = true;\n  while(true){\n    vTaskDelay(1000);\n  }\n}\n\nvoid uploadFile(){\n  file = SD.open(filename, FILE_READ);\n  if(!file){\n    Serial.println("FILE IS NOT AVAILABLE!");\n    return;\n  }\n\n  Serial.println("===> Upload FILE to Node.js Server");\n\n  HTTPClient client;\n  client.begin("http://192.168.1.208:8888/uploadAudio");\n  client.addHeader("Content-Type", "audio/wav");\n  int httpResponseCode = client.sendRequest("POST", &file, file.size());\n  Serial.print("httpResponseCode : ");\n  Serial.println(httpResponseCode);\n\n  if(httpResponseCode == 200){\n    String response = client.getString();\n    Serial.println("==================== Transcription ====================");\n    Serial.println(response);\n    Serial.println("====================      End      ====================");\n  }else{\n    Serial.println("Error");\n  }\n  file.close();\n  client.end();\n}\n'))),(0,o.kt)("p",null,"Before compiling and uploading the example program, there are a few things you will need to change to suit your situation."),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("strong",{parentName:"li"},"Time to record sound")," - On ",(0,o.kt)("a",{parentName:"li",href:"https://github.com/limengdu/XIAO-ESP32S3Sense-Speech2ChatGPT/blob/404007a16f42495576d729848d00c6bb6a8149fc/XIAOESP32S3-RECORD-UPLOAD/XIAOESP32S3-RECORD-UPLOAD.ino#LL13C2-L13C2"},"line 13")," of the code, the default recording time is set to 10 seconds, you can adjust this recording time to suit you, up to a maximum of 240 seconds."),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("strong",{parentName:"li"},"Name of the saved recording file")," - On ",(0,o.kt)("a",{parentName:"li",href:"https://github.com/limengdu/XIAO-ESP32S3Sense-Speech2ChatGPT/blob/404007a16f42495576d729848d00c6bb6a8149fc/XIAOESP32S3-RECORD-UPLOAD/XIAOESP32S3-RECORD-UPLOAD.ino#L19"},"line 19")," of the code, you can change a name for your recording file."),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("strong",{parentName:"li"},"WiFi name of the network")," - Change the network name of the code ",(0,o.kt)("a",{parentName:"li",href:"https://github.com/limengdu/XIAO-ESP32S3Sense-Speech2ChatGPT/blob/404007a16f42495576d729848d00c6bb6a8149fc/XIAOESP32S3-RECORD-UPLOAD/XIAOESP32S3-RECORD-UPLOAD.ino#L172"},"line 172")," to the name of the network under the same LAN as the host where you are deploying Google Cloud Services."),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("strong",{parentName:"li"},"WiFi password of the network")," - On ",(0,o.kt)("a",{parentName:"li",href:"https://github.com/limengdu/XIAO-ESP32S3Sense-Speech2ChatGPT/blob/404007a16f42495576d729848d00c6bb6a8149fc/XIAOESP32S3-RECORD-UPLOAD/XIAOESP32S3-RECORD-UPLOAD.ino#LL173C5-L173C5"},"line 172")," of the code, change the password corresponding to the network."),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("strong",{parentName:"li"},"Host IP address")," - On ",(0,o.kt)("a",{parentName:"li",href:"https://github.com/limengdu/XIAO-ESP32S3Sense-Speech2ChatGPT/blob/404007a16f42495576d729848d00c6bb6a8149fc/XIAOESP32S3-RECORD-UPLOAD/XIAOESP32S3-RECORD-UPLOAD.ino#LL198C7-L198C7"},"line 198")," of the code, you need to change the IP address here to your host IP address and keep the port number at 8888.")),(0,o.kt)("p",null,"Once you have changed the program to suit your needs and uploaded it you can turn on the serial monitor and start preparing to record what you want to say. After the ten-second recording, Google Cloud will analyse your recording file and return the results of the recognition to you."),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/xiaoesp32s3sense-speech2chatgpt/15.png",style:{width:1e3,height:"auto"}})),(0,o.kt)("h2",{id:"deploy-chatgpt-on-xiao-esp32s3-sense"},"Deploy ChatGPT on XIAO ESP32S3 Sense"),(0,o.kt)("p",null,"Next we increase the difficulty. Continue adding ChatGPT calls to the code."),(0,o.kt)("h3",{id:"step-12-ask-chatgpt-a-question-with-the-identified-text-as-a-question"},"Step 12. Ask ChatGPT a question with the identified text as a question"),(0,o.kt)("p",null,"In the project folder ",(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("a",{parentName:"strong",href:"https://github.com/limengdu/XIAO-ESP32S3Sense-Speech2ChatGPT/blob/main/XIAOESP32S3-SPEECH-TO-CHATGPT/XIAOESP32S3-SPEECH-TO-CHATGPT.ino"},"XIAOESP32S3-SPEECH-TO-CHATGPT"))," we have prepared the program for the examples in this section."),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Click to preview the full program"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-cpp"},'#include <I2S.h>\n#include <WiFi.h>\n#include <HTTPClient.h>\n#include <WiFiClientSecure.h>\n#include <ArduinoJson.h>\n#include <ChatGPT.hpp>\n#include "FS.h"\n#include "SD.h"\n#include "SPI.h"\n\n// Variables to be used in the recording program, do not change for best\n#define SAMPLE_RATE 16000U\n#define SAMPLE_BITS 16\n#define WAV_HEADER_SIZE 44\n#define VOLUME_GAIN 2\n#define RECORD_TIME 5  // seconds, The maximum value is 240\n\nconst char* ssid = "wifi-ssid";\nconst char* password = "wifi-password";\n\n\n// Number of bytes required for the recording buffer\nuint32_t record_size = (SAMPLE_RATE * SAMPLE_BITS / 8) * RECORD_TIME;\n\nFile file;\nconst char filename[] = "/recording.wav";\nbool isWIFIConnected;\n\nString chatgpt_Q;\n\nTaskHandle_t chatgpt_handle;\nWiFiClientSecure client;\nChatGPT<WiFiClientSecure> chat_gpt(&client, "v1", "OpenAI-TOKEN");\n\n//*****************************************Arduino Base******************************************//\n\nvoid setup() {\n  // put your setup code here, to run once:\n  Serial.begin(115200);\n  while (!Serial) ;\n  \n  I2S.setAllPins(-1, 42, 41, -1, -1);\n  \n  // The transmission mode is PDM_MONO_MODE, which means that PDM (pulse density modulation) mono mode is used for transmission\n  if (!I2S.begin(PDM_MONO_MODE, SAMPLE_RATE, SAMPLE_BITS)) {\n    Serial.println("Failed to initialize I2S!");\n    while (1) ;\n  }\n\n  if(!SD.begin(D2)){\n    Serial.println("Failed to mount SD Card!");\n    while (1) ;\n  }\n\n  xTaskCreate(wifiConnect, "wifi_Connect", 4096, NULL, 0, NULL);\n  delay(500);\n  xTaskCreate(i2s_adc, "i2s_adc", 1024 * 8, NULL, 1, NULL);\n  xTaskCreate(chatgpt, "chatgpt", 1024 * 8, NULL, 2, &chatgpt_handle);\n}\n\nvoid loop() {\n  // put your main code here, to run repeatedly:\n}\n\n//*****************************************RTOS TASK******************************************//\n\nvoid i2s_adc(void *arg)\n{\n  while(1){\n    uint32_t sample_size = 0;\n  \n    // This variable will be used to point to the actual recording buffer\n    uint8_t *rec_buffer = NULL;\n    Serial.printf("Ready to start recording ...\\n");\n  \n    File file = SD.open(filename, FILE_WRITE);\n  \n    // Write the header to the WAV file\n    uint8_t wav_header[WAV_HEADER_SIZE];\n  \n    // Write the WAV file header information to the wav_header array\n    generate_wav_header(wav_header, record_size, SAMPLE_RATE);\n  \n    // Call the file.write() function to write the data in the wav_header array to the newly created WAV file\n    file.write(wav_header, WAV_HEADER_SIZE);\n  \n    // This code uses the ESP32\'s PSRAM (external cache memory) to dynamically allocate a section of memory to store the recording data\n    rec_buffer = (uint8_t *)ps_malloc(record_size);\n    if (rec_buffer == NULL) {\n      Serial.printf("malloc failed!\\n");\n      while(1) ;\n    }\n    Serial.printf("Buffer: %d bytes\\n", ESP.getPsramSize() - ESP.getFreePsram());\n  \n    // Start recording\n    // I2S port number (in this case I2S_NUM_0), \n    // a pointer to the buffer to which the data is to be written (i.e. rec_buffer),\n    // the size of the data to be read (i.e. record_size),\n    // a pointer to a variable that points to the actual size of the data being read (i.e. &sample_size),\n    // and the maximum time to wait for the data to be read (in this case portMAX_DELAY, indicating an infinite wait time).\n    esp_i2s::i2s_read(esp_i2s::I2S_NUM_0, rec_buffer, record_size, &sample_size, portMAX_DELAY);\n    if (sample_size == 0) {\n      Serial.printf("Record Failed!\\n");\n    } else {\n      Serial.printf("Record %d bytes\\n", sample_size);\n    }\n  \n    // Increase volume\n    for (uint32_t i = 0; i < sample_size; i += SAMPLE_BITS/8) {\n      (*(uint16_t *)(rec_buffer+i)) <<= VOLUME_GAIN;\n    }\n  \n    // Write data to the WAV file\n    Serial.printf("Writing to the file ...\\n");\n    if (file.write(rec_buffer, record_size) != record_size)\n      Serial.printf("Write file Failed!\\n");\n  \n    free(rec_buffer);\n    rec_buffer = NULL;\n    file.close();\n    Serial.printf("The recording is over.\\n");\n      \n    listDir(SD, "/", 0);\n\n    bool uploadStatus = false;\n  \n    if(isWIFIConnected){\n      uploadStatus = uploadFile();\n    }\n    \n    if(uploadStatus)\n      xTaskNotifyGive(chatgpt_handle);\n    vTaskDelay(10000);       // Each recording is spaced 10s apart\n  }\n//  vTaskDelete(NULL);\n}\n\nvoid wifiConnect(void *pvParameters){\n  isWIFIConnected = false;\n  Serial.print("Try to connect to ");\n  Serial.println(ssid);\n  WiFi.begin(ssid, password);\n  while(WiFi.status() != WL_CONNECTED){\n    vTaskDelay(500);\n    Serial.print(".");\n  }\n  Serial.println("Wi-Fi Connected!");\n  isWIFIConnected = true;\n  // Ignore SSL certificate validation\n  client.setInsecure();\n  while(true){\n    vTaskDelay(1000);\n  }\n}\n\nvoid chatgpt(void *pvParameters){\n  while(1){\n    // Waiting for notification signal from Task 1\n    ulTaskNotifyTake(pdTRUE, portMAX_DELAY);\n\n    String result;\n    if (chat_gpt.simple_message("gpt-3.5-turbo-0301", "user", chatgpt_Q, result)) {\n      Serial.println("===OK===");\n      Serial.println(result);\n    } else {\n      Serial.println("===ERROR===");\n      Serial.println(result);\n    }\n\n  }\n}\n\n//*****************************************Audio Process******************************************//\n\nvoid generate_wav_header(uint8_t *wav_header, uint32_t wav_size, uint32_t sample_rate)\n{\n  // See this for reference: http://soundfile.sapp.org/doc/WaveFormat/\n  uint32_t file_size = wav_size + WAV_HEADER_SIZE - 8;\n  uint32_t byte_rate = SAMPLE_RATE * SAMPLE_BITS / 8;\n  const uint8_t set_wav_header[] = {\n    \'R\', \'I\', \'F\', \'F\', // ChunkID\n    file_size, file_size >> 8, file_size >> 16, file_size >> 24, // ChunkSize\n    \'W\', \'A\', \'V\', \'E\', // Format\n    \'f\', \'m\', \'t\', \' \', // Subchunk1ID\n    0x10, 0x00, 0x00, 0x00, // Subchunk1Size (16 for PCM)\n    0x01, 0x00, // AudioFormat (1 for PCM)\n    0x01, 0x00, // NumChannels (1 channel)\n    sample_rate, sample_rate >> 8, sample_rate >> 16, sample_rate >> 24, // SampleRate\n    byte_rate, byte_rate >> 8, byte_rate >> 16, byte_rate >> 24, // ByteRate\n    0x02, 0x00, // BlockAlign\n    0x10, 0x00, // BitsPerSample (16 bits)\n    \'d\', \'a\', \'t\', \'a\', // Subchunk2ID\n    wav_size, wav_size >> 8, wav_size >> 16, wav_size >> 24, // Subchunk2Size\n  };\n  memcpy(wav_header, set_wav_header, sizeof(set_wav_header));\n}\n\n//*****************************************File Process******************************************//\n\nvoid listDir(fs::FS &fs, const char * dirname, uint8_t levels){\n    Serial.printf("Listing directory: %s\\n", dirname);\n\n    File root = fs.open(dirname);\n    if(!root){\n        Serial.println("Failed to open directory");\n        return;\n    }\n    if(!root.isDirectory()){\n        Serial.println("Not a directory");\n        return;\n    }\n\n    File file = root.openNextFile();\n    while(file){\n        if(file.isDirectory()){\n            Serial.print("  DIR : ");\n            Serial.println(file.name());\n            if(levels){\n                listDir(fs, file.path(), levels -1);\n            }\n        } else {\n            Serial.print("  FILE: ");\n            Serial.print(file.name());\n            Serial.print("  SIZE: ");\n            Serial.println(file.size());\n        }\n        file = root.openNextFile();\n    }\n}\n\nbool uploadFile(){\n  file = SD.open(filename, FILE_READ);\n  if(!file){\n    Serial.println("FILE IS NOT AVAILABLE!");\n    return false;\n  }\n\n  Serial.println("===> Upload FILE to Node.js Server");\n\n  HTTPClient client;\n  client.begin("http://192.168.1.208:8888/uploadAudio");\n  client.addHeader("Content-Type", "audio/wav");\n  int httpResponseCode = client.sendRequest("POST", &file, file.size());\n  Serial.print("httpResponseCode : ");\n  Serial.println(httpResponseCode);\n\n  if(httpResponseCode == 200){\n    String response = client.getString();\n    Serial.println("==================== Transcription ====================");\n    Serial.println(response);\n    chatgpt_Q = response;\n    Serial.println("====================      End      ====================");\n    file.close();\n    client.end();\n    return true;\n  }else{\n    Serial.println("Error");\n    return false;\n  }\n  \n}\n'))),(0,o.kt)("p",null,"Again, before this program can be used, you will need to make the following changes to the code as you see fit"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("strong",{parentName:"li"},"WiFi name of the network")," - Change the network name of the code ",(0,o.kt)("a",{parentName:"li",href:"https://github.com/limengdu/XIAO-ESP32S3Sense-Speech2ChatGPT/blob/404007a16f42495576d729848d00c6bb6a8149fc/XIAOESP32S3-SPEECH-TO-CHATGPT/XIAOESP32S3-SPEECH-TO-CHATGPT.ino#L18"},"line 18")," to the name of the network under the same LAN as the host where you are deploying Google Cloud Services."),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("strong",{parentName:"li"},"WiFi password of the network")," - On ",(0,o.kt)("a",{parentName:"li",href:"https://github.com/limengdu/XIAO-ESP32S3Sense-Speech2ChatGPT/blob/404007a16f42495576d729848d00c6bb6a8149fc/XIAOESP32S3-SPEECH-TO-CHATGPT/XIAOESP32S3-SPEECH-TO-CHATGPT.ino#LL19C40-L19C40"},"line 19")," of the code, change the password corresponding to the network."),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("strong",{parentName:"li"},"Host IP address")," - On ",(0,o.kt)("a",{parentName:"li",href:"https://github.com/limengdu/XIAO-ESP32S3Sense-Speech2ChatGPT/blob/404007a16f42495576d729848d00c6bb6a8149fc/XIAOESP32S3-SPEECH-TO-CHATGPT/XIAOESP32S3-SPEECH-TO-CHATGPT.ino#LL241C7-L241C7"},"line 241")," of the code, you need to change the IP address here to your host IP address and keep the port number at 8888."),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("strong",{parentName:"li"},"OpenAI API Token")," - Since you need to call the ChatGPT interface, you need to prepare the OpenAI Token and fill it into the code ",(0,o.kt)("a",{parentName:"li",href:"https://github.com/limengdu/XIAO-ESP32S3Sense-Speech2ChatGPT/blob/404007a16f42495576d729848d00c6bb6a8149fc/XIAOESP32S3-SPEECH-TO-CHATGPT/XIAOESP32S3-SPEECH-TO-CHATGPT.ino#L33"},"line 33"),". If this is your first time using Tokens, you can read the ",(0,o.kt)("a",{parentName:"li",href:"https://wiki.seeedstudio.com/xiaoesp32c3-chatgpt/#submit-questions-via-the-built-in-web-page"},"content of this Wiki")," to learn how to obtain them.")),(0,o.kt)("p",null,"Once modified, upload the program and turn on the serial monitor. After recording, you will see the answer returned by ChatGPT for your question."),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/xiaoesp32s3sense-speech2chatgpt/16.png",style:{width:1e3,height:"auto"}})),(0,o.kt)("h2",{id:"design-of-screen-display-content--integration-of-programs"},"Design of screen display content & Integration of programs"),(0,o.kt)("p",null,"Finally, we add a little more fancy. Instead of using a serial monitor, which is a less suitable interface for displaying effects, we have used a touch screen for the touch and click function."),(0,o.kt)("h3",{id:"step-13-using-squareline-studio-to-draw-display-screens"},"Step 13. Using SquareLine Studio to draw display screens"),(0,o.kt)("p",null,"SquareLine Studio is a GUI design tool developed by LVGL, a graphics library for embedded systems. SquareLine Studio is designed to help developers create and design user interfaces for their embedded systems quickly and efficiently. It provides a drag-and-drop interface for designing UIs, and it supports various widgets and themes."),(0,o.kt)("p",null,"So we recommend you to use this tool to design such simple interfaces. If you want to know more about the use of Round Display in SquareLine Studio, you can go to our usage ",(0,o.kt)("a",{parentName:"p",href:"https://wiki.seeedstudio.com/using_lvgl_and_tft_on_round_display/#drawing-complex-ui-interfaces-with-squareline-studio"},"Wiki"),"."),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/xiaoesp32s3sense-speech2chatgpt/21.png",style:{width:1e3,height:"auto"}})),(0,o.kt)("p",null,"For reasons of space, this article will not go into detail on how to design a display page, but we will provide the exported program code which you can use. It is currently in the ",(0,o.kt)("strong",{parentName:"p"},"ui")," folder under that ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/limengdu/XIAO-ESP32S3Sense-Speech2ChatGPT/tree/main/ui"},"project folder"),"."),(0,o.kt)("admonition",{type:"caution"},(0,o.kt)("p",{parentName:"admonition"},"We recommend you to use the ",(0,o.kt)("strong",{parentName:"p"},"v1.2.3")," version of SquareLine Studio. After testing, the v1.3.0 version can have compatibility problems with the tft_eSPI library.")),(0,o.kt)("h3",{id:"step-14-integration-procedures"},"Step 14. Integration procedures"),(0,o.kt)("p",null,"The final complete project code is in the ",(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("a",{parentName:"strong",href:"https://github.com/limengdu/XIAO-ESP32S3Sense-Speech2ChatGPT/blob/main/XIAOESP32S3-SPEECH-CHATGPT-COMPLETE/XIAOESP32S3-SPEECH-CHATGPT-COMPLETE.ino"},"XIAOESP32S3-SPEECH-CHATGPT-COMPLETE"))," folder."),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Click to preview the full program"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-cpp"},'#include <lvgl.h>\n#include <TFT_eSPI.h>\n#include "ui.h"\n#include <WiFi.h>\n#include <WiFiClientSecure.h>\n#include <ArduinoJson.h>\n#include <ChatGPT.hpp>\n#include <I2S.h>\n#include <HTTPClient.h>\n#include "FS.h"\n#include "SD.h"\n#include "SPI.h"\n\n\n// Import the library for the round display and define the frame used as the TFT display frame\n#define USE_TFT_ESPI_LIBRARY\n#include "lv_xiao_round_screen.h"\n\n\n/*Change to your screen resolution*/\nstatic const uint16_t screenWidth  = 240;\nstatic const uint16_t screenHeight = 240;\n\n\n// Variables to be used in the recording program, do not change for best\n#define SAMPLE_RATE 16000U\n#define SAMPLE_BITS 16\n#define WAV_HEADER_SIZE 44\n#define VOLUME_GAIN 2\n#define RECORD_TIME 5  // seconds, The maximum value is 240\n\n\n// Number of bytes required for the recording buffer\nuint32_t record_size = (SAMPLE_RATE * SAMPLE_BITS / 8) * RECORD_TIME;\n\n\n// Name of the file in which the recording is saved\nFile file;\nconst char filename[] = "/recording.wav";\n\n\n// Network connection status flag\nbool isWIFIConnected;\n\n\n// Answers to the questions chatgpt replied to\nString response;\n\n\n// Flags for different task starts\nbool recordTask = false;\nbool chatgptTask = false;\n\nWiFiClientSecure client;\nChatGPT<WiFiClientSecure> chat_gpt(&client, "v1", "OpenAI-TOKEN");   // Please fill in your OpenAI key\n\n\n// Please change to your network\nconst char* ssid = "wifi-ssid";\nconst char* password = "wifi-password";\n\nstatic lv_disp_draw_buf_t draw_buf;\nstatic lv_color_t buf[ screenWidth * screenHeight / 10 ];\n\n\n//****************************************LVGL****************************************************//\n\n#if LV_USE_LOG != 0\n/* Serial debugging */\nvoid my_print(const char * buf)\n{\n    Serial.printf(buf);\n    Serial.flush();\n}\n#endif\n\n/* Display flushing */\nvoid my_disp_flush( lv_disp_drv_t *disp, const lv_area_t *area, lv_color_t *color_p )\n{\n    uint32_t w = ( area->x2 - area->x1 + 1 );\n    uint32_t h = ( area->y2 - area->y1 + 1 );\n\n    tft.startWrite();\n    tft.setAddrWindow( area->x1, area->y1, w, h );\n    tft.pushColors( ( uint16_t * )&color_p->full, w * h, true );\n    tft.endWrite();\n\n    lv_disp_flush_ready( disp );\n}\n\n/*Read the touchpad*/\nvoid my_touchpad_read( lv_indev_drv_t * indev_driver, lv_indev_data_t * data )\n{\n    // uint16_t touchX = 0, touchY = 0;\n    // bool touched = false;//tft.getTouch( &touchX, &touchY, 600 );\n\n    lv_coord_t touchX, touchY;\n    chsc6x_get_xy(&touchX, &touchY);\n\n    // if( !touched )\n    if(!chsc6x_is_pressed())\n    {\n        data->state = LV_INDEV_STATE_REL;\n    }\n    else\n    {\n        data->state = LV_INDEV_STATE_PR;\n\n        /*Set the coordinates*/\n        data->point.x = touchX;\n        data->point.y = touchY;\n\n//        Serial.print( "Data x " );\n//        Serial.println( touchX );\n//\n//        Serial.print( "Data y " );\n//        Serial.println( touchY );\n\n        // You can also start recording by uncommenting and configuring by clicking on the logo\n//        if((touchX < 240 && touchX > 230) && (touchY < 120 && touchY > 100)){\n          recordTask = true;\n//        }\n    }\n}\n\n//****************************************Arduino Base****************************************************//\n\nvoid setup()\n{\n    Serial.begin( 115200 ); /* prepare for possible serial debug */\n//    while(!Serial);\n\n    pinMode(TOUCH_INT, INPUT_PULLUP);\n    Wire.begin();\n\n    String LVGL_Arduino = "Hello Arduino! ";\n    LVGL_Arduino += String(\'V\') + lv_version_major() + "." + lv_version_minor() + "." + lv_version_patch();\n\n    Serial.println( LVGL_Arduino );\n    Serial.println( "I am LVGL_Arduino" );\n\n    lv_init();\n\n#if LV_USE_LOG != 0\n    lv_log_register_print_cb( my_print ); /* register print function for debugging */\n#endif\n\n    tft.begin();          /* TFT init */\n    tft.setRotation( 0 ); /* Landscape orientation, flipped */\n\n    lv_disp_draw_buf_init( &draw_buf, buf, NULL, screenWidth * screenHeight / 10 );\n\n    /*Initialize the display*/\n    static lv_disp_drv_t disp_drv;\n    lv_disp_drv_init( &disp_drv );\n    /*Change the following line to your display resolution*/\n    disp_drv.hor_res = screenWidth;\n    disp_drv.ver_res = screenHeight;\n    disp_drv.flush_cb = my_disp_flush;\n    disp_drv.draw_buf = &draw_buf;\n    lv_disp_drv_register( &disp_drv );\n\n    /*Initialize the (dummy) input device driver*/\n    static lv_indev_drv_t indev_drv;\n    lv_indev_drv_init( &indev_drv );\n    indev_drv.type = LV_INDEV_TYPE_POINTER;\n    indev_drv.read_cb = my_touchpad_read;\n    lv_indev_drv_register( &indev_drv );\n\n    ui_init();\n\n    I2S.setAllPins(-1, 42, 41, -1, -1);\n  \n    //The transmission mode is PDM_MONO_MODE, which means that PDM (pulse density modulation) mono mode is used for transmission\n    if (!I2S.begin(PDM_MONO_MODE, SAMPLE_RATE, SAMPLE_BITS)) {\n        Serial.println("Failed to initialize I2S!");\n        while (1) ;\n    }\n\n    if(!SD.begin(D2)){\n        Serial.println("Failed to mount SD Card!");\n        while (1) ;\n    }\n\n    Serial.println( "Setup done" );\n\n    // Create a FreeRTOS task to check the connection status of the network at regular intervals.\n    xTaskCreate(wifiConnect, "wifi_Connect", 4096, NULL, 0, NULL);\n}\n\nvoid loop()\n{\n    lv_timer_handler(); /* let the GUI do its work */\n    record();\n    chatgpt();\n    delay(5);\n}\n\n//*****************************************Audio Process******************************************//\n\nvoid generate_wav_header(uint8_t *wav_header, uint32_t wav_size, uint32_t sample_rate)\n{\n  // See this for reference: http://soundfile.sapp.org/doc/WaveFormat/\n  uint32_t file_size = wav_size + WAV_HEADER_SIZE - 8;\n  uint32_t byte_rate = SAMPLE_RATE * SAMPLE_BITS / 8;\n  const uint8_t set_wav_header[] = {\n    \'R\', \'I\', \'F\', \'F\', // ChunkID\n    file_size, file_size >> 8, file_size >> 16, file_size >> 24, // ChunkSize\n    \'W\', \'A\', \'V\', \'E\', // Format\n    \'f\', \'m\', \'t\', \' \', // Subchunk1ID\n    0x10, 0x00, 0x00, 0x00, // Subchunk1Size (16 for PCM)\n    0x01, 0x00, // AudioFormat (1 for PCM)\n    0x01, 0x00, // NumChannels (1 channel)\n    sample_rate, sample_rate >> 8, sample_rate >> 16, sample_rate >> 24, // SampleRate\n    byte_rate, byte_rate >> 8, byte_rate >> 16, byte_rate >> 24, // ByteRate\n    0x02, 0x00, // BlockAlign\n    0x10, 0x00, // BitsPerSample (16 bits)\n    \'d\', \'a\', \'t\', \'a\', // Subchunk2ID\n    wav_size, wav_size >> 8, wav_size >> 16, wav_size >> 24, // Subchunk2Size\n  };\n  memcpy(wav_header, set_wav_header, sizeof(set_wav_header));\n}\n\n//*****************************************File Process******************************************//\n\nvoid listDir(fs::FS &fs, const char * dirname, uint8_t levels){\n    Serial.printf("Listing directory: %s\\n", dirname);\n\n    File root = fs.open(dirname);\n    if(!root){\n        Serial.println("Failed to open directory");\n        return;\n    }\n    if(!root.isDirectory()){\n        Serial.println("Not a directory");\n        return;\n    }\n\n    File file = root.openNextFile();\n    while(file){\n        if(file.isDirectory()){\n            Serial.print("  DIR : ");\n            Serial.println(file.name());\n            if(levels){\n                listDir(fs, file.path(), levels -1);\n            }\n        } else {\n            Serial.print("  FILE: ");\n            Serial.print(file.name());\n            Serial.print("  SIZE: ");\n            Serial.println(file.size());\n        }\n        file = root.openNextFile();\n    }\n}\n\nbool uploadFile(){\n  file = SD.open(filename, FILE_READ);\n  if(!file){\n    Serial.println("FILE IS NOT AVAILABLE!");\n    return false;\n  }\n\n  Serial.println("===> Upload FILE to Node.js Server");\n\n  HTTPClient client;\n  client.begin("http://192.168.1.208:8888/uploadAudio");\n  client.addHeader("Content-Type", "audio/wav");\n  int httpResponseCode = client.sendRequest("POST", &file, file.size());\n  Serial.print("httpResponseCode : ");\n  Serial.println(httpResponseCode);\n\n  if(httpResponseCode == 200){\n    response = client.getString();\n    Serial.println("==================== Transcription ====================");\n    Serial.println(response);\n    const char* chatgpt_Q = response.c_str();\n    lv_label_set_text(ui_question, chatgpt_Q);\n    Serial.println("====================      End      ====================");\n    file.close();\n    client.end();\n    recordTask = false;\n    chatgptTask = true;\n    return true;\n  }else{\n    Serial.println("Error");\n    lv_label_set_text(ui_question, "Error");\n    recordTask = false;\n    chatgptTask = false;\n    return false;\n  }\n}\n\n\n//*****************************************Main Functions******************************************//\n\nvoid record(){\n  if(recordTask){\n    Serial.println("Record Task Begin!!!");\n    lv_label_set_text(ui_question, "Recording ...");\n    lv_timer_handler();\n    uint32_t sample_size = 0;\n    \n    // This variable will be used to point to the actual recording buffer\n    uint8_t *rec_buffer = NULL;\n    Serial.printf("Ready to start recording ...\\n");\n  \n    File file = SD.open(filename, FILE_WRITE);\n  \n    // Write the header to the WAV file\n    uint8_t wav_header[WAV_HEADER_SIZE];\n  \n    // Write the WAV file header information to the wav_header array\n    generate_wav_header(wav_header, record_size, SAMPLE_RATE);\n  \n    // Call the file.write() function to write the data in the wav_header array to the newly created WAV file\n    file.write(wav_header, WAV_HEADER_SIZE);\n  \n    // This code uses the ESP32\'s PSRAM (external cache memory) to dynamically allocate a section of memory to store the recording data.\n    rec_buffer = (uint8_t *)ps_malloc(record_size);\n    if (rec_buffer == NULL) {\n      Serial.printf("malloc failed!\\n");\n      while(1) ;\n    }\n    Serial.printf("Buffer: %d bytes\\n", ESP.getPsramSize() - ESP.getFreePsram());\n  \n    // Start recording\n    // I2S port number (in this case I2S_NUM_0), \n    // a pointer to the buffer to which the data is to be written (i.e. rec_buffer),\n    // the size of the data to be read (i.e. record_size),\n    // a pointer to a variable that points to the actual size of the data being read (i.e. &sample_size),\n    // and the maximum time to wait for the data to be read (in this case portMAX_DELAY, indicating an infinite wait time).\n    esp_i2s::i2s_read(esp_i2s::I2S_NUM_0, rec_buffer, record_size, &sample_size, portMAX_DELAY);\n    if (sample_size == 0) {\n      Serial.printf("Record Failed!\\n");\n    } else {\n      Serial.printf("Record %d bytes\\n", sample_size);\n    }\n  \n    // Increase volume\n    for (uint32_t i = 0; i < sample_size; i += SAMPLE_BITS/8) {\n      (*(uint16_t *)(rec_buffer+i)) <<= VOLUME_GAIN;\n    }\n  \n    // Write data to the WAV file\n    Serial.printf("Writing to the file ...\\n");\n    if (file.write(rec_buffer, record_size) != record_size)\n      Serial.printf("Write file Failed!\\n");\n  \n    free(rec_buffer);\n    rec_buffer = NULL;\n    file.close();\n    Serial.printf("The recording is over.\\n");\n    lv_label_set_text(ui_question, "Identifying ...");\n    lv_timer_handler();\n    listDir(SD, "/", 0);\n  \n    bool uploadStatus = false;\n  \n    if(isWIFIConnected){\n      uploadStatus = uploadFile();\n    }\n  }\n}\n\nvoid chatgpt(){\n  if(chatgptTask){\n    Serial.println("ChatGPT Task Begin!!!");\n    lv_label_set_text(ui_answer,"Answering ...");\n    lv_timer_handler();\n    String result;\n    if (chat_gpt.simple_message("gpt-3.5-turbo-0301", "user", response, result)) {\n      Serial.println("===OK===");\n      Serial.println(result);\n      const char* chatgpt_A = result.c_str();\n      lv_label_set_text(ui_answer, chatgpt_A);\n    } else {\n      Serial.println("===ERROR===");\n      Serial.println(result);\n      lv_label_set_text(ui_answer, "ERROR");\n      lv_timer_handler();\n    }\n    recordTask = false;\n    chatgptTask = false;\n  }\n}\n\n//*****************************************RTOS******************************************//\n\nvoid wifiConnect(void *pvParameters){\n  isWIFIConnected = false;\n  Serial.print("Try to connect to ");\n  Serial.println(ssid);\n  WiFi.begin(ssid, password);\n  while(WiFi.status() != WL_CONNECTED){\n    vTaskDelay(500);\n    Serial.print(".");\n  }\n  Serial.println("Wi-Fi Connected!");\n  isWIFIConnected = true;\n  // Ignore SSL certificate validation\n  client.setInsecure();\n  while(true){\n    vTaskDelay(1000);\n  }\n}\n'))),(0,o.kt)("p",null,"Before compiling and uploading the example program, there are a few things you will need to change to suit your situation."),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("strong",{parentName:"li"},"WiFi name of the network")," - Change the network name of the code ",(0,o.kt)("a",{parentName:"li",href:"https://github.com/limengdu/XIAO-ESP32S3Sense-Speech2ChatGPT/blob/404007a16f42495576d729848d00c6bb6a8149fc/XIAOESP32S3-SPEECH-TO-CHATGPT/XIAOESP32S3-SPEECH-TO-CHATGPT.ino#L18"},"line 18")," to the name of the network under the same LAN as the host where you are deploying Google Cloud Services."),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("strong",{parentName:"li"},"WiFi password of the network")," - On ",(0,o.kt)("a",{parentName:"li",href:"https://github.com/limengdu/XIAO-ESP32S3Sense-Speech2ChatGPT/blob/404007a16f42495576d729848d00c6bb6a8149fc/XIAOESP32S3-SPEECH-TO-CHATGPT/XIAOESP32S3-SPEECH-TO-CHATGPT.ino#LL19C40-L19C40"},"line 19")," of the code, change the password corresponding to the network."),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("strong",{parentName:"li"},"Host IP address")," - On ",(0,o.kt)("a",{parentName:"li",href:"https://github.com/limengdu/XIAO-ESP32S3Sense-Speech2ChatGPT/blob/404007a16f42495576d729848d00c6bb6a8149fc/XIAOESP32S3-SPEECH-TO-CHATGPT/XIAOESP32S3-SPEECH-TO-CHATGPT.ino#LL241C7-L241C7"},"line 241")," of the code, you need to change the IP address here to your host IP address and keep the port number at 8888."),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("strong",{parentName:"li"},"OpenAI API Token")," - Since you need to call the ChatGPT interface, you need to prepare the OpenAI Token and fill it into the code ",(0,o.kt)("a",{parentName:"li",href:"https://github.com/limengdu/XIAO-ESP32S3Sense-Speech2ChatGPT/blob/404007a16f42495576d729848d00c6bb6a8149fc/XIAOESP32S3-SPEECH-TO-CHATGPT/XIAOESP32S3-SPEECH-TO-CHATGPT.ino#L33"},"line 33"),". If this is your first time using Tokens, you can read the ",(0,o.kt)("a",{parentName:"li",href:"https://wiki.seeedstudio.com/xiaoesp32c3-chatgpt/#submit-questions-via-the-built-in-web-page"},"content of this Wiki")," to learn how to obtain them.")),(0,o.kt)("p",null,"Once you have uploaded the program and clicked on the screen, the recording task will begin, at which point you can speak the question you wish to ask towards the microphone. Once the result has been recognised, the question is displayed in the top half of the screen. Immediately afterwards, we will get the answer to the ChatGPT and it will be displayed at the bottom of the screen."),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:"https://files.seeedstudio.com/wiki/xiaoesp32s3sense-speech2chatgpt/22.jpg",style:{width:600,height:"auto"}})),(0,o.kt)("h2",{id:"tech-support--product-discussion"},"Tech Support & Product Discussion"),(0,o.kt)("p",null,"Thank you for choosing our products! We are here to provide you with different support to ensure that your experience with our products is as smooth as possible. We offer several communication channels to cater to different preferences and needs."),(0,o.kt)("div",{class:"button_tech_support_container"},(0,o.kt)("a",{href:"https://forum.seeedstudio.com/",class:"button_forum"}),(0,o.kt)("a",{href:"https://www.seeedstudio.com/contacts",class:"button_email"})),(0,o.kt)("div",{class:"button_tech_support_container"},(0,o.kt)("a",{href:"https://discord.gg/eWkprNDMU7",class:"button_discord"}),(0,o.kt)("a",{href:"https://github.com/Seeed-Studio/wiki-documents/discussions/69",class:"button_discussion"})))}f.isMDXComponent=!0}}]);