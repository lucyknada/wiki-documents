"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[69875],{3905:(e,n,t)=>{t.d(n,{Zo:()=>p,kt:()=>m});var r=t(67294);function s(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function a(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?a(Object(t),!0).forEach((function(n){s(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function _(e,n){if(null==e)return{};var t,r,s=function(e,n){if(null==e)return{};var t,r,s={},a=Object.keys(e);for(r=0;r<a.length;r++)t=a[r],n.indexOf(t)>=0||(s[t]=e[t]);return s}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)t=a[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(s[t]=e[t])}return s}var o=r.createContext({}),l=function(e){var n=r.useContext(o),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},p=function(e){var n=l(e.components);return r.createElement(o.Provider,{value:n},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},u=r.forwardRef((function(e,n){var t=e.components,s=e.mdxType,a=e.originalType,o=e.parentName,p=_(e,["components","mdxType","originalType","parentName"]),c=l(t),u=s,m=c["".concat(o,".").concat(u)]||c[u]||d[u]||a;return t?r.createElement(m,i(i({ref:n},p),{},{components:t})):r.createElement(m,i({ref:n},p))}));function m(e,n){var t=arguments,s=n&&n.mdxType;if("string"==typeof e||s){var a=t.length,i=new Array(a);i[0]=u;var _={};for(var o in n)hasOwnProperty.call(n,o)&&(_[o]=n[o]);_.originalType=e,_[c]="string"==typeof e?e:s,i[1]=_;for(var l=2;l<a;l++)i[l]=t[l];return r.createElement.apply(null,i)}return r.createElement.apply(null,t)}u.displayName="MDXCreateElement"},85162:(e,n,t)=>{t.d(n,{Z:()=>i});var r=t(67294),s=t(86010);const a="tabItem_Ymn6";function i(e){let{children:n,hidden:t,className:i}=e;return r.createElement("div",{role:"tabpanel",className:(0,s.Z)(a,i),hidden:t},n)}},65488:(e,n,t)=>{t.d(n,{Z:()=>u});var r=t(87462),s=t(67294),a=t(86010),i=t(72389),_=t(67392),o=t(7094),l=t(12466);const p="tabList__CuJ",c="tabItem_LNqP";function d(e){const{lazy:n,block:t,defaultValue:i,values:d,groupId:u,className:m}=e,f=s.Children.map(e.children,(e=>{if((0,s.isValidElement)(e)&&"value"in e.props)return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})),h=d??f.map((e=>{let{props:{value:n,label:t,attributes:r}}=e;return{value:n,label:t,attributes:r}})),E=(0,_.l)(h,((e,n)=>e.value===n.value));if(E.length>0)throw new Error(`Docusaurus error: Duplicate values "${E.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`);const b=null===i?i:i??f.find((e=>e.props.default))?.props.value??f[0].props.value;if(null!==b&&!h.some((e=>e.value===b)))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${b}" but none of its children has the corresponding value. Available values are: ${h.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);const{tabGroupChoices:S,setTabGroupChoices:g}=(0,o.U)(),[v,L]=(0,s.useState)(b),T=[],{blockElementScrollPositionUntilNextRender:A}=(0,l.o5)();if(null!=u){const e=S[u];null!=e&&e!==v&&h.some((n=>n.value===e))&&L(e)}const P=e=>{const n=e.currentTarget,t=T.indexOf(n),r=h[t].value;r!==v&&(A(n),L(r),null!=u&&g(u,String(r)))},w=e=>{let n=null;switch(e.key){case"Enter":P(e);break;case"ArrowRight":{const t=T.indexOf(e.currentTarget)+1;n=T[t]??T[0];break}case"ArrowLeft":{const t=T.indexOf(e.currentTarget)-1;n=T[t]??T[T.length-1];break}}n?.focus()};return s.createElement("div",{className:(0,a.Z)("tabs-container",p)},s.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,a.Z)("tabs",{"tabs--block":t},m)},h.map((e=>{let{value:n,label:t,attributes:i}=e;return s.createElement("li",(0,r.Z)({role:"tab",tabIndex:v===n?0:-1,"aria-selected":v===n,key:n,ref:e=>T.push(e),onKeyDown:w,onClick:P},i,{className:(0,a.Z)("tabs__item",c,i?.className,{"tabs__item--active":v===n})}),t??n)}))),n?(0,s.cloneElement)(f.filter((e=>e.props.value===v))[0],{className:"margin-top--md"}):s.createElement("div",{className:"margin-top--md"},f.map(((e,n)=>(0,s.cloneElement)(e,{key:n,hidden:e.props.value!==v})))))}function u(e){const n=(0,i.Z)();return s.createElement(d,(0,r.Z)({key:String(n)},e))}},36161:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>p,contentTitle:()=>o,default:()=>u,frontMatter:()=>_,metadata:()=>l,toc:()=>c});var r=t(87462),s=(t(67294),t(3905)),a=t(65488),i=t(85162);const _={description:"ChatGPT X DALL\xb7E with Indicator",title:"ChatGPT X DALL\xb7E X SenseCAP Indicator",keywords:["SenseCAP Indicator ChatGPT DALL\xb7E Application Development"],image:"https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png",slug:"/SenseCAP_Indicator_Application_ChatGPT",last_update:{date:"5/31/2023",author:"Thomas"}},o="SenseCAP Indicator X ChatGPT X DALL\xb7E Application Development",l={unversionedId:"Sensor/SenseCAP/SenseCAP_Indicator/Application/OpenAI",id:"Sensor/SenseCAP/SenseCAP_Indicator/Application/OpenAI",title:"ChatGPT X DALL\xb7E X SenseCAP Indicator",description:"ChatGPT X DALL\xb7E with Indicator",source:"@site/docs/Sensor/SenseCAP/SenseCAP_Indicator/Application/OpenAI.md",sourceDirName:"Sensor/SenseCAP/SenseCAP_Indicator/Application",slug:"/SenseCAP_Indicator_Application_ChatGPT",permalink:"/SenseCAP_Indicator_Application_ChatGPT",draft:!1,editUrl:"https://github.com/Seeed-Studio/wiki-documents/blob/docusaurus-version/docs/Sensor/SenseCAP/SenseCAP_Indicator/Application/OpenAI.md",tags:[],version:"current",lastUpdatedBy:"Thomas",lastUpdatedAt:1685491200,formattedLastUpdatedAt:"May 31, 2023",frontMatter:{description:"ChatGPT X DALL\xb7E with Indicator",title:"ChatGPT X DALL\xb7E X SenseCAP Indicator",keywords:["SenseCAP Indicator ChatGPT DALL\xb7E Application Development"],image:"https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png",slug:"/SenseCAP_Indicator_Application_ChatGPT",last_update:{date:"5/31/2023",author:"Thomas"}},sidebar:"ProductSidebar",previous:{title:"How To Flash The Native Firmware",permalink:"/SenseCAP_Indicator_How_To_Flash_The_Default_Firmware"},next:{title:"Home Assistant X SenseCAP Indicator",permalink:"/SenseCAP_Indicator_Application_Home_Assistant"}},p={},c=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Get Started",id:"get-started",level:2},{value:"Function",id:"function",level:3},{value:"<strong>ChatGPT flowchart</strong>",id:"chatgpt-flowchart",level:4},{value:"<strong>DALL\xb7E flowchart</strong>",id:"dalle-flowchart",level:4},{value:"Example Code",id:"example-code",level:2},{value:"Resources",id:"resources",level:2},{value:"<strong>Tech Support</strong>",id:"tech-support",level:2}],d={toc:c};function u(e){let{components:n,...t}=e;return(0,s.kt)("wrapper",(0,r.Z)({},d,t,{components:n,mdxType:"MDXLayout"}),(0,s.kt)("h1",{id:"sensecap-indicator-x-chatgpt-x-dalle-application-development"},"SenseCAP Indicator X ChatGPT X DALL\xb7E Application Development"),(0,s.kt)("center",null,(0,s.kt)("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/xUX47UnT7xk",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",allowfullscreen:!0})),(0,s.kt)("br",null),(0,s.kt)("p",null,"This guide will provide you with information on how to organize the OpenAI Demo for quick addition, deletion, and modification of programs according to the provided BSP (Board Support Package)."),(0,s.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"One ",(0,s.kt)("a",{parentName:"li",href:"https://www.seeedstudio.com/SenseCAP-Indicator-D1-p-5643.html"},"SenseCAP Indicator")),(0,s.kt)("li",{parentName:"ul"},"The ",(0,s.kt)("a",{parentName:"li",href:"https://github.com/espressif/esp-idf"},"ESP-IDF")," toolchain installed on your computer")),(0,s.kt)("admonition",{type:"tip"},(0,s.kt)("p",{parentName:"admonition"},"If you want to learn how to change the user interface (UI), you can refer to the guide: ",(0,s.kt)("a",{parentName:"p",href:"/SenseCAP_Indicator_How_to_Create_your_own_UI"},"How to Create your own UI")),(0,s.kt)("p",{parentName:"admonition"},"If you haven't installed the IDF toolchain yet, you can follow the instructions in the guide: ",(0,s.kt)("a",{parentName:"p",href:"/SenseCAP_Indicator_How_To_Flash_The_Default_Firmware"},"How_To_Flash_The_Default_Firmware"))),(0,s.kt)("h2",{id:"get-started"},"Get Started"),(0,s.kt)("div",{align:"center"},(0,s.kt)("img",{width:680,src:"https://files.seeedstudio.com/wiki/SenseCAP/SenseCAP_Indicator/GPT_RES_BE_RICH.JPG"})),(0,s.kt)("div",{align:"center"},(0,s.kt)("img",{width:680,src:"https://files.seeedstudio.com/wiki/SenseCAP/SenseCAP_Indicator/DALL_1_CAT.JPG"})),(0,s.kt)("p",null,"The main code related to the OpenAI startup flowchart is shown below:"),(0,s.kt)("div",{align:"center"},(0,s.kt)("img",{width:800,src:"https://files.seeedstudio.com/wiki/SenseCAP/SenseCAP_Indicator/Indicator_openai_sys.png"})),(0,s.kt)("h3",{id:"function"},"Function"),(0,s.kt)("p",null,"The SenseCAP Indicator x ChatGPT x DALL\xb7E Application is developed based on the MVC (Model-View-Controller) architecture. The project's workflow indicates its reliance on the MVC architecture."),(0,s.kt)("p",null,"In this architecture, the components are structured as follows:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"View: The View handles various event-triggered signals and utilizes LVGL (Light and Versatile Graphics Library) for driving the display.")),(0,s.kt)("admonition",{type:"note"},(0,s.kt)("p",{parentName:"admonition"},"To quickly build the user interface (UI), you can use ",(0,s.kt)("a",{parentName:"p",href:"https://squareline.io/"},"SquareLine Studio"),", which is also employed in our project. Recommend using SquareLine Studio version 1.3.0 to ensure a smooth and seamless experience while following this guide..")),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"Model: The Model contains the ",(0,s.kt)("inlineCode",{parentName:"li"},"indicator_openai.c")," file, which includes the ",(0,s.kt)("inlineCode",{parentName:"li"},"indicator_openai_init()")," function. When executed at the Model entry, this function sends requests to OpenAI, receives responses, and parses them for display on the screen through the View.")),(0,s.kt)("p",null,"Here are the key functions and workflow of the Model (once ",(0,s.kt)("a",{parentName:"p",href:"/SenseCAP_Indicator_How_to_Set_the_API_Key"},"the API Key")," is saved):"),(0,s.kt)("h4",{id:"chatgpt-flowchart"},(0,s.kt)("strong",{parentName:"h4"},"ChatGPT flowchart")),(0,s.kt)("div",{align:"center"},(0,s.kt)("img",{width:800,src:"https://files.seeedstudio.com/wiki/SenseCAP/SenseCAP_Indicator/model_openai.png"})),(0,s.kt)("h4",{id:"dalle-flowchart"},(0,s.kt)("strong",{parentName:"h4"},"DALL\xb7E flowchart")),(0,s.kt)("div",{align:"center"},(0,s.kt)("img",{width:800,src:"https://files.seeedstudio.com/wiki/SenseCAP/SenseCAP_Indicator/model_openai_DALLE.png"})),(0,s.kt)("h2",{id:"example-code"},"Example Code"),(0,s.kt)("p",null,"To utilize the OpenAI service, we need to implement functions that can send requests to OpenAI, receive responses, and parse the JSON response. The following code snippet illustrates the necessary code structure:"),(0,s.kt)(a.Z,{mdxType:"Tabs"},(0,s.kt)(i.Z,{value:"ChatGPT",label:"ChatGPT Code",mdxType:"TabItem"},(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-c",metastring:'title="openai.c"',title:'"openai.c"'},"/* HTTPS Request & get Response */\nstatic int chat_request(struct view_data_openai_request *p_req,\n                        struct view_data_openai_response *p_resp);\n\n/* Json Prase */\nstatic int __chat_json_prase(const char *p_str, char *p_answer, char *p_err);\n")),(0,s.kt)("p",null,"The ",(0,s.kt)("inlineCode",{parentName:"p"},"chat_request(...)")," function in ",(0,s.kt)("inlineCode",{parentName:"p"},"indicator_openai.c")," is responsible for sending requests to the OpenAI API, receiving responses, and parsing the JSON response. It generates an HTTP request encapsulating user-supplied data and communicates with the server using ",(0,s.kt)("inlineCode",{parentName:"p"},"mbedtls_send_then_recv(...)"),"."),(0,s.kt)("p",null,"To add a prompt to your application, you can modify the ",(0,s.kt)("inlineCode",{parentName:"p"},"data_buf")," variable in the ",(0,s.kt)("inlineCode",{parentName:"p"},"chat_request(...)")," function as follows:"),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"Adding Prompt:")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-c"},'data_len += sprintf(data_buf + data_len, "Your are SenseCAP Indicator, developed by Seeed Studio, has been launched on April 20th, 2023.");\ndata_len += sprintf(data_buf + data_len, "You are a 4-inch touch screen driven by ESP32 and RP2040 dual-MCU,");\ndata_len += sprintf(data_buf + data_len, "and support Wi-Fi/BLE/LoRa communication.");\ndata_len += sprintf(data_buf + data_len, "You are a fully open-source powerful IoT development platform for developers.");\ndata_len += sprintf(data_buf + data_len, "You are on behalf of Seeed Studio to answer requests.");\ndata_len += sprintf(data_buf + data_len, "Each time your answer text should not exceed 100 words.");\ndata_len += sprintf(data_buf + data_len, "My first sentence is [");\ndata_len += sprintf(data_buf + data_len, "%s", p_req->question); // user input\ndata_len += sprintf(data_buf + data_len, "]");\ndata_len += sprintf(data_buf + data_len, "\\"}]}");\n')),(0,s.kt)("p",null,"In this function, ",(0,s.kt)("inlineCode",{parentName:"p"},"mbedtls_send_then_recv")," is called to do the request and get method.")),(0,s.kt)(i.Z,{value:"DALL\xb7E",label:"DALL\xb7E Code",mdxType:"TabItem"},(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-c",metastring:'title="openai.c"',title:'"openai.c"'},"/* HTTPS Request & get Response */\nstatic int image_request(struct view_data_openai_request *p_req,\n                     struct view_data_openai_response *p_resp);\n\n/* Json Prase */\nstatic int __image_json_prase(const char *p_str, char *p_url, char *p_err);\n\n/* prase URL to download */\nstatic void url_prase(char *p_url, char *p_host, char *p_path);\n")),(0,s.kt)("blockquote",null,(0,s.kt)("p",{parentName:"blockquote"},"Principle: When a request is successful, it returns a URL address. By downloading and decoding the image from this URL link, it can be displayed.")),(0,s.kt)("p",null,"Same as ",(0,s.kt)("inlineCode",{parentName:"p"},"ChatGPT Code"),", in the initial request, we will utilize a prompt to obtain the image URL. After acquiring the URL, we will attempt to download the image to the local buffer using the obtained URL."))),(0,s.kt)("hr",null),(0,s.kt)("details",null,(0,s.kt)("summary",null,"ChatGPT & DALL\xb7E Code"),(0,s.kt)("p",null,"For the detailed and latest code, please refer to ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/Seeed-Solution/SenseCAP_Indicator_ESP32/tree/main/examples/indicator_openai"},"SenseCAP Indicator OpenAI"),"."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-c"},'#include "indicator_openai.h"\n#include "cJSON.h"\n#include "esp_http_client.h"\n#include "esp_tls.h"\n#include "freertos/semphr.h"\n\n#include "lwip/dns.h"\n#include "lwip/err.h"\n#include "lwip/netdb.h"\n#include "lwip/sockets.h"\n#include "lwip/sys.h"\n\n#include "esp_crt_bundle.h"\n#include "mbedtls/ctr_drbg.h"\n#include "mbedtls/entropy.h"\n#include "mbedtls/error.h"\n#include "mbedtls/esp_debug.h"\n#include "mbedtls/net_sockets.h"\n#include "mbedtls/platform.h"\n#include "mbedtls/ssl.h"\n#include "nvs.h"\n\nstruct indicator_openai\n{\n};\n\nstatic const char *TAG = "openai";\n\nstatic struct view_data_openai_request request;\nstatic struct view_data_openai_response response;\n\nstatic SemaphoreHandle_t __g_gpt_com_sem;\nstatic SemaphoreHandle_t __g_dalle_com_sem;\nstatic bool net_flag = false;\n\nstatic int request_st_update(int progress, const char* msg)\n{\n    struct view_data_openai_request_st  st;\n    st.progress = progress;\n    strcpy(st.state, msg);\n    esp_event_post_to(view_event_handle, VIEW_EVENT_BASE, VIEW_EVENT_OPENAI_REQUEST_ST, &st, sizeof(st), portMAX_DELAY);\n}\n\nstatic int mbedtls_send_then_recv(char *p_server, char *p_port, char *p_tx,\n                                  size_t tx_len, char *p_rx, size_t rx_len,\n                                  int delay_ms, void(*p_read_cb)(uint8_t *p_data, int len))\n{\n    int ret, flags, len;\n    char buf[512];\n\n    mbedtls_entropy_context entropy;\n    mbedtls_ctr_drbg_context ctr_drbg;\n    mbedtls_ssl_context ssl;\n    mbedtls_x509_crt cacert;\n    mbedtls_ssl_config conf;\n    mbedtls_net_context server_fd;\n\n    memset(&entropy,0, sizeof(entropy) );\n    memset(&ctr_drbg,0, sizeof(ctr_drbg) );\n    memset(&ssl,0, sizeof(ssl) );\n    memset(&cacert,0, sizeof(cacert) );\n    memset(&conf,0, sizeof(conf) );\n    memset(&server_fd,0, sizeof(server_fd) );\n\n    mbedtls_ssl_init(&ssl);\n    mbedtls_x509_crt_init(&cacert);\n    mbedtls_ctr_drbg_init(&ctr_drbg);\n    ESP_LOGI(TAG, "Seeding the random number generator");\n    mbedtls_ssl_config_init(&conf);\n    ESP_LOGI(TAG, "Initializing the entropy source...");\n    mbedtls_entropy_init(&entropy);\n    ESP_LOGI(TAG, "Initializing the ctr_drbg...");\n    if ((ret = mbedtls_ctr_drbg_seed(&ctr_drbg, mbedtls_entropy_func, &entropy,\n                                     NULL, 0)) != 0)\n    {\n        ESP_LOGE(TAG, "mbedtls_ctr_drbg_seed returned %d", ret);\n        return -1;\n    }\n\n    ESP_LOGI(TAG, "Attaching the certificate bundle...");\n    ret = esp_crt_bundle_attach(&conf);\n    if (ret < 0)\n    {\n        ESP_LOGE(TAG, "esp_crt_bundle_attach returned -0x%x\\n\\n", -ret);\n        return -1;\n    }\n    ESP_LOGI(TAG, "Setting hostname for TLS session...");\n    if ((ret = mbedtls_ssl_set_hostname(&ssl, p_server)) != 0)\n    {\n        ESP_LOGE(TAG, "mbedtls_ssl_set_hostname returned -0x%x", -ret);\n        return -1;\n    }\n\n    ESP_LOGI(TAG, "Setting up the SSL/TLS structure...");\n    if ((ret = mbedtls_ssl_config_defaults(&conf, MBEDTLS_SSL_IS_CLIENT,\n                                           MBEDTLS_SSL_TRANSPORT_STREAM,\n                                           MBEDTLS_SSL_PRESET_DEFAULT)) != 0)\n    {\n        ESP_LOGE(TAG, "mbedtls_ssl_config_defaults returned %d", ret);\n        goto exit;\n    }\n\n    mbedtls_ssl_conf_authmode(&conf, MBEDTLS_SSL_VERIFY_OPTIONAL);\n    mbedtls_ssl_conf_ca_chain(&conf, &cacert, NULL);\n    mbedtls_ssl_conf_rng(&conf, mbedtls_ctr_drbg_random, &ctr_drbg);\n#ifdef CONFIG_MBEDTLS_DEBUG\n    mbedtls_esp_enable_debug_log(&conf, CONFIG_MBEDTLS_DEBUG_LEVEL);\n#endif\n\n#ifdef CONFIG_MBEDTLS_SSL_PROTO_TLS1_3\n    mbedtls_ssl_conf_min_version(&conf, MBEDTLS_SSL_MAJOR_VERSION_3,\n                                 MBEDTLS_SSL_MINOR_VERSION_4);\n    mbedtls_ssl_conf_max_version(&conf, MBEDTLS_SSL_MAJOR_VERSION_3,\n                                 MBEDTLS_SSL_MINOR_VERSION_4);\n#endif\n\n    if ((ret = mbedtls_ssl_setup(&ssl, &conf)) != 0)\n    {\n        ESP_LOGE(TAG, "mbedtls_ssl_setup returned -0x%x\\n\\n", -ret);\n        goto exit;\n    }\n\n    mbedtls_net_init(&server_fd);\n\n    ESP_LOGI(TAG, "Connecting to %s:%s...", p_server, p_port);\n\n    if ((ret = mbedtls_net_connect(&server_fd, p_server, p_port,\n                                   MBEDTLS_NET_PROTO_TCP)) != 0)\n    {\n        ESP_LOGE(TAG, "mbedtls_net_connect returned -%x", -ret);\n        goto exit;\n    }\n\n    ESP_LOGI(TAG, "Connected.");\n\n    mbedtls_ssl_set_bio(&ssl, &server_fd, mbedtls_net_send, mbedtls_net_recv,\n                        NULL);\n\n    ESP_LOGI(TAG, "Performing the SSL/TLS handshake...");\n\n    while ((ret = mbedtls_ssl_handshake(&ssl)) != 0)\n    {\n        if (ret != MBEDTLS_ERR_SSL_WANT_READ && ret != MBEDTLS_ERR_SSL_WANT_WRITE)\n        {\n            ESP_LOGE(TAG, "mbedtls_ssl_handshake returned -0x%x", -ret);\n            goto exit;\n        }\n    }\n\n    ESP_LOGI(TAG, "Verifying peer X.509 certificate...");\n\n    if ((flags = mbedtls_ssl_get_verify_result(&ssl)) != 0)\n    {\n        /* In real life, we probably want to close connection if ret != 0 */\n        ESP_LOGW(TAG, "Failed to verify peer certificate!");\n        bzero(buf, sizeof(buf));\n        mbedtls_x509_crt_verify_info(buf, sizeof(buf), "  ! ", flags);\n        ESP_LOGW(TAG, "verification info: %s", buf);\n    }\n    else\n    {\n        ESP_LOGI(TAG, "Certificate verified.");\n    }\n\n    ESP_LOGI(TAG, "Cipher suite is %s", mbedtls_ssl_get_ciphersuite(&ssl));\n\n    ESP_LOGI(TAG, "Writing HTTP request\\r\\n%s", p_tx);\n\n    size_t written_bytes = 0;\n    do\n    {\n        ret = mbedtls_ssl_write(&ssl, (const unsigned char *)p_tx + written_bytes,\n                                tx_len - written_bytes);\n\n        if (ret >= 0)\n        {\n            ESP_LOGI(TAG, "%d bytes written", ret);\n            written_bytes += ret;\n        }\n        else if (ret != MBEDTLS_ERR_SSL_WANT_WRITE &&\n                 ret != MBEDTLS_ERR_SSL_WANT_READ)\n        {\n            ESP_LOGE(TAG, "mbedtls_ssl_write returned -0x%x", -ret);\n            goto exit;\n        }\n    } while (written_bytes < tx_len);\n\n    if (delay_ms > 0)\n    {\n        vTaskDelay(delay_ms / portTICK_PERIOD_MS); // wait\n    }\n\n    ESP_LOGI(TAG, "Reading HTTP response..."); // HERE\uff01\uff01\uff01\n\n    size_t recv_len = 0;\n\n    do\n    {\n        ret = mbedtls_ssl_read(&ssl, (unsigned char *)(p_rx + recv_len), rx_len - recv_len);\n        ESP_LOGI(TAG, "mbedtls_ssl_read returned %d", ret);\n        if (ret == MBEDTLS_ERR_SSL_WANT_READ || ret == MBEDTLS_ERR_SSL_WANT_WRITE)\n            continue;\n\n        if (ret == MBEDTLS_ERR_SSL_PEER_CLOSE_NOTIFY)\n        {\n            ret = 0;\n            break;\n        }\n        if (ret < 0)\n        {\n            ESP_LOGE(TAG, "mbedtls_ssl_read returned -0x%x", -ret);\n            break;\n        }\n        if (ret == 0)\n        {\n            ESP_LOGI(TAG, "connection closed");\n            break;\n        }\n        len = ret;\n\n        // if( recv_len < 512 ) {\n        //     for (int i = 0; (i < len); i++)\n        //     {\n        //         putchar(p_rx[i + recv_len]);\n        //     }\n        // }\n        if( p_read_cb != NULL ) {\n            p_read_cb(NULL, len);\n        }\n        recv_len += len;\n    } while (1);\n\n    ESP_LOGI(TAG, "recv total: %d bytes ", recv_len);\n\n    mbedtls_ssl_close_notify(&ssl);\nexit:\n    mbedtls_ssl_session_reset(&ssl);\n    mbedtls_net_free(&server_fd);\n\n    if (ret != 0)\n    {\n        mbedtls_strerror(ret, buf, 100);\n        ESP_LOGE(TAG, "Last error was: -0x%x - %s", -ret, buf);\n        return -1;\n    }\n\n    return recv_len;\n}\n\n#define WEB_SERVER "api.openai.com"\n#define WEB_PORT "443"\n\nstatic char *p_recv_buf;\nstatic size_t recv_buf_max_len;\n\nstatic char openai_api_key[52];\nstatic bool have_key = false;\n\nstatic int __chat_json_prase(const char *p_str, char *p_answer, char *p_err)\n{\n    int ret = 0;\n\n    cJSON *root = NULL;\n    cJSON *cjson_item = NULL;\n    cJSON *cjson_item1 = NULL;\n    cJSON *cjson_item2 = NULL;\n\n    root = cJSON_Parse(p_str);\n    if (root == NULL)\n    {\n        strcpy(p_err, "Parse json fail");\n        return -1;\n    }\n\n    // {\n    //     "error": {\n    //         "message": "",\n    //         "type": "invalid_request_error",\n    //         "param": null,\n    //         "code": "invalid_api_key"\n    //     }\n    // }\n    cjson_item = cJSON_GetObjectItem(root, "error");\n    if (cjson_item != NULL)\n    {\n        cjson_item1 = cJSON_GetObjectItem(cjson_item, "message");\n        if (cjson_item1 != NULL && cjson_item1->valuestring != NULL && strlen(cjson_item1->valuestring) > 0)\n        {\n            strncpy(p_err, cjson_item1->valuestring, 63);\n        } else {\n            cjson_item1 = cJSON_GetObjectItem(cjson_item, "code");\n            if (cjson_item1 != NULL && cjson_item1->valuestring != NULL)\n            {\n                strncpy(p_err, cjson_item1->valuestring, 63);\n            }\n        }\n        cJSON_Delete(root);\n        return -1;\n    }\n\n    cjson_item = cJSON_GetObjectItem(root, "choices");\n    if (cjson_item != NULL)\n    {\n        cjson_item1 = cJSON_GetObjectItem(cJSON_GetArrayItem(cjson_item, 0), "message");\n\n        if (cjson_item1 != NULL)\n        {\n            cjson_item2 = cJSON_GetObjectItem(cjson_item1, "content");\n\n            if (cjson_item2 != NULL && cjson_item2->valuestring != NULL)\n            {\n                strcpy(p_answer, cjson_item2->valuestring);\n                cJSON_Delete(root);\n                return 0;\n            }\n        }\n    }\n    strcpy(p_err, "Not find answer");\n    return -1;\n}\n\nstatic int chat_request(struct view_data_openai_request *p_req,\n                        struct view_data_openai_response *p_resp)\n{\n    char request_buf[2048];\n    char data_buf[1536];\n\n    int data_len = 0;\n    int ret = 0;\n    int len = 0;\n\n    memset(request_buf, 0, sizeof(request_buf));\n    memset(data_buf, 0, sizeof(data_buf));\n\n    data_len = sprintf(data_buf,\n                       "{\\"model\\":\\"gpt-3.5-turbo\\",\\"temperature\\":0.7, \\"messages\\":[{\\"role\\":"\n                       "\\"user\\",\\"content\\":\\"");\n    data_len += sprintf(data_buf + data_len, "Your are SenseCAP Indicator, developed by Seeed Studio, has been launched on April 20th, 2023.");\n    data_len += sprintf(data_buf + data_len, "You are a 4-inch touch screen driven by ESP32 and RP2040 dual-MCU,");\n    data_len += sprintf(data_buf + data_len, "and support Wi-Fi/BLE/LoRa communication.");\n    data_len += sprintf(data_buf + data_len, "You are a fully open-source powerful IoT development platform for developers.");\n    data_len += sprintf(data_buf + data_len, "You are on behalf of Seeed Studio to answer requests.");\n    data_len += sprintf(data_buf + data_len, "Each time your answer text should not exceed 100 words.");\n    data_len += sprintf(data_buf + data_len, "My first sentence is [");\n    data_len += sprintf(data_buf + data_len, "%s", p_req->question);\n    data_len += sprintf(data_buf + data_len, "]");\n    data_len += sprintf(data_buf + data_len, "\\"}]}");\n\n    len += sprintf(request_buf + len, "POST /v1/chat/completions HTTP/1.0\\r\\n");\n    len += sprintf(request_buf + len, "Host: %s\\r\\n", WEB_SERVER);\n    len += sprintf(request_buf + len, "Connection: Close\\r\\n");\n    len += sprintf(request_buf + len, "Content-Type: application/json\\r\\n");\n    len += sprintf(request_buf + len, "Content-Length: %d\\r\\n", data_len);\n    len += sprintf(request_buf + len, "Authorization: Bearer %s\\r\\n",\n                   openai_api_key);\n    len += sprintf(request_buf + len, "\\r\\n");\n    len += sprintf(request_buf + len, "%s", data_buf);\n\n    memset(p_recv_buf, 0, recv_buf_max_len);\n    ret = mbedtls_send_then_recv(WEB_SERVER, WEB_PORT, request_buf, len,\n                                 p_recv_buf, recv_buf_max_len, 100, NULL);\n    ESP_LOGI(TAG, "mbedtls ret = %d", ret);\n    if (ret < 0)\n    {\n        ESP_LOGE(TAG, "mbedtls request fail");\n        p_resp->ret = 0;\n        strcpy(p_resp->err_msg, "Connect \'api.openai.com\' fail");\n        return -1;\n    }\n    ESP_LOGI(TAG, "Starting using strstr");\n    char *p_json = strstr(p_recv_buf, "\\r\\n\\r\\n");\n    if (p_json == NULL)\n    {\n        ESP_LOGE(TAG, "Response format error");\n        p_resp->ret = 0;\n        strcpy(p_resp->err_msg, "Response format error");\n        return -1;\n    }\n\n    p_json += 4;\n\n    p_resp->p_answer = p_recv_buf + recv_buf_max_len / 2; // use p_recv_buf mem\n\n    ret = __chat_json_prase(p_json, p_resp->p_answer, p_resp->err_msg);\n    if (ret != 0)\n    {\n        p_resp->ret = 0;\n        return -1;\n    }\n    p_resp->ret = 1;\n    return 0;\n}\n\nstatic int __image_json_prase(const char *p_str, char *p_url, char *p_err)\n{\n    int ret = 0;\n\n    cJSON *root = NULL;\n    cJSON *cjson_item = NULL;\n    cJSON *cjson_item1 = NULL;\n    cJSON *cjson_item2 = NULL;\n\n    root = cJSON_Parse(p_str);\n    if (root == NULL)\n    {\n        strcpy(p_err, "Parse json fail");\n        return -1;\n    }\n\n    cjson_item = cJSON_GetObjectItem(root, "error");\n    if (cjson_item != NULL)\n    {\n        cjson_item1 = cJSON_GetObjectItem(cjson_item, "message");\n        if (cjson_item1 != NULL && cjson_item1->valuestring != NULL)\n        {\n            strcpy(p_err, cjson_item1->valuestring);\n        }\n        cJSON_Delete(root);\n        return -1;\n    }\n\n    cjson_item = cJSON_GetObjectItem(root, "data");\n    if (cjson_item != NULL)\n    {\n        cjson_item1 = cJSON_GetObjectItem(cJSON_GetArrayItem(cjson_item, 0), "url");\n\n        if (cjson_item1 != NULL && cjson_item1->valuestring != NULL)\n        {\n            strcpy(p_url, cjson_item1->valuestring);\n            cJSON_Delete(root);\n            return 0;\n        }\n    }\n    strcpy(p_err, "Not find url");\n    return -1;\n}\n\nstatic void url_prase(char *p_url, char *p_host, char *p_path)\n{\n    char *pos1;\n    char *pos2;\n    pos1 = strchr(p_url, \'/\');\n    pos2 = strchr(pos1 + 2, \'/\');\n\n    strncpy(p_host, pos1 + 2, pos2 - (pos1 + 2));\n    strncpy(p_path, pos2, strlen(pos2) + 1);\n}\n\nstatic image_download_progress = 40;\nstatic void image_progress_update_cb(uint8_t *p_data, int len)\n{\n    image_download_progress++;\n    if( image_download_progress >=99) {\n        image_download_progress=99;\n    }\n    if( (image_download_progress%10) == 0) {\n        request_st_update(image_download_progress, "Download image...");\n    }\n}\n\nstatic int image_request(struct view_data_openai_request *p_req,\n                         struct view_data_openai_response *p_resp)\n{\n    char request_buf[1024];\n    char data_buf[1024];\n\n    int data_len = 0;\n    int ret = 0;\n    int len = 0;\n\n    memset(request_buf, 0, sizeof(request_buf));\n    memset(data_buf, 0, sizeof(data_buf));\n\n    if( strlen(request.question) == 0) {\n        strcpy(request.question, "Astronaut riding a horse in space.");\n    }\n\n    data_len =\n    sprintf(data_buf, "{\\"prompt\\":\\"%s\\",\\"n\\":1,\\"size\\":\\"512x512\\"}",\n                p_req->question);\n\n    len += sprintf(request_buf + len, "POST /v1/images/generations HTTP/1.0\\r\\n");\n    len += sprintf(request_buf + len, "Host: %s\\r\\n", WEB_SERVER);\n    len += sprintf(request_buf + len, "Content-Type: application/json\\r\\n");\n    len += sprintf(request_buf + len, "Connection: Close\\r\\n");\n    len += sprintf(request_buf + len, "Content-Length: %d\\r\\n", data_len);\n    len += sprintf(request_buf + len, "Authorization: Bearer %s\\r\\n",\n                   openai_api_key);\n    len += sprintf(request_buf + len, "\\r\\n");\n    len += sprintf(request_buf + len, "%s", data_buf);\n\n    memset(p_recv_buf, 0, recv_buf_max_len);\n\n    image_download_progress = 40;\n    request_st_update( image_download_progress, "Image generation...");\n    ret = mbedtls_send_then_recv(WEB_SERVER, WEB_PORT, request_buf, len,\n                                 p_recv_buf, recv_buf_max_len, 2000, NULL);\n    if (ret < 0)\n    {\n        ESP_LOGE(TAG, "mbedtls request fail");\n        p_resp->ret = 0;\n        strcpy(p_resp->err_msg, "Request fail");\n        return -1;\n    }\n\n    char *p_json = strstr(p_recv_buf, "\\r\\n\\r\\n");\n    if (p_json == NULL)\n    {\n        ESP_LOGE(TAG, "Response format error");\n        p_resp->ret = 0;\n        strcpy(p_resp->err_msg, "Response format error");\n        return -1;\n    }\n\n    p_json += 4;\n\n    memset(data_buf, 0, sizeof(data_buf));\n    ret = __image_json_prase(p_json, data_buf, p_resp->err_msg);\n    if (ret != 0)\n    {\n        p_resp->ret = 0;\n        return -1;\n    }\n\n    // download image\n    ESP_LOGI(TAG, "Download image from (%s)...", data_buf);\n\n    char host[64];\n    char path[512];\n\n    memset(host, 0, sizeof(host));\n    memset(path, 0, sizeof(path));\n    url_prase(data_buf, host, path);\n\n    len = 0;\n    memset(request_buf, 0, sizeof(request_buf));\n    len += sprintf(request_buf + len, "GET %s HTTP/1.0\\r\\n", path);\n    len += sprintf(request_buf + len, "Host: %s\\r\\n", host);\n    len += sprintf(request_buf + len, "Connection: Close\\r\\n");\n    len += sprintf(request_buf + len, "\\r\\n");\n\n    memset(p_recv_buf, 0, recv_buf_max_len);\n    ret = mbedtls_send_then_recv(host, "443", request_buf, len,\n                                 p_recv_buf, recv_buf_max_len, 2000,  image_progress_update_cb);\n    if (ret < 0)\n    {\n        ESP_LOGE(TAG, "Download fail");\n        p_resp->ret = 0;\n        strcpy(p_resp->err_msg, "Download fail");\n        return -1;\n    }\n\n    // find png image len\n    int content_len = 0;\n    char *p_content_len_str = strstr(p_recv_buf, "Content-Length");\n    if( p_content_len_str == NULL ) {\n        ESP_LOGE(TAG, "Content-Length not find");\n        p_resp->ret = 0;\n        strcpy(p_resp->err_msg, "Content-Length not find");\n        return -1;\n    }\n    sscanf(p_content_len_str, "Content-Length: %d", &content_len);\n    ESP_LOGI(TAG, "Content-Length: %d", content_len);\n\n\n    // find png image body\n    char *p_png = strstr(p_recv_buf, "\\r\\n\\r\\n");\n    if (p_json == NULL)\n    {\n        ESP_LOGE(TAG, "Response format error");\n        p_resp->ret = 0;\n        strcpy(p_resp->err_msg, "Response format error");\n        return -1;\n    }\n\n    p_png += 4;\n    p_resp->p_answer = p_png;\n    p_resp->ret = 1;\n    p_resp->len = content_len;\n    return 0;\n}\n\nstatic void __openai_api_key_read(void)\n{\n    esp_err_t ret = 0;\n    int len = sizeof(openai_api_key);\n    ret = indicator_storage_read(OPENAI_API_KEY_STORAGE, (void *)openai_api_key, &len);\n    if (ret == ESP_OK && len == (sizeof(openai_api_key)))\n    {\n        have_key = true;\n        esp_event_post_to(view_event_handle, VIEW_EVENT_BASE, VIEW_EVENT_OPENAI_ST, &have_key, sizeof(have_key), portMAX_DELAY);\n        ESP_LOGI(TAG, "openai_api_key read successful");\n    }\n    else\n    {\n        // err or not find\n        have_key = false;\n        esp_event_post_to(view_event_handle, VIEW_EVENT_BASE, VIEW_EVENT_OPENAI_ST, &have_key, sizeof(have_key), portMAX_DELAY);\n        if (ret == ESP_ERR_NVS_NOT_FOUND)\n        {\n            ESP_LOGI(TAG, "openai_api_key not find");\n        }\n        else\n        {\n            ESP_LOGI(TAG, "openai_api_key read err:%d", ret);\n        }\n    }\n}\n\nstatic int __openai_init()\n{\n    recv_buf_max_len = 1024 * 1024;\n    p_recv_buf = malloc(recv_buf_max_len); // from psram\n    if (p_recv_buf == NULL)\n    {\n        ESP_LOGE(TAG, "malloc %s bytes fail!", recv_buf_max_len);\n    }\n}\n\nstatic void __indicator_openai_task(void *p_arg)\n{\n    int ret = 0;\n    while (1) {\n        if (net_flag) {\n            if (xSemaphoreTake(__g_gpt_com_sem, pdMS_TO_TICKS(100)) == pdTRUE) {\n                ESP_LOGI(TAG, "--\x3e chat request: %s", request.question);\n                memset(&response, 0, sizeof(response));\n                request_st_update(99, "Request...");\n                ret = chat_request(&request, &response);\n                if (ret != 0) {\n                    ESP_LOGE(TAG, "reuest fail: %d, err_msg:%s", response.ret, response.err_msg);\n                    request_st_update(100, "Reuest fail");\n                } else {\n                    ESP_LOGI(TAG, "<-- response:%s", response.p_answer);\n                    request_st_update(100, "Done");\n                }\n                // vTaskDelay(pdMS_TO_TICKS(1000));\n                esp_event_post_to(view_event_handle, VIEW_EVENT_BASE, VIEW_EVENT_CHATGPT_RESPONSE, &response, sizeof(response), portMAX_DELAY);\n            }\n\n            if (xSemaphoreTake(__g_dalle_com_sem, pdMS_TO_TICKS(100)) == pdTRUE)\n            {\n                ESP_LOGI(TAG, "--\x3e dell\xb7e request: %s", request.question);\n                memset(&response, 0, sizeof(response));\n                request_st_update(10, "Request...");\n                ret = image_request(&request, &response);\n                if (ret != 0) {\n                    ESP_LOGE(TAG, "reuest fail: %d, err_msg:%s", response.ret, response.err_msg);\n                    request_st_update(100, "Reuest fail");\n                } else {\n                    // ESP_LOGI(TAG, "<-- response:%s", response.p_answer);\n                    request_st_update(100, "Done");\n                }\n                esp_event_post_to(view_event_handle, VIEW_EVENT_BASE, VIEW_EVENT_DALLE_RESPONSE, &response, sizeof(response), portMAX_DELAY);\n            }\n        }\n        vTaskDelay(pdMS_TO_TICKS(1000));\n    }\n}\n\nstatic void __view_event_handler(void *handler_args, esp_event_base_t base,\n                                 int32_t id, void *event_data)\n{\n    switch (id)\n    {\n        case VIEW_EVENT_WIFI_ST:\n        {\n            ESP_LOGI(TAG, "event: VIEW_EVENT_WIFI_ST");\n            struct view_data_wifi_st *p_st = (struct view_data_wifi_st *)event_data;\n            if (p_st->is_network)\n            {\n                net_flag = true;\n            }\n            else\n            {\n                net_flag = false;\n            }\n            break;\n        }\n        case VIEW_EVENT_CHATGPT_REQUEST:\n        {\n            ESP_LOGI(TAG, "event: VIEW_EVENT_CHATGPT_REQUEST");\n            struct view_data_openai_request *p_req = (struct view_data_openai_request *)event_data;\n            memcpy(&request,p_req, sizeof(request));\n            request_st_update(0, "ready");\n            xSemaphoreGive(__g_gpt_com_sem);\n            break;\n        }\n        case VIEW_EVENT_DALLE_REQUEST:\n        {\n            ESP_LOGI(TAG, "event: VIEW_EVENT_DALLE_REQUEST");\n            struct view_data_openai_request *p_req = (struct view_data_openai_request *)event_data;\n            memcpy(&request,p_req, sizeof(request));\n            request_st_update(0, "ready");\n            xSemaphoreGive(__g_dalle_com_sem);\n            break;\n        }\n        case VIEW_EVENT_OPENAI_API_KEY_READ:\n        {\n            ESP_LOGI(TAG, "event: VIEW_EVENT_OPENAI_API_KEY_READ");\n            __openai_api_key_read();\n            break;\n        }\n        default:\n            break;\n    }\n}\n\nint indicator_openai_init(void)\n{\n    __g_gpt_com_sem = xSemaphoreCreateBinary();\n    __g_dalle_com_sem = xSemaphoreCreateBinary();\n\n    __openai_api_key_read();\n    __openai_init();\n\n    ESP_ERROR_CHECK(esp_event_handler_instance_register_with( view_event_handle,\n                                                            VIEW_EVENT_BASE, VIEW_EVENT_WIFI_ST,\n                                                            __view_event_handler, NULL, NULL));\n    ESP_ERROR_CHECK(esp_event_handler_instance_register_with( view_event_handle,\n                                                            VIEW_EVENT_BASE, VIEW_EVENT_CHATGPT_REQUEST,\n                                                            __view_event_handler, NULL, NULL));\n    ESP_ERROR_CHECK(esp_event_handler_instance_register_with( view_event_handle,\n                                                            VIEW_EVENT_BASE, VIEW_EVENT_DALLE_REQUEST,\n                                                            __view_event_handler, NULL, NULL));\n    ESP_ERROR_CHECK(esp_event_handler_instance_register_with( view_event_handle,\n                                                            VIEW_EVENT_BASE, VIEW_EVENT_OPENAI_API_KEY_READ,\n                                                            __view_event_handler, NULL, NULL));\n    xTaskCreate(&__indicator_openai_task, "__indicator_openai_task", 1024 * 10, NULL, 10, NULL);\n}\n'))),(0,s.kt)("h2",{id:"resources"},"Resources"),(0,s.kt)("ol",null,(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("a",{parentName:"li",href:"/SenseCAP_Indicator_ChatGPT"},"SenseCAP Indicator X ChatGPT")),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("a",{parentName:"li",href:"/SenseCAP_Indicator_DALL%C2%B7E"},"SenseCAP Indicator X DALL\xb7E")),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("strong",{parentName:"li"},"Demo SDK"),": The Demo SDK for the SenseCAP Indicator is available on ",(0,s.kt)("a",{parentName:"li",href:"https://github.com/Seeed-Solution/SenseCAP_Indicator_ESP32"},"GitHub"),"."),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("strong",{parentName:"li"},"SenseCAP Indicator User Guide"),": The User Guide provides detailed information about the software and hardware of the SenseCAP Indicator Board. You can read it ",(0,s.kt)("a",{parentName:"li",href:"https://wiki.seeedstudio.com/SenseCAP_Indicator_Get_Started"},"here"),"."),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("strong",{parentName:"li"},"Chat completions OpenAI Guide"),": If you're new to Chat API, this guide will help you get you on board. You can find it ",(0,s.kt)("a",{parentName:"li",href:"https://platform.openai.com/docs/guides/chat/chat-completions-beta"},"here"),"."),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("strong",{parentName:"li"},(0,s.kt)("inlineCode",{parentName:"strong"},"indicator_openai.c")," File"),": This file contains the main functions for the ",(0,s.kt)("inlineCode",{parentName:"li"},"ChatGPT")," and ",(0,s.kt)("inlineCode",{parentName:"li"},"DALL\xb7E")," integration. You can view it ",(0,s.kt)("a",{parentName:"li",href:"https://raw.githubusercontent.com/Seeed-Solution/SenseCAP_Indicator_ESP32/main/examples/indicator_openai/main/model/indicator_openai.c"},"here"),"."),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("strong",{parentName:"li"},"Getting Started Guide for ESP-IDF"),": This guide provides full steps to configure and use ESP-IDF to build projects. You can access it ",(0,s.kt)("a",{parentName:"li",href:"https://docs.espressif.com/projects/esp-idf/en/latest/get-started/index.html"},"here"),".")),(0,s.kt)("h2",{id:"tech-support"},(0,s.kt)("strong",{parentName:"h2"},"Tech Support")),(0,s.kt)("p",null,"Don't worry, we've got you covered! Please visit our ",(0,s.kt)("a",{parentName:"p",href:"https://discord.gg/cPpeuQMM"},"Seeed Official Discord Channel")," to ask your questions!"),(0,s.kt)("p",null,"If you have large order or customization requirement, please contact ",(0,s.kt)("a",{parentName:"p",href:"mailto:iot@seeed.cc"},"iot@seeed.cc")),(0,s.kt)("div",{class:"button_tech_support_container"},(0,s.kt)("a",{href:"https://discord.gg/sensecap",class:"button_tech_support_sensecap"}),(0,s.kt)("a",{href:"https://support.sensecapmx.com/portal/en/home",class:"button_tech_support_sensecap3"})),(0,s.kt)("div",{class:"button_tech_support_container"},(0,s.kt)("a",{href:"mailto:support@sensecapmx.com",class:"button_tech_support_sensecap2"}),(0,s.kt)("a",{href:"https://github.com/Seeed-Studio/wiki-documents/discussions/69",class:"button_discussion"})))}u.isMDXComponent=!0}}]);